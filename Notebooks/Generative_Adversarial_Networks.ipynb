{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dr7yZDOSBDYz"
   },
   "source": [
    "# Generative Adversarial Networks\n",
    "\n",
    "Train a GAN to generate new handwritten digits. The dataset is MNIST. Results after 20 epochs:\n",
    "\n",
    "<img src=\"static/epoch20.png\" alt=\"Image epoch20.png not found\" style=\"width: 400px;\"/>\n",
    "\n",
    "- [Paper](https://arxiv.org/abs/1406.2661)\n",
    "- [Code](https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-an-mnist-handwritten-digits-from-scratch-in-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZMAenCXOB3Mu",
    "outputId": "d57516aa-36ba-4ce5-ab74-0d7a63f30bcc"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# Expand Dimensions to 3D to add one for the color channel of black and white: expand_dims(train_images, axis=-1)\n",
    "# Normalize the image by dividing by 255 --> faster convergence\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images, test_images = np.expand_dims(train_images, axis=-1) / 255.0, np.expand_dims(test_images, axis=-1) / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A GAN is trained in two steps.\n",
    "\n",
    "<img src=\"static/GAN_Step1.png\" alt=\"Image GAN_Step1.png not found\" style=\"width: 600px;\"/>\n",
    "\n",
    "The discriminator is trained to discriminate between dataset and generated images. Half the batch size is taken from the dataset and given the label '1' (dataset). The other half of the images is generated by the generator. They get label '0' (generated).\n",
    "\n",
    "Only the weights of the discriminator are updated in this step.\n",
    "\n",
    "\n",
    "<img src=\"static/GAN_Step2.png\" alt=\"Image GAN_Step2.png not found\" style=\"width: 600px;\"/>\n",
    "\n",
    "The generator is trained to generate images that look like handwritten digits. The generator takes as input 100 random numbers. This is called the latent space. It uses Conv2DTranspose layers to upscale this to a 28 x 28 image. This should over time resemble handwritten digits.\n",
    "\n",
    "The generated images are passed on to the discriminator. They are given the label '1' (dataset) to compute the loss. This is because we want to make the generator generate images that fool the discriminator into thinking that the images came from the dataset ('1').\n",
    "\n",
    "Only the weights of the generator are updated in this step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVm5mxjKI7E2"
   },
   "source": [
    "# Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gnnqLj4hIKuh"
   },
   "outputs": [],
   "source": [
    "def get_mnist_batch(batch_size):\n",
    "    mnist_batch = np.zeros((batch_size, 28, 28, 1))\n",
    "\n",
    "    for i in range (0, batch_size):\n",
    "        index = random.randint(0, 59999)\n",
    "        mnist_batch[i] = train_images[index]\n",
    "\n",
    "    labels = np.ones((batch_size, 1))\n",
    "    return mnist_batch, labels\n",
    "\n",
    "\n",
    "def get_noise_batch(batch_size, noise_size):\n",
    "    # noise_batch = np.random.randn(batch_size, noise_size)\n",
    "    noise_batch = np.random.randn(batch_size * noise_size)\n",
    "    noise_batch = noise_batch.reshape(batch_size, noise_size)\n",
    "\n",
    "    noise_labels = np.zeros((batch_size, 1))\n",
    "    return noise_batch, noise_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6gNcwKHMF_9"
   },
   "source": [
    "# Define the models\n",
    "\n",
    "Generator, Discriminator, GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYE6B-aGMEG6"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Reshape, Dropout, Dense\n",
    "from tensorflow.keras.layers import Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D, Conv2DTranspose, LeakyReLU\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def build_generator(noise_size=100):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Foundation for 7x7 image\n",
    "    n_nodes = 128 * 7 * 7\n",
    "    model.add(Dense(n_nodes, input_dim=noise_size))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((7, 7, 128)))\n",
    "\n",
    "    # Upsample to 14x14\n",
    "    model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # Upsample to 28x28\n",
    "    model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(1, (7, 7), activation='sigmoid', padding='same'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_discriminator(in_shape=(28, 28, 1)):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Image 14 x 14\n",
    "    model.add(Conv2D(64, (3, 3), strides=(2, 2), padding='same', input_shape=in_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Image 7 x 7\n",
    "    model.add(Conv2D(64, (3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_gan(generator, discriminator):\n",
    "    model = Sequential()\n",
    "    discriminator.trainable = False\n",
    "    \n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "\n",
    "    optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdp_HJJ2OdDv"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t10-l-GJOeVU",
    "outputId": "80ec2984-53b9-444d-9c29-adf2a660234e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "Epoch:  9     Batch:  148  /  468     Loss_generator:  0.711235761642456     Loss_discriminator:  0.6903877854347229\n",
      "Epoch:  9     Batch:  149  /  468     Loss_generator:  0.6991949081420898     Loss_discriminator:  0.6921806335449219\n",
      "Epoch:  9     Batch:  150  /  468     Loss_generator:  0.6934654712677002     Loss_discriminator:  0.6831632256507874\n",
      "Epoch:  9     Batch:  151  /  468     Loss_generator:  0.6715892553329468     Loss_discriminator:  0.6860253810882568\n",
      "Epoch:  9     Batch:  152  /  468     Loss_generator:  0.689160943031311     Loss_discriminator:  0.6927200555801392\n",
      "Epoch:  9     Batch:  153  /  468     Loss_generator:  0.7259432077407837     Loss_discriminator:  0.6893840432167053\n",
      "Epoch:  9     Batch:  154  /  468     Loss_generator:  0.7536672353744507     Loss_discriminator:  0.677346408367157\n",
      "Epoch:  9     Batch:  155  /  468     Loss_generator:  0.749859094619751     Loss_discriminator:  0.684540331363678\n",
      "Epoch:  9     Batch:  156  /  468     Loss_generator:  0.7315544486045837     Loss_discriminator:  0.6842414140701294\n",
      "Epoch:  9     Batch:  157  /  468     Loss_generator:  0.6967391967773438     Loss_discriminator:  0.6876540780067444\n",
      "Epoch:  9     Batch:  158  /  468     Loss_generator:  0.6949089169502258     Loss_discriminator:  0.6871420741081238\n",
      "Epoch:  9     Batch:  159  /  468     Loss_generator:  0.6765679121017456     Loss_discriminator:  0.6875690221786499\n",
      "Epoch:  9     Batch:  160  /  468     Loss_generator:  0.6696585416793823     Loss_discriminator:  0.6826537847518921\n",
      "Epoch:  9     Batch:  161  /  468     Loss_generator:  0.673190712928772     Loss_discriminator:  0.6844682097434998\n",
      "Epoch:  9     Batch:  162  /  468     Loss_generator:  0.6920408010482788     Loss_discriminator:  0.6833659410476685\n",
      "Epoch:  9     Batch:  163  /  468     Loss_generator:  0.710939884185791     Loss_discriminator:  0.6948572397232056\n",
      "Epoch:  9     Batch:  164  /  468     Loss_generator:  0.7482515573501587     Loss_discriminator:  0.687533974647522\n",
      "Epoch:  9     Batch:  165  /  468     Loss_generator:  0.7633904814720154     Loss_discriminator:  0.6919174790382385\n",
      "Epoch:  9     Batch:  166  /  468     Loss_generator:  0.727318286895752     Loss_discriminator:  0.6827795505523682\n",
      "Epoch:  9     Batch:  167  /  468     Loss_generator:  0.6971784830093384     Loss_discriminator:  0.693252682685852\n",
      "Epoch:  9     Batch:  168  /  468     Loss_generator:  0.6809498071670532     Loss_discriminator:  0.6945708990097046\n",
      "Epoch:  9     Batch:  169  /  468     Loss_generator:  0.6576612591743469     Loss_discriminator:  0.6854588389396667\n",
      "Epoch:  9     Batch:  170  /  468     Loss_generator:  0.6672077178955078     Loss_discriminator:  0.6871299743652344\n",
      "Epoch:  9     Batch:  171  /  468     Loss_generator:  0.6812715530395508     Loss_discriminator:  0.6881402134895325\n",
      "Epoch:  9     Batch:  172  /  468     Loss_generator:  0.7197985649108887     Loss_discriminator:  0.6908779144287109\n",
      "Epoch:  9     Batch:  173  /  468     Loss_generator:  0.7245850563049316     Loss_discriminator:  0.6869619488716125\n",
      "Epoch:  9     Batch:  174  /  468     Loss_generator:  0.7477774620056152     Loss_discriminator:  0.6946921348571777\n",
      "Epoch:  9     Batch:  175  /  468     Loss_generator:  0.7389777898788452     Loss_discriminator:  0.6873361468315125\n",
      "Epoch:  9     Batch:  176  /  468     Loss_generator:  0.7120606899261475     Loss_discriminator:  0.6908725500106812\n",
      "Epoch:  9     Batch:  177  /  468     Loss_generator:  0.6978379487991333     Loss_discriminator:  0.6911067366600037\n",
      "Epoch:  9     Batch:  178  /  468     Loss_generator:  0.694542646408081     Loss_discriminator:  0.6727015972137451\n",
      "Epoch:  9     Batch:  179  /  468     Loss_generator:  0.705359935760498     Loss_discriminator:  0.6892122030258179\n",
      "Epoch:  9     Batch:  180  /  468     Loss_generator:  0.6993148326873779     Loss_discriminator:  0.6925109028816223\n",
      "Epoch:  9     Batch:  181  /  468     Loss_generator:  0.7257175445556641     Loss_discriminator:  0.6833330392837524\n",
      "Epoch:  9     Batch:  182  /  468     Loss_generator:  0.7162438631057739     Loss_discriminator:  0.6725798845291138\n",
      "Epoch:  9     Batch:  183  /  468     Loss_generator:  0.7246306538581848     Loss_discriminator:  0.6897439956665039\n",
      "Epoch:  9     Batch:  184  /  468     Loss_generator:  0.7200401425361633     Loss_discriminator:  0.6740682125091553\n",
      "Epoch:  9     Batch:  185  /  468     Loss_generator:  0.7275294065475464     Loss_discriminator:  0.6738383769989014\n",
      "Epoch:  9     Batch:  186  /  468     Loss_generator:  0.7210371494293213     Loss_discriminator:  0.6850873231887817\n",
      "Epoch:  9     Batch:  187  /  468     Loss_generator:  0.7035079002380371     Loss_discriminator:  0.6802350878715515\n",
      "Epoch:  9     Batch:  188  /  468     Loss_generator:  0.7005476951599121     Loss_discriminator:  0.6883862018585205\n",
      "Epoch:  9     Batch:  189  /  468     Loss_generator:  0.7038026452064514     Loss_discriminator:  0.6917308568954468\n",
      "Epoch:  9     Batch:  190  /  468     Loss_generator:  0.7086237072944641     Loss_discriminator:  0.6770084500312805\n",
      "Epoch:  9     Batch:  191  /  468     Loss_generator:  0.6991640329360962     Loss_discriminator:  0.6727285981178284\n",
      "Epoch:  9     Batch:  192  /  468     Loss_generator:  0.7001540064811707     Loss_discriminator:  0.6789093017578125\n",
      "Epoch:  9     Batch:  193  /  468     Loss_generator:  0.7073702216148376     Loss_discriminator:  0.688835859298706\n",
      "Epoch:  9     Batch:  194  /  468     Loss_generator:  0.70688396692276     Loss_discriminator:  0.6790421009063721\n",
      "Epoch:  9     Batch:  195  /  468     Loss_generator:  0.6961234211921692     Loss_discriminator:  0.6809810996055603\n",
      "Epoch:  9     Batch:  196  /  468     Loss_generator:  0.7012383937835693     Loss_discriminator:  0.6880808472633362\n",
      "Epoch:  9     Batch:  197  /  468     Loss_generator:  0.7161071300506592     Loss_discriminator:  0.6803539395332336\n",
      "Epoch:  9     Batch:  198  /  468     Loss_generator:  0.7059693336486816     Loss_discriminator:  0.6737691760063171\n",
      "Epoch:  9     Batch:  199  /  468     Loss_generator:  0.7039254307746887     Loss_discriminator:  0.6725893020629883\n",
      "Epoch:  9     Batch:  200  /  468     Loss_generator:  0.6962875723838806     Loss_discriminator:  0.6997693181037903\n",
      "Epoch:  9     Batch:  201  /  468     Loss_generator:  0.6956908702850342     Loss_discriminator:  0.6964561939239502\n",
      "Epoch:  9     Batch:  202  /  468     Loss_generator:  0.7055339813232422     Loss_discriminator:  0.6868857145309448\n",
      "Epoch:  9     Batch:  203  /  468     Loss_generator:  0.6807352304458618     Loss_discriminator:  0.6888219714164734\n",
      "Epoch:  9     Batch:  204  /  468     Loss_generator:  0.7000874280929565     Loss_discriminator:  0.6975150108337402\n",
      "Epoch:  9     Batch:  205  /  468     Loss_generator:  0.7075173258781433     Loss_discriminator:  0.6931671500205994\n",
      "Epoch:  9     Batch:  206  /  468     Loss_generator:  0.7267025709152222     Loss_discriminator:  0.6883754730224609\n",
      "Epoch:  9     Batch:  207  /  468     Loss_generator:  0.7152391672134399     Loss_discriminator:  0.6832422018051147\n",
      "Epoch:  9     Batch:  208  /  468     Loss_generator:  0.6949250102043152     Loss_discriminator:  0.6891844272613525\n",
      "Epoch:  9     Batch:  209  /  468     Loss_generator:  0.6936681866645813     Loss_discriminator:  0.6943614482879639\n",
      "Epoch:  9     Batch:  210  /  468     Loss_generator:  0.7026543021202087     Loss_discriminator:  0.6718628406524658\n",
      "Epoch:  9     Batch:  211  /  468     Loss_generator:  0.7071093916893005     Loss_discriminator:  0.6856683492660522\n",
      "Epoch:  9     Batch:  212  /  468     Loss_generator:  0.7174975275993347     Loss_discriminator:  0.6780607104301453\n",
      "Epoch:  9     Batch:  213  /  468     Loss_generator:  0.716073751449585     Loss_discriminator:  0.6872739195823669\n",
      "Epoch:  9     Batch:  214  /  468     Loss_generator:  0.6850718259811401     Loss_discriminator:  0.6795685887336731\n",
      "Epoch:  9     Batch:  215  /  468     Loss_generator:  0.6858642101287842     Loss_discriminator:  0.6836624145507812\n",
      "Epoch:  9     Batch:  216  /  468     Loss_generator:  0.6768628358840942     Loss_discriminator:  0.6853979229927063\n",
      "Epoch:  9     Batch:  217  /  468     Loss_generator:  0.7062033414840698     Loss_discriminator:  0.6842119693756104\n",
      "Epoch:  9     Batch:  218  /  468     Loss_generator:  0.7674441337585449     Loss_discriminator:  0.6875901818275452\n",
      "Epoch:  9     Batch:  219  /  468     Loss_generator:  0.7857427597045898     Loss_discriminator:  0.6821343898773193\n",
      "Epoch:  9     Batch:  220  /  468     Loss_generator:  0.7633065581321716     Loss_discriminator:  0.6822697520256042\n",
      "Epoch:  9     Batch:  221  /  468     Loss_generator:  0.7147301435470581     Loss_discriminator:  0.7018277049064636\n",
      "Epoch:  9     Batch:  222  /  468     Loss_generator:  0.6775627136230469     Loss_discriminator:  0.689011812210083\n",
      "Epoch:  9     Batch:  223  /  468     Loss_generator:  0.6652308702468872     Loss_discriminator:  0.6950305700302124\n",
      "Epoch:  9     Batch:  224  /  468     Loss_generator:  0.6485480070114136     Loss_discriminator:  0.6832149028778076\n",
      "Epoch:  9     Batch:  225  /  468     Loss_generator:  0.6918085217475891     Loss_discriminator:  0.6818913221359253\n",
      "Epoch:  9     Batch:  226  /  468     Loss_generator:  0.743489682674408     Loss_discriminator:  0.6885101795196533\n",
      "Epoch:  9     Batch:  227  /  468     Loss_generator:  0.7736186981201172     Loss_discriminator:  0.6941773891448975\n",
      "Epoch:  9     Batch:  228  /  468     Loss_generator:  0.7901774644851685     Loss_discriminator:  0.6862726807594299\n",
      "Epoch:  9     Batch:  229  /  468     Loss_generator:  0.7543694972991943     Loss_discriminator:  0.6841430068016052\n",
      "Epoch:  9     Batch:  230  /  468     Loss_generator:  0.7085379362106323     Loss_discriminator:  0.6809855103492737\n",
      "Epoch:  9     Batch:  231  /  468     Loss_generator:  0.6734496355056763     Loss_discriminator:  0.6919777393341064\n",
      "Epoch:  9     Batch:  232  /  468     Loss_generator:  0.6541516780853271     Loss_discriminator:  0.6885905861854553\n",
      "Epoch:  9     Batch:  233  /  468     Loss_generator:  0.6388990879058838     Loss_discriminator:  0.6757236123085022\n",
      "Epoch:  9     Batch:  234  /  468     Loss_generator:  0.6674119830131531     Loss_discriminator:  0.6919686794281006\n",
      "Epoch:  9     Batch:  235  /  468     Loss_generator:  0.7283129692077637     Loss_discriminator:  0.6913841366767883\n",
      "Epoch:  9     Batch:  236  /  468     Loss_generator:  0.7646434307098389     Loss_discriminator:  0.6840394735336304\n",
      "Epoch:  9     Batch:  237  /  468     Loss_generator:  0.7796145081520081     Loss_discriminator:  0.6826831698417664\n",
      "Epoch:  9     Batch:  238  /  468     Loss_generator:  0.7613470554351807     Loss_discriminator:  0.6889418959617615\n",
      "Epoch:  9     Batch:  239  /  468     Loss_generator:  0.7362629771232605     Loss_discriminator:  0.6701040267944336\n",
      "Epoch:  9     Batch:  240  /  468     Loss_generator:  0.7094054222106934     Loss_discriminator:  0.6889930963516235\n",
      "Epoch:  9     Batch:  241  /  468     Loss_generator:  0.6949243545532227     Loss_discriminator:  0.6719352006912231\n",
      "Epoch:  9     Batch:  242  /  468     Loss_generator:  0.6894598603248596     Loss_discriminator:  0.6831238865852356\n",
      "Epoch:  9     Batch:  243  /  468     Loss_generator:  0.690574586391449     Loss_discriminator:  0.6867326498031616\n",
      "Epoch:  9     Batch:  244  /  468     Loss_generator:  0.7058717012405396     Loss_discriminator:  0.6835767030715942\n",
      "Epoch:  9     Batch:  245  /  468     Loss_generator:  0.720666766166687     Loss_discriminator:  0.6805382370948792\n",
      "Epoch:  9     Batch:  246  /  468     Loss_generator:  0.7364591360092163     Loss_discriminator:  0.6749590635299683\n",
      "Epoch:  9     Batch:  247  /  468     Loss_generator:  0.7582229375839233     Loss_discriminator:  0.6868181228637695\n",
      "Epoch:  9     Batch:  248  /  468     Loss_generator:  0.7577784061431885     Loss_discriminator:  0.6880367994308472\n",
      "Epoch:  9     Batch:  249  /  468     Loss_generator:  0.720170259475708     Loss_discriminator:  0.676690936088562\n",
      "Epoch:  9     Batch:  250  /  468     Loss_generator:  0.6851376295089722     Loss_discriminator:  0.6830199956893921\n",
      "Epoch:  9     Batch:  251  /  468     Loss_generator:  0.6764551401138306     Loss_discriminator:  0.6881619095802307\n",
      "Epoch:  9     Batch:  252  /  468     Loss_generator:  0.6792809367179871     Loss_discriminator:  0.6761361956596375\n",
      "Epoch:  9     Batch:  253  /  468     Loss_generator:  0.6948297619819641     Loss_discriminator:  0.7054346203804016\n",
      "Epoch:  9     Batch:  254  /  468     Loss_generator:  0.6887146830558777     Loss_discriminator:  0.66974276304245\n",
      "Epoch:  9     Batch:  255  /  468     Loss_generator:  0.7063279151916504     Loss_discriminator:  0.6917369365692139\n",
      "Epoch:  9     Batch:  256  /  468     Loss_generator:  0.7189798355102539     Loss_discriminator:  0.6851202249526978\n",
      "Epoch:  9     Batch:  257  /  468     Loss_generator:  0.7209072113037109     Loss_discriminator:  0.6896179914474487\n",
      "Epoch:  9     Batch:  258  /  468     Loss_generator:  0.7185109257698059     Loss_discriminator:  0.6871515512466431\n",
      "Epoch:  9     Batch:  259  /  468     Loss_generator:  0.7344017028808594     Loss_discriminator:  0.693932294845581\n",
      "Epoch:  9     Batch:  260  /  468     Loss_generator:  0.6979882717132568     Loss_discriminator:  0.6834803223609924\n",
      "Epoch:  9     Batch:  261  /  468     Loss_generator:  0.7006211280822754     Loss_discriminator:  0.690561056137085\n",
      "Epoch:  9     Batch:  262  /  468     Loss_generator:  0.708344578742981     Loss_discriminator:  0.6896175742149353\n",
      "Epoch:  9     Batch:  263  /  468     Loss_generator:  0.728661060333252     Loss_discriminator:  0.695376992225647\n",
      "Epoch:  9     Batch:  264  /  468     Loss_generator:  0.7144426107406616     Loss_discriminator:  0.6961126327514648\n",
      "Epoch:  9     Batch:  265  /  468     Loss_generator:  0.6911526918411255     Loss_discriminator:  0.7038441896438599\n",
      "Epoch:  9     Batch:  266  /  468     Loss_generator:  0.7017767429351807     Loss_discriminator:  0.6802887916564941\n",
      "Epoch:  9     Batch:  267  /  468     Loss_generator:  0.7022595405578613     Loss_discriminator:  0.6818779706954956\n",
      "Epoch:  9     Batch:  268  /  468     Loss_generator:  0.6978372931480408     Loss_discriminator:  0.6849414110183716\n",
      "Epoch:  9     Batch:  269  /  468     Loss_generator:  0.6835722923278809     Loss_discriminator:  0.6804789900779724\n",
      "Epoch:  9     Batch:  270  /  468     Loss_generator:  0.6803422570228577     Loss_discriminator:  0.6841086745262146\n",
      "Epoch:  9     Batch:  271  /  468     Loss_generator:  0.7199269533157349     Loss_discriminator:  0.7007008194923401\n",
      "Epoch:  9     Batch:  272  /  468     Loss_generator:  0.7319919466972351     Loss_discriminator:  0.6929556131362915\n",
      "Epoch:  9     Batch:  273  /  468     Loss_generator:  0.7410266399383545     Loss_discriminator:  0.6916817426681519\n",
      "Epoch:  9     Batch:  274  /  468     Loss_generator:  0.7370171546936035     Loss_discriminator:  0.6800240278244019\n",
      "Epoch:  9     Batch:  275  /  468     Loss_generator:  0.7332818508148193     Loss_discriminator:  0.6768850088119507\n",
      "Epoch:  9     Batch:  276  /  468     Loss_generator:  0.7077603340148926     Loss_discriminator:  0.6898043751716614\n",
      "Epoch:  9     Batch:  277  /  468     Loss_generator:  0.6868010759353638     Loss_discriminator:  0.6858168840408325\n",
      "Epoch:  9     Batch:  278  /  468     Loss_generator:  0.693844199180603     Loss_discriminator:  0.6927001476287842\n",
      "Epoch:  9     Batch:  279  /  468     Loss_generator:  0.6725589632987976     Loss_discriminator:  0.6809014081954956\n",
      "Epoch:  9     Batch:  280  /  468     Loss_generator:  0.6897349953651428     Loss_discriminator:  0.6761711835861206\n",
      "Epoch:  9     Batch:  281  /  468     Loss_generator:  0.6867974996566772     Loss_discriminator:  0.6699471473693848\n",
      "Epoch:  9     Batch:  282  /  468     Loss_generator:  0.7076188325881958     Loss_discriminator:  0.6929318904876709\n",
      "Epoch:  9     Batch:  283  /  468     Loss_generator:  0.730629026889801     Loss_discriminator:  0.6821936368942261\n",
      "Epoch:  9     Batch:  284  /  468     Loss_generator:  0.7240440249443054     Loss_discriminator:  0.689237117767334\n",
      "Epoch:  9     Batch:  285  /  468     Loss_generator:  0.7101049423217773     Loss_discriminator:  0.6817740201950073\n",
      "Epoch:  9     Batch:  286  /  468     Loss_generator:  0.7077798843383789     Loss_discriminator:  0.68618243932724\n",
      "Epoch:  9     Batch:  287  /  468     Loss_generator:  0.7053285837173462     Loss_discriminator:  0.6748561263084412\n",
      "Epoch:  9     Batch:  288  /  468     Loss_generator:  0.6965966820716858     Loss_discriminator:  0.6823588609695435\n",
      "Epoch:  9     Batch:  289  /  468     Loss_generator:  0.6917200684547424     Loss_discriminator:  0.6676062345504761\n",
      "Epoch:  9     Batch:  290  /  468     Loss_generator:  0.6893768310546875     Loss_discriminator:  0.6722400188446045\n",
      "Epoch:  9     Batch:  291  /  468     Loss_generator:  0.7077780365943909     Loss_discriminator:  0.6812115907669067\n",
      "Epoch:  9     Batch:  292  /  468     Loss_generator:  0.7294095158576965     Loss_discriminator:  0.6857928037643433\n",
      "Epoch:  9     Batch:  293  /  468     Loss_generator:  0.7744324207305908     Loss_discriminator:  0.6743481159210205\n",
      "Epoch:  9     Batch:  294  /  468     Loss_generator:  0.7289779782295227     Loss_discriminator:  0.6911972165107727\n",
      "Epoch:  9     Batch:  295  /  468     Loss_generator:  0.7136510014533997     Loss_discriminator:  0.6648851633071899\n",
      "Epoch:  9     Batch:  296  /  468     Loss_generator:  0.6841475367546082     Loss_discriminator:  0.6881978511810303\n",
      "Epoch:  9     Batch:  297  /  468     Loss_generator:  0.6564663648605347     Loss_discriminator:  0.685883641242981\n",
      "Epoch:  9     Batch:  298  /  468     Loss_generator:  0.6708793640136719     Loss_discriminator:  0.6907975077629089\n",
      "Epoch:  9     Batch:  299  /  468     Loss_generator:  0.7212027311325073     Loss_discriminator:  0.6968466639518738\n",
      "Epoch:  9     Batch:  300  /  468     Loss_generator:  0.7334640026092529     Loss_discriminator:  0.6906213760375977\n",
      "Epoch:  9     Batch:  301  /  468     Loss_generator:  0.7320386171340942     Loss_discriminator:  0.6830793619155884\n",
      "Epoch:  9     Batch:  302  /  468     Loss_generator:  0.7231104373931885     Loss_discriminator:  0.6837211847305298\n",
      "Epoch:  9     Batch:  303  /  468     Loss_generator:  0.7212290167808533     Loss_discriminator:  0.6894669532775879\n",
      "Epoch:  9     Batch:  304  /  468     Loss_generator:  0.6994276642799377     Loss_discriminator:  0.692219078540802\n",
      "Epoch:  9     Batch:  305  /  468     Loss_generator:  0.6849380731582642     Loss_discriminator:  0.678608238697052\n",
      "Epoch:  9     Batch:  306  /  468     Loss_generator:  0.6850292086601257     Loss_discriminator:  0.6802437901496887\n",
      "Epoch:  9     Batch:  307  /  468     Loss_generator:  0.6821532845497131     Loss_discriminator:  0.6913073062896729\n",
      "Epoch:  9     Batch:  308  /  468     Loss_generator:  0.7167012691497803     Loss_discriminator:  0.6895340085029602\n",
      "Epoch:  9     Batch:  309  /  468     Loss_generator:  0.74187171459198     Loss_discriminator:  0.6761143207550049\n",
      "Epoch:  9     Batch:  310  /  468     Loss_generator:  0.7486714720726013     Loss_discriminator:  0.68748939037323\n",
      "Epoch:  9     Batch:  311  /  468     Loss_generator:  0.7194812893867493     Loss_discriminator:  0.6952354311943054\n",
      "Epoch:  9     Batch:  312  /  468     Loss_generator:  0.6971734166145325     Loss_discriminator:  0.6831352114677429\n",
      "Epoch:  9     Batch:  313  /  468     Loss_generator:  0.7093468904495239     Loss_discriminator:  0.6858439445495605\n",
      "Epoch:  9     Batch:  314  /  468     Loss_generator:  0.7169656753540039     Loss_discriminator:  0.6783472299575806\n",
      "Epoch:  9     Batch:  315  /  468     Loss_generator:  0.7188540101051331     Loss_discriminator:  0.6985759735107422\n",
      "Epoch:  9     Batch:  316  /  468     Loss_generator:  0.7194037437438965     Loss_discriminator:  0.6840623617172241\n",
      "Epoch:  9     Batch:  317  /  468     Loss_generator:  0.6877871155738831     Loss_discriminator:  0.6799517869949341\n",
      "Epoch:  9     Batch:  318  /  468     Loss_generator:  0.68504399061203     Loss_discriminator:  0.6761771440505981\n",
      "Epoch:  9     Batch:  319  /  468     Loss_generator:  0.7097828388214111     Loss_discriminator:  0.6830845475196838\n",
      "Epoch:  9     Batch:  320  /  468     Loss_generator:  0.7375362515449524     Loss_discriminator:  0.6866388916969299\n",
      "Epoch:  9     Batch:  321  /  468     Loss_generator:  0.7426519393920898     Loss_discriminator:  0.6827925443649292\n",
      "Epoch:  9     Batch:  322  /  468     Loss_generator:  0.7042572498321533     Loss_discriminator:  0.6862714290618896\n",
      "Epoch:  9     Batch:  323  /  468     Loss_generator:  0.7072606086730957     Loss_discriminator:  0.6757304668426514\n",
      "Epoch:  9     Batch:  324  /  468     Loss_generator:  0.6995493769645691     Loss_discriminator:  0.6767090559005737\n",
      "Epoch:  9     Batch:  325  /  468     Loss_generator:  0.7071732878684998     Loss_discriminator:  0.6844586133956909\n",
      "Epoch:  9     Batch:  326  /  468     Loss_generator:  0.703571617603302     Loss_discriminator:  0.6809172630310059\n",
      "Epoch:  9     Batch:  327  /  468     Loss_generator:  0.7132031917572021     Loss_discriminator:  0.6696099638938904\n",
      "Epoch:  9     Batch:  328  /  468     Loss_generator:  0.7236192226409912     Loss_discriminator:  0.6910496950149536\n",
      "Epoch:  9     Batch:  329  /  468     Loss_generator:  0.7473239302635193     Loss_discriminator:  0.6874579191207886\n",
      "Epoch:  9     Batch:  330  /  468     Loss_generator:  0.756949782371521     Loss_discriminator:  0.6989898681640625\n",
      "Epoch:  9     Batch:  331  /  468     Loss_generator:  0.7393801212310791     Loss_discriminator:  0.6892107725143433\n",
      "Epoch:  9     Batch:  332  /  468     Loss_generator:  0.6860182285308838     Loss_discriminator:  0.6942459940910339\n",
      "Epoch:  9     Batch:  333  /  468     Loss_generator:  0.6534430980682373     Loss_discriminator:  0.6945463418960571\n",
      "Epoch:  9     Batch:  334  /  468     Loss_generator:  0.6629215478897095     Loss_discriminator:  0.6970120668411255\n",
      "Epoch:  9     Batch:  335  /  468     Loss_generator:  0.691521406173706     Loss_discriminator:  0.6810385584831238\n",
      "Epoch:  9     Batch:  336  /  468     Loss_generator:  0.7206905484199524     Loss_discriminator:  0.6780887246131897\n",
      "Epoch:  9     Batch:  337  /  468     Loss_generator:  0.7594050168991089     Loss_discriminator:  0.6902845501899719\n",
      "Epoch:  9     Batch:  338  /  468     Loss_generator:  0.756645679473877     Loss_discriminator:  0.6855227947235107\n",
      "Epoch:  9     Batch:  339  /  468     Loss_generator:  0.7257789373397827     Loss_discriminator:  0.6834424734115601\n",
      "Epoch:  9     Batch:  340  /  468     Loss_generator:  0.7070056200027466     Loss_discriminator:  0.6936074495315552\n",
      "Epoch:  9     Batch:  341  /  468     Loss_generator:  0.6708760261535645     Loss_discriminator:  0.6880244016647339\n",
      "Epoch:  9     Batch:  342  /  468     Loss_generator:  0.6546707153320312     Loss_discriminator:  0.6941224932670593\n",
      "Epoch:  9     Batch:  343  /  468     Loss_generator:  0.6756205558776855     Loss_discriminator:  0.6860302090644836\n",
      "Epoch:  9     Batch:  344  /  468     Loss_generator:  0.7052018046379089     Loss_discriminator:  0.6901196837425232\n",
      "Epoch:  9     Batch:  345  /  468     Loss_generator:  0.7317487597465515     Loss_discriminator:  0.6792247295379639\n",
      "Epoch:  9     Batch:  346  /  468     Loss_generator:  0.7415182590484619     Loss_discriminator:  0.6726869344711304\n",
      "Epoch:  9     Batch:  347  /  468     Loss_generator:  0.7507266402244568     Loss_discriminator:  0.6790729761123657\n",
      "Epoch:  9     Batch:  348  /  468     Loss_generator:  0.711561918258667     Loss_discriminator:  0.6902586817741394\n",
      "Epoch:  9     Batch:  349  /  468     Loss_generator:  0.6941527128219604     Loss_discriminator:  0.6761928796768188\n",
      "Epoch:  9     Batch:  350  /  468     Loss_generator:  0.6672607660293579     Loss_discriminator:  0.6834738254547119\n",
      "Epoch:  9     Batch:  351  /  468     Loss_generator:  0.6656956672668457     Loss_discriminator:  0.6800305247306824\n",
      "Epoch:  9     Batch:  352  /  468     Loss_generator:  0.6910847425460815     Loss_discriminator:  0.6774865984916687\n",
      "Epoch:  9     Batch:  353  /  468     Loss_generator:  0.701731264591217     Loss_discriminator:  0.6813526153564453\n",
      "Epoch:  9     Batch:  354  /  468     Loss_generator:  0.7381069660186768     Loss_discriminator:  0.6847427487373352\n",
      "Epoch:  9     Batch:  355  /  468     Loss_generator:  0.7856813669204712     Loss_discriminator:  0.6806620359420776\n",
      "Epoch:  9     Batch:  356  /  468     Loss_generator:  0.7963471412658691     Loss_discriminator:  0.6913874745368958\n",
      "Epoch:  9     Batch:  357  /  468     Loss_generator:  0.7538697719573975     Loss_discriminator:  0.6950613260269165\n",
      "Epoch:  9     Batch:  358  /  468     Loss_generator:  0.7156267762184143     Loss_discriminator:  0.6803189516067505\n",
      "Epoch:  9     Batch:  359  /  468     Loss_generator:  0.6721717119216919     Loss_discriminator:  0.6949193477630615\n",
      "Epoch:  9     Batch:  360  /  468     Loss_generator:  0.6486784815788269     Loss_discriminator:  0.6934489011764526\n",
      "Epoch:  9     Batch:  361  /  468     Loss_generator:  0.6536149978637695     Loss_discriminator:  0.6887223124504089\n",
      "Epoch:  9     Batch:  362  /  468     Loss_generator:  0.6976139545440674     Loss_discriminator:  0.6877174377441406\n",
      "Epoch:  9     Batch:  363  /  468     Loss_generator:  0.748349666595459     Loss_discriminator:  0.7001953125\n",
      "Epoch:  9     Batch:  364  /  468     Loss_generator:  0.7889080047607422     Loss_discriminator:  0.6861848831176758\n",
      "Epoch:  9     Batch:  365  /  468     Loss_generator:  0.7352138757705688     Loss_discriminator:  0.6732914447784424\n",
      "Epoch:  9     Batch:  366  /  468     Loss_generator:  0.6932779550552368     Loss_discriminator:  0.6891975402832031\n",
      "Epoch:  9     Batch:  367  /  468     Loss_generator:  0.6881842017173767     Loss_discriminator:  0.677221417427063\n",
      "Epoch:  9     Batch:  368  /  468     Loss_generator:  0.694277286529541     Loss_discriminator:  0.6923173069953918\n",
      "Epoch:  9     Batch:  369  /  468     Loss_generator:  0.6955950260162354     Loss_discriminator:  0.6853857040405273\n",
      "Epoch:  9     Batch:  370  /  468     Loss_generator:  0.6572681069374084     Loss_discriminator:  0.6752884387969971\n",
      "Epoch:  9     Batch:  371  /  468     Loss_generator:  0.686023473739624     Loss_discriminator:  0.695462703704834\n",
      "Epoch:  9     Batch:  372  /  468     Loss_generator:  0.7252572774887085     Loss_discriminator:  0.6782246828079224\n",
      "Epoch:  9     Batch:  373  /  468     Loss_generator:  0.7540014982223511     Loss_discriminator:  0.6718204021453857\n",
      "Epoch:  9     Batch:  374  /  468     Loss_generator:  0.7488579750061035     Loss_discriminator:  0.6882230043411255\n",
      "Epoch:  9     Batch:  375  /  468     Loss_generator:  0.7197766304016113     Loss_discriminator:  0.6839236617088318\n",
      "Epoch:  9     Batch:  376  /  468     Loss_generator:  0.7304553985595703     Loss_discriminator:  0.6861066818237305\n",
      "Epoch:  9     Batch:  377  /  468     Loss_generator:  0.7018758058547974     Loss_discriminator:  0.6842812299728394\n",
      "Epoch:  9     Batch:  378  /  468     Loss_generator:  0.6873868703842163     Loss_discriminator:  0.6804484128952026\n",
      "Epoch:  9     Batch:  379  /  468     Loss_generator:  0.7031314969062805     Loss_discriminator:  0.6883015632629395\n",
      "Epoch:  9     Batch:  380  /  468     Loss_generator:  0.6800293326377869     Loss_discriminator:  0.6852717399597168\n",
      "Epoch:  9     Batch:  381  /  468     Loss_generator:  0.6914645433425903     Loss_discriminator:  0.6789567470550537\n",
      "Epoch:  9     Batch:  382  /  468     Loss_generator:  0.6971253156661987     Loss_discriminator:  0.6930684447288513\n",
      "Epoch:  9     Batch:  383  /  468     Loss_generator:  0.7062698602676392     Loss_discriminator:  0.6888278722763062\n",
      "Epoch:  9     Batch:  384  /  468     Loss_generator:  0.7012453079223633     Loss_discriminator:  0.6764535903930664\n",
      "Epoch:  9     Batch:  385  /  468     Loss_generator:  0.7411547303199768     Loss_discriminator:  0.6878844499588013\n",
      "Epoch:  9     Batch:  386  /  468     Loss_generator:  0.7311573624610901     Loss_discriminator:  0.6895034313201904\n",
      "Epoch:  9     Batch:  387  /  468     Loss_generator:  0.7029762268066406     Loss_discriminator:  0.6817461252212524\n",
      "Epoch:  9     Batch:  388  /  468     Loss_generator:  0.686835527420044     Loss_discriminator:  0.690880537033081\n",
      "Epoch:  9     Batch:  389  /  468     Loss_generator:  0.687646210193634     Loss_discriminator:  0.6853135824203491\n",
      "Epoch:  9     Batch:  390  /  468     Loss_generator:  0.6968163847923279     Loss_discriminator:  0.6957001686096191\n",
      "Epoch:  9     Batch:  391  /  468     Loss_generator:  0.6939706206321716     Loss_discriminator:  0.6922154426574707\n",
      "Epoch:  9     Batch:  392  /  468     Loss_generator:  0.7134959697723389     Loss_discriminator:  0.6893091201782227\n",
      "Epoch:  9     Batch:  393  /  468     Loss_generator:  0.7196975350379944     Loss_discriminator:  0.6868270635604858\n",
      "Epoch:  9     Batch:  394  /  468     Loss_generator:  0.7411216497421265     Loss_discriminator:  0.6872100234031677\n",
      "Epoch:  9     Batch:  395  /  468     Loss_generator:  0.7102247476577759     Loss_discriminator:  0.6797323226928711\n",
      "Epoch:  9     Batch:  396  /  468     Loss_generator:  0.6949422359466553     Loss_discriminator:  0.679007887840271\n",
      "Epoch:  9     Batch:  397  /  468     Loss_generator:  0.6927681565284729     Loss_discriminator:  0.6904004812240601\n",
      "Epoch:  9     Batch:  398  /  468     Loss_generator:  0.7079950571060181     Loss_discriminator:  0.6720649003982544\n",
      "Epoch:  9     Batch:  399  /  468     Loss_generator:  0.7226436138153076     Loss_discriminator:  0.6937673091888428\n",
      "Epoch:  9     Batch:  400  /  468     Loss_generator:  0.6921356916427612     Loss_discriminator:  0.6839823722839355\n",
      "Epoch:  9     Batch:  401  /  468     Loss_generator:  0.6812968850135803     Loss_discriminator:  0.6872453093528748\n",
      "Epoch:  9     Batch:  402  /  468     Loss_generator:  0.7020055055618286     Loss_discriminator:  0.6871033906936646\n",
      "Epoch:  9     Batch:  403  /  468     Loss_generator:  0.7294783592224121     Loss_discriminator:  0.6768715381622314\n",
      "Epoch:  9     Batch:  404  /  468     Loss_generator:  0.7244733572006226     Loss_discriminator:  0.6829752326011658\n",
      "Epoch:  9     Batch:  405  /  468     Loss_generator:  0.7307384014129639     Loss_discriminator:  0.6807308197021484\n",
      "Epoch:  9     Batch:  406  /  468     Loss_generator:  0.7176682949066162     Loss_discriminator:  0.6851580142974854\n",
      "Epoch:  9     Batch:  407  /  468     Loss_generator:  0.6848049163818359     Loss_discriminator:  0.6783257126808167\n",
      "Epoch:  9     Batch:  408  /  468     Loss_generator:  0.6621445417404175     Loss_discriminator:  0.6926184892654419\n",
      "Epoch:  9     Batch:  409  /  468     Loss_generator:  0.6664296388626099     Loss_discriminator:  0.6899732947349548\n",
      "Epoch:  9     Batch:  410  /  468     Loss_generator:  0.7072234153747559     Loss_discriminator:  0.6991798281669617\n",
      "Epoch:  9     Batch:  411  /  468     Loss_generator:  0.7342267036437988     Loss_discriminator:  0.6805270910263062\n",
      "Epoch:  9     Batch:  412  /  468     Loss_generator:  0.767000675201416     Loss_discriminator:  0.6873380541801453\n",
      "Epoch:  9     Batch:  413  /  468     Loss_generator:  0.7774871587753296     Loss_discriminator:  0.6727756261825562\n",
      "Epoch:  9     Batch:  414  /  468     Loss_generator:  0.7405284643173218     Loss_discriminator:  0.682022750377655\n",
      "Epoch:  9     Batch:  415  /  468     Loss_generator:  0.6938676834106445     Loss_discriminator:  0.6936675310134888\n",
      "Epoch:  9     Batch:  416  /  468     Loss_generator:  0.6785293817520142     Loss_discriminator:  0.6798986792564392\n",
      "Epoch:  9     Batch:  417  /  468     Loss_generator:  0.6723430752754211     Loss_discriminator:  0.6788220405578613\n",
      "Epoch:  9     Batch:  418  /  468     Loss_generator:  0.6800068616867065     Loss_discriminator:  0.6859678030014038\n",
      "Epoch:  9     Batch:  419  /  468     Loss_generator:  0.703749418258667     Loss_discriminator:  0.690808892250061\n",
      "Epoch:  9     Batch:  420  /  468     Loss_generator:  0.7382240891456604     Loss_discriminator:  0.6848767995834351\n",
      "Epoch:  9     Batch:  421  /  468     Loss_generator:  0.7327640652656555     Loss_discriminator:  0.6837113499641418\n",
      "Epoch:  9     Batch:  422  /  468     Loss_generator:  0.7327387928962708     Loss_discriminator:  0.6906037330627441\n",
      "Epoch:  9     Batch:  423  /  468     Loss_generator:  0.7145879864692688     Loss_discriminator:  0.6919437646865845\n",
      "Epoch:  9     Batch:  424  /  468     Loss_generator:  0.694990873336792     Loss_discriminator:  0.6709021925926208\n",
      "Epoch:  9     Batch:  425  /  468     Loss_generator:  0.6799997091293335     Loss_discriminator:  0.6928293704986572\n",
      "Epoch:  9     Batch:  426  /  468     Loss_generator:  0.6838693022727966     Loss_discriminator:  0.6843786835670471\n",
      "Epoch:  9     Batch:  427  /  468     Loss_generator:  0.6681910753250122     Loss_discriminator:  0.6742641925811768\n",
      "Epoch:  9     Batch:  428  /  468     Loss_generator:  0.6916791200637817     Loss_discriminator:  0.6902856826782227\n",
      "Epoch:  9     Batch:  429  /  468     Loss_generator:  0.7346946001052856     Loss_discriminator:  0.6953059434890747\n",
      "Epoch:  9     Batch:  430  /  468     Loss_generator:  0.7222340106964111     Loss_discriminator:  0.688302755355835\n",
      "Epoch:  9     Batch:  431  /  468     Loss_generator:  0.7299747467041016     Loss_discriminator:  0.6893290281295776\n",
      "Epoch:  9     Batch:  432  /  468     Loss_generator:  0.7195440530776978     Loss_discriminator:  0.6831986308097839\n",
      "Epoch:  9     Batch:  433  /  468     Loss_generator:  0.7233503460884094     Loss_discriminator:  0.6819308400154114\n",
      "Epoch:  9     Batch:  434  /  468     Loss_generator:  0.6996844410896301     Loss_discriminator:  0.6842690706253052\n",
      "Epoch:  9     Batch:  435  /  468     Loss_generator:  0.6964689493179321     Loss_discriminator:  0.6963796019554138\n",
      "Epoch:  9     Batch:  436  /  468     Loss_generator:  0.6763607263565063     Loss_discriminator:  0.6882745623588562\n",
      "Epoch:  9     Batch:  437  /  468     Loss_generator:  0.6751430034637451     Loss_discriminator:  0.6819412708282471\n",
      "Epoch:  9     Batch:  438  /  468     Loss_generator:  0.702436089515686     Loss_discriminator:  0.6930338144302368\n",
      "Epoch:  9     Batch:  439  /  468     Loss_generator:  0.7239730358123779     Loss_discriminator:  0.6900343894958496\n",
      "Epoch:  9     Batch:  440  /  468     Loss_generator:  0.7400164604187012     Loss_discriminator:  0.676423192024231\n",
      "Epoch:  9     Batch:  441  /  468     Loss_generator:  0.7167397737503052     Loss_discriminator:  0.6851931810379028\n",
      "Epoch:  9     Batch:  442  /  468     Loss_generator:  0.6982011795043945     Loss_discriminator:  0.6894340515136719\n",
      "Epoch:  9     Batch:  443  /  468     Loss_generator:  0.6915407776832581     Loss_discriminator:  0.6969966292381287\n",
      "Epoch:  9     Batch:  444  /  468     Loss_generator:  0.6791549921035767     Loss_discriminator:  0.6902590990066528\n",
      "Epoch:  9     Batch:  445  /  468     Loss_generator:  0.6761203408241272     Loss_discriminator:  0.6820045709609985\n",
      "Epoch:  9     Batch:  446  /  468     Loss_generator:  0.7018673419952393     Loss_discriminator:  0.6796970963478088\n",
      "Epoch:  9     Batch:  447  /  468     Loss_generator:  0.6980483531951904     Loss_discriminator:  0.6802295446395874\n",
      "Epoch:  9     Batch:  448  /  468     Loss_generator:  0.7109721899032593     Loss_discriminator:  0.6927570700645447\n",
      "Epoch:  9     Batch:  449  /  468     Loss_generator:  0.707877516746521     Loss_discriminator:  0.6820353269577026\n",
      "Epoch:  9     Batch:  450  /  468     Loss_generator:  0.6984748840332031     Loss_discriminator:  0.6839231252670288\n",
      "Epoch:  9     Batch:  451  /  468     Loss_generator:  0.6896361112594604     Loss_discriminator:  0.692282497882843\n",
      "Epoch:  9     Batch:  452  /  468     Loss_generator:  0.7053432464599609     Loss_discriminator:  0.6868586540222168\n",
      "Epoch:  9     Batch:  453  /  468     Loss_generator:  0.7280184030532837     Loss_discriminator:  0.6874613165855408\n",
      "Epoch:  9     Batch:  454  /  468     Loss_generator:  0.7220677733421326     Loss_discriminator:  0.6822883486747742\n",
      "Epoch:  9     Batch:  455  /  468     Loss_generator:  0.7198584079742432     Loss_discriminator:  0.6828652024269104\n",
      "Epoch:  9     Batch:  456  /  468     Loss_generator:  0.7006928324699402     Loss_discriminator:  0.6870459318161011\n",
      "Epoch:  9     Batch:  457  /  468     Loss_generator:  0.6971334218978882     Loss_discriminator:  0.7086681127548218\n",
      "Epoch:  9     Batch:  458  /  468     Loss_generator:  0.6760222315788269     Loss_discriminator:  0.6784164905548096\n",
      "Epoch:  9     Batch:  459  /  468     Loss_generator:  0.6935871839523315     Loss_discriminator:  0.684180498123169\n",
      "Epoch:  9     Batch:  460  /  468     Loss_generator:  0.7274644374847412     Loss_discriminator:  0.6851969361305237\n",
      "Epoch:  9     Batch:  461  /  468     Loss_generator:  0.722710132598877     Loss_discriminator:  0.6882400512695312\n",
      "Epoch:  9     Batch:  462  /  468     Loss_generator:  0.724266767501831     Loss_discriminator:  0.6891582012176514\n",
      "Epoch:  9     Batch:  463  /  468     Loss_generator:  0.7280141115188599     Loss_discriminator:  0.6796682476997375\n",
      "Epoch:  9     Batch:  464  /  468     Loss_generator:  0.6963059902191162     Loss_discriminator:  0.6742845773696899\n",
      "Epoch:  9     Batch:  465  /  468     Loss_generator:  0.6820695400238037     Loss_discriminator:  0.6858218312263489\n",
      "Epoch:  9     Batch:  466  /  468     Loss_generator:  0.6757332682609558     Loss_discriminator:  0.6917542219161987\n",
      "Epoch:  9     Batch:  467  /  468     Loss_generator:  0.687924861907959     Loss_discriminator:  0.6985886693000793\n",
      "Epoch:  10     Batch:  0  /  468     Loss_generator:  0.7005786299705505     Loss_discriminator:  0.692575216293335\n",
      "Epoch:  10     Batch:  1  /  468     Loss_generator:  0.7134173512458801     Loss_discriminator:  0.6916602253913879\n",
      "Epoch:  10     Batch:  2  /  468     Loss_generator:  0.7153251767158508     Loss_discriminator:  0.6768872141838074\n",
      "Epoch:  10     Batch:  3  /  468     Loss_generator:  0.7115330696105957     Loss_discriminator:  0.6939257383346558\n",
      "Epoch:  10     Batch:  4  /  468     Loss_generator:  0.7384929656982422     Loss_discriminator:  0.6837359070777893\n",
      "Epoch:  10     Batch:  5  /  468     Loss_generator:  0.7523844242095947     Loss_discriminator:  0.6942067742347717\n",
      "Epoch:  10     Batch:  6  /  468     Loss_generator:  0.7454275488853455     Loss_discriminator:  0.6847105026245117\n",
      "Epoch:  10     Batch:  7  /  468     Loss_generator:  0.7020261883735657     Loss_discriminator:  0.6867057681083679\n",
      "Epoch:  10     Batch:  8  /  468     Loss_generator:  0.6617931127548218     Loss_discriminator:  0.7020866274833679\n",
      "Epoch:  10     Batch:  9  /  468     Loss_generator:  0.6544091701507568     Loss_discriminator:  0.688355565071106\n",
      "Epoch:  10     Batch:  10  /  468     Loss_generator:  0.6625437140464783     Loss_discriminator:  0.7003487944602966\n",
      "Epoch:  10     Batch:  11  /  468     Loss_generator:  0.6933251023292542     Loss_discriminator:  0.7078210115432739\n",
      "Epoch:  10     Batch:  12  /  468     Loss_generator:  0.7454665899276733     Loss_discriminator:  0.6848236322402954\n",
      "Epoch:  10     Batch:  13  /  468     Loss_generator:  0.7573660612106323     Loss_discriminator:  0.6783726215362549\n",
      "Epoch:  10     Batch:  14  /  468     Loss_generator:  0.7334723472595215     Loss_discriminator:  0.6869823932647705\n",
      "Epoch:  10     Batch:  15  /  468     Loss_generator:  0.706763505935669     Loss_discriminator:  0.6716878414154053\n",
      "Epoch:  10     Batch:  16  /  468     Loss_generator:  0.6922363638877869     Loss_discriminator:  0.6974444389343262\n",
      "Epoch:  10     Batch:  17  /  468     Loss_generator:  0.6702886819839478     Loss_discriminator:  0.6906270980834961\n",
      "Epoch:  10     Batch:  18  /  468     Loss_generator:  0.6994737386703491     Loss_discriminator:  0.6894278526306152\n",
      "Epoch:  10     Batch:  19  /  468     Loss_generator:  0.6832359433174133     Loss_discriminator:  0.6822031736373901\n",
      "Epoch:  10     Batch:  20  /  468     Loss_generator:  0.7150189280509949     Loss_discriminator:  0.6818870306015015\n",
      "Epoch:  10     Batch:  21  /  468     Loss_generator:  0.757768988609314     Loss_discriminator:  0.684572696685791\n",
      "Epoch:  10     Batch:  22  /  468     Loss_generator:  0.7560520172119141     Loss_discriminator:  0.6839702725410461\n",
      "Epoch:  10     Batch:  23  /  468     Loss_generator:  0.7486358284950256     Loss_discriminator:  0.696183443069458\n",
      "Epoch:  10     Batch:  24  /  468     Loss_generator:  0.7166618704795837     Loss_discriminator:  0.6891229748725891\n",
      "Epoch:  10     Batch:  25  /  468     Loss_generator:  0.6849761009216309     Loss_discriminator:  0.6865801811218262\n",
      "Epoch:  10     Batch:  26  /  468     Loss_generator:  0.6625477075576782     Loss_discriminator:  0.6919461488723755\n",
      "Epoch:  10     Batch:  27  /  468     Loss_generator:  0.6566175222396851     Loss_discriminator:  0.6852438449859619\n",
      "Epoch:  10     Batch:  28  /  468     Loss_generator:  0.6765482425689697     Loss_discriminator:  0.6870611906051636\n",
      "Epoch:  10     Batch:  29  /  468     Loss_generator:  0.7138379216194153     Loss_discriminator:  0.6857309937477112\n",
      "Epoch:  10     Batch:  30  /  468     Loss_generator:  0.7255215048789978     Loss_discriminator:  0.6903351545333862\n",
      "Epoch:  10     Batch:  31  /  468     Loss_generator:  0.7481096386909485     Loss_discriminator:  0.690199613571167\n",
      "Epoch:  10     Batch:  32  /  468     Loss_generator:  0.7280762791633606     Loss_discriminator:  0.6865458488464355\n",
      "Epoch:  10     Batch:  33  /  468     Loss_generator:  0.6971956491470337     Loss_discriminator:  0.6821606755256653\n",
      "Epoch:  10     Batch:  34  /  468     Loss_generator:  0.70339035987854     Loss_discriminator:  0.6907115578651428\n",
      "Epoch:  10     Batch:  35  /  468     Loss_generator:  0.7212116718292236     Loss_discriminator:  0.6752632856369019\n",
      "Epoch:  10     Batch:  36  /  468     Loss_generator:  0.7079321146011353     Loss_discriminator:  0.6780800819396973\n",
      "Epoch:  10     Batch:  37  /  468     Loss_generator:  0.7064950466156006     Loss_discriminator:  0.6878401041030884\n",
      "Epoch:  10     Batch:  38  /  468     Loss_generator:  0.7106701731681824     Loss_discriminator:  0.6817421913146973\n",
      "Epoch:  10     Batch:  39  /  468     Loss_generator:  0.6930553913116455     Loss_discriminator:  0.6980406045913696\n",
      "Epoch:  10     Batch:  40  /  468     Loss_generator:  0.6907579898834229     Loss_discriminator:  0.6755552887916565\n",
      "Epoch:  10     Batch:  41  /  468     Loss_generator:  0.7120869755744934     Loss_discriminator:  0.6828484535217285\n",
      "Epoch:  10     Batch:  42  /  468     Loss_generator:  0.7452651858329773     Loss_discriminator:  0.6873400211334229\n",
      "Epoch:  10     Batch:  43  /  468     Loss_generator:  0.7460084557533264     Loss_discriminator:  0.6836544275283813\n",
      "Epoch:  10     Batch:  44  /  468     Loss_generator:  0.7251054048538208     Loss_discriminator:  0.6864283084869385\n",
      "Epoch:  10     Batch:  45  /  468     Loss_generator:  0.6882627606391907     Loss_discriminator:  0.6943638324737549\n",
      "Epoch:  10     Batch:  46  /  468     Loss_generator:  0.6755735874176025     Loss_discriminator:  0.6755098104476929\n",
      "Epoch:  10     Batch:  47  /  468     Loss_generator:  0.6873216032981873     Loss_discriminator:  0.6850161552429199\n",
      "Epoch:  10     Batch:  48  /  468     Loss_generator:  0.6944483518600464     Loss_discriminator:  0.6947137713432312\n",
      "Epoch:  10     Batch:  49  /  468     Loss_generator:  0.7187533974647522     Loss_discriminator:  0.6864789724349976\n",
      "Epoch:  10     Batch:  50  /  468     Loss_generator:  0.7180261611938477     Loss_discriminator:  0.6855815052986145\n",
      "Epoch:  10     Batch:  51  /  468     Loss_generator:  0.7083320021629333     Loss_discriminator:  0.6851373314857483\n",
      "Epoch:  10     Batch:  52  /  468     Loss_generator:  0.7026879787445068     Loss_discriminator:  0.6769030094146729\n",
      "Epoch:  10     Batch:  53  /  468     Loss_generator:  0.7176868915557861     Loss_discriminator:  0.6877944469451904\n",
      "Epoch:  10     Batch:  54  /  468     Loss_generator:  0.7228509187698364     Loss_discriminator:  0.6907536387443542\n",
      "Epoch:  10     Batch:  55  /  468     Loss_generator:  0.7220181226730347     Loss_discriminator:  0.6705127358436584\n",
      "Epoch:  10     Batch:  56  /  468     Loss_generator:  0.7163188457489014     Loss_discriminator:  0.6782045364379883\n",
      "Epoch:  10     Batch:  57  /  468     Loss_generator:  0.7298677563667297     Loss_discriminator:  0.6801398992538452\n",
      "Epoch:  10     Batch:  58  /  468     Loss_generator:  0.714881956577301     Loss_discriminator:  0.6789177656173706\n",
      "Epoch:  10     Batch:  59  /  468     Loss_generator:  0.6925792694091797     Loss_discriminator:  0.6941278576850891\n",
      "Epoch:  10     Batch:  60  /  468     Loss_generator:  0.6673048138618469     Loss_discriminator:  0.6864205598831177\n",
      "Epoch:  10     Batch:  61  /  468     Loss_generator:  0.668941080570221     Loss_discriminator:  0.7040414214134216\n",
      "Epoch:  10     Batch:  62  /  468     Loss_generator:  0.6985881924629211     Loss_discriminator:  0.6875821352005005\n",
      "Epoch:  10     Batch:  63  /  468     Loss_generator:  0.7347213625907898     Loss_discriminator:  0.6872382164001465\n",
      "Epoch:  10     Batch:  64  /  468     Loss_generator:  0.7366726398468018     Loss_discriminator:  0.6786416172981262\n",
      "Epoch:  10     Batch:  65  /  468     Loss_generator:  0.7275055646896362     Loss_discriminator:  0.6871961951255798\n",
      "Epoch:  10     Batch:  66  /  468     Loss_generator:  0.7054916620254517     Loss_discriminator:  0.6797791719436646\n",
      "Epoch:  10     Batch:  67  /  468     Loss_generator:  0.7132403254508972     Loss_discriminator:  0.68678879737854\n",
      "Epoch:  10     Batch:  68  /  468     Loss_generator:  0.7026594877243042     Loss_discriminator:  0.6803593039512634\n",
      "Epoch:  10     Batch:  69  /  468     Loss_generator:  0.7054139375686646     Loss_discriminator:  0.6927738189697266\n",
      "Epoch:  10     Batch:  70  /  468     Loss_generator:  0.7030364871025085     Loss_discriminator:  0.6837853789329529\n",
      "Epoch:  10     Batch:  71  /  468     Loss_generator:  0.7037477493286133     Loss_discriminator:  0.6926169395446777\n",
      "Epoch:  10     Batch:  72  /  468     Loss_generator:  0.7050355672836304     Loss_discriminator:  0.6944273114204407\n",
      "Epoch:  10     Batch:  73  /  468     Loss_generator:  0.693564772605896     Loss_discriminator:  0.6770153045654297\n",
      "Epoch:  10     Batch:  74  /  468     Loss_generator:  0.7143455147743225     Loss_discriminator:  0.6886116862297058\n",
      "Epoch:  10     Batch:  75  /  468     Loss_generator:  0.7168453335762024     Loss_discriminator:  0.6910655498504639\n",
      "Epoch:  10     Batch:  76  /  468     Loss_generator:  0.7500074505805969     Loss_discriminator:  0.6927978992462158\n",
      "Epoch:  10     Batch:  77  /  468     Loss_generator:  0.7583576440811157     Loss_discriminator:  0.6844457387924194\n",
      "Epoch:  10     Batch:  78  /  468     Loss_generator:  0.7199074625968933     Loss_discriminator:  0.6962757706642151\n",
      "Epoch:  10     Batch:  79  /  468     Loss_generator:  0.6947954297065735     Loss_discriminator:  0.6932563185691833\n",
      "Epoch:  10     Batch:  80  /  468     Loss_generator:  0.67865389585495     Loss_discriminator:  0.684952437877655\n",
      "Epoch:  10     Batch:  81  /  468     Loss_generator:  0.6594482660293579     Loss_discriminator:  0.6853033304214478\n",
      "Epoch:  10     Batch:  82  /  468     Loss_generator:  0.6964192986488342     Loss_discriminator:  0.6856732368469238\n",
      "Epoch:  10     Batch:  83  /  468     Loss_generator:  0.7133170962333679     Loss_discriminator:  0.6801376938819885\n",
      "Epoch:  10     Batch:  84  /  468     Loss_generator:  0.7402327060699463     Loss_discriminator:  0.6844486594200134\n",
      "Epoch:  10     Batch:  85  /  468     Loss_generator:  0.7377132177352905     Loss_discriminator:  0.688501238822937\n",
      "Epoch:  10     Batch:  86  /  468     Loss_generator:  0.7213359475135803     Loss_discriminator:  0.6825692057609558\n",
      "Epoch:  10     Batch:  87  /  468     Loss_generator:  0.7317988872528076     Loss_discriminator:  0.6963911652565002\n",
      "Epoch:  10     Batch:  88  /  468     Loss_generator:  0.7277368307113647     Loss_discriminator:  0.6781232357025146\n",
      "Epoch:  10     Batch:  89  /  468     Loss_generator:  0.704249382019043     Loss_discriminator:  0.6833717823028564\n",
      "Epoch:  10     Batch:  90  /  468     Loss_generator:  0.6903259754180908     Loss_discriminator:  0.6819692254066467\n",
      "Epoch:  10     Batch:  91  /  468     Loss_generator:  0.693443775177002     Loss_discriminator:  0.6770594120025635\n",
      "Epoch:  10     Batch:  92  /  468     Loss_generator:  0.6974439024925232     Loss_discriminator:  0.680314302444458\n",
      "Epoch:  10     Batch:  93  /  468     Loss_generator:  0.6891947984695435     Loss_discriminator:  0.6811705827713013\n",
      "Epoch:  10     Batch:  94  /  468     Loss_generator:  0.6905784606933594     Loss_discriminator:  0.6851277947425842\n",
      "Epoch:  10     Batch:  95  /  468     Loss_generator:  0.7049980759620667     Loss_discriminator:  0.6826684474945068\n",
      "Epoch:  10     Batch:  96  /  468     Loss_generator:  0.7193531394004822     Loss_discriminator:  0.6946510076522827\n",
      "Epoch:  10     Batch:  97  /  468     Loss_generator:  0.7369526624679565     Loss_discriminator:  0.685905933380127\n",
      "Epoch:  10     Batch:  98  /  468     Loss_generator:  0.7400731444358826     Loss_discriminator:  0.6791712045669556\n",
      "Epoch:  10     Batch:  99  /  468     Loss_generator:  0.7254787087440491     Loss_discriminator:  0.6877661943435669\n",
      "Epoch:  10     Batch:  100  /  468     Loss_generator:  0.7251081466674805     Loss_discriminator:  0.6864413022994995\n",
      "Epoch:  10     Batch:  101  /  468     Loss_generator:  0.6924999952316284     Loss_discriminator:  0.6893861293792725\n",
      "Epoch:  10     Batch:  102  /  468     Loss_generator:  0.673260509967804     Loss_discriminator:  0.6785135269165039\n",
      "Epoch:  10     Batch:  103  /  468     Loss_generator:  0.6895253658294678     Loss_discriminator:  0.6908556818962097\n",
      "Epoch:  10     Batch:  104  /  468     Loss_generator:  0.7129715085029602     Loss_discriminator:  0.6823334693908691\n",
      "Epoch:  10     Batch:  105  /  468     Loss_generator:  0.7310166954994202     Loss_discriminator:  0.6832005381584167\n",
      "Epoch:  10     Batch:  106  /  468     Loss_generator:  0.7331637144088745     Loss_discriminator:  0.6808077096939087\n",
      "Epoch:  10     Batch:  107  /  468     Loss_generator:  0.7219516038894653     Loss_discriminator:  0.6831074953079224\n",
      "Epoch:  10     Batch:  108  /  468     Loss_generator:  0.6899534463882446     Loss_discriminator:  0.6675339937210083\n",
      "Epoch:  10     Batch:  109  /  468     Loss_generator:  0.6807135343551636     Loss_discriminator:  0.6884230971336365\n",
      "Epoch:  10     Batch:  110  /  468     Loss_generator:  0.7061302065849304     Loss_discriminator:  0.6777135133743286\n",
      "Epoch:  10     Batch:  111  /  468     Loss_generator:  0.7008552551269531     Loss_discriminator:  0.684963583946228\n",
      "Epoch:  10     Batch:  112  /  468     Loss_generator:  0.7001911401748657     Loss_discriminator:  0.6812626719474792\n",
      "Epoch:  10     Batch:  113  /  468     Loss_generator:  0.7188340425491333     Loss_discriminator:  0.6956169605255127\n",
      "Epoch:  10     Batch:  114  /  468     Loss_generator:  0.7345296144485474     Loss_discriminator:  0.6790246963500977\n",
      "Epoch:  10     Batch:  115  /  468     Loss_generator:  0.72892826795578     Loss_discriminator:  0.6909387707710266\n",
      "Epoch:  10     Batch:  116  /  468     Loss_generator:  0.7337004542350769     Loss_discriminator:  0.6864643096923828\n",
      "Epoch:  10     Batch:  117  /  468     Loss_generator:  0.7140474319458008     Loss_discriminator:  0.6774955987930298\n",
      "Epoch:  10     Batch:  118  /  468     Loss_generator:  0.71030592918396     Loss_discriminator:  0.6846470832824707\n",
      "Epoch:  10     Batch:  119  /  468     Loss_generator:  0.7024793028831482     Loss_discriminator:  0.6880008578300476\n",
      "Epoch:  10     Batch:  120  /  468     Loss_generator:  0.6972112655639648     Loss_discriminator:  0.6801502108573914\n",
      "Epoch:  10     Batch:  121  /  468     Loss_generator:  0.704267144203186     Loss_discriminator:  0.6948016285896301\n",
      "Epoch:  10     Batch:  122  /  468     Loss_generator:  0.6865975856781006     Loss_discriminator:  0.6774805784225464\n",
      "Epoch:  10     Batch:  123  /  468     Loss_generator:  0.7076998949050903     Loss_discriminator:  0.6838730573654175\n",
      "Epoch:  10     Batch:  124  /  468     Loss_generator:  0.6979504227638245     Loss_discriminator:  0.6918720602989197\n",
      "Epoch:  10     Batch:  125  /  468     Loss_generator:  0.6823761463165283     Loss_discriminator:  0.6895117163658142\n",
      "Epoch:  10     Batch:  126  /  468     Loss_generator:  0.7029994130134583     Loss_discriminator:  0.7004209160804749\n",
      "Epoch:  10     Batch:  127  /  468     Loss_generator:  0.7210940718650818     Loss_discriminator:  0.6852104067802429\n",
      "Epoch:  10     Batch:  128  /  468     Loss_generator:  0.712196946144104     Loss_discriminator:  0.6833231449127197\n",
      "Epoch:  10     Batch:  129  /  468     Loss_generator:  0.6875483393669128     Loss_discriminator:  0.689346432685852\n",
      "Epoch:  10     Batch:  130  /  468     Loss_generator:  0.6667861342430115     Loss_discriminator:  0.6884328126907349\n",
      "Epoch:  10     Batch:  131  /  468     Loss_generator:  0.6942281723022461     Loss_discriminator:  0.6988697052001953\n",
      "Epoch:  10     Batch:  132  /  468     Loss_generator:  0.7160382270812988     Loss_discriminator:  0.6885771751403809\n",
      "Epoch:  10     Batch:  133  /  468     Loss_generator:  0.7367835640907288     Loss_discriminator:  0.6831490993499756\n",
      "Epoch:  10     Batch:  134  /  468     Loss_generator:  0.7781697511672974     Loss_discriminator:  0.688778817653656\n",
      "Epoch:  10     Batch:  135  /  468     Loss_generator:  0.7319459319114685     Loss_discriminator:  0.6831641793251038\n",
      "Epoch:  10     Batch:  136  /  468     Loss_generator:  0.6750696897506714     Loss_discriminator:  0.6942088603973389\n",
      "Epoch:  10     Batch:  137  /  468     Loss_generator:  0.6557644009590149     Loss_discriminator:  0.687139630317688\n",
      "Epoch:  10     Batch:  138  /  468     Loss_generator:  0.6719529628753662     Loss_discriminator:  0.6864011883735657\n",
      "Epoch:  10     Batch:  139  /  468     Loss_generator:  0.6871294975280762     Loss_discriminator:  0.6773493885993958\n",
      "Epoch:  10     Batch:  140  /  468     Loss_generator:  0.6944746971130371     Loss_discriminator:  0.6762537360191345\n",
      "Epoch:  10     Batch:  141  /  468     Loss_generator:  0.7225615978240967     Loss_discriminator:  0.6802573204040527\n",
      "Epoch:  10     Batch:  142  /  468     Loss_generator:  0.7481282949447632     Loss_discriminator:  0.6813195943832397\n",
      "Epoch:  10     Batch:  143  /  468     Loss_generator:  0.7427839040756226     Loss_discriminator:  0.6935601234436035\n",
      "Epoch:  10     Batch:  144  /  468     Loss_generator:  0.7148916721343994     Loss_discriminator:  0.6918002367019653\n",
      "Epoch:  10     Batch:  145  /  468     Loss_generator:  0.702682375907898     Loss_discriminator:  0.6852223873138428\n",
      "Epoch:  10     Batch:  146  /  468     Loss_generator:  0.6950475573539734     Loss_discriminator:  0.6836031675338745\n",
      "Epoch:  10     Batch:  147  /  468     Loss_generator:  0.7051787376403809     Loss_discriminator:  0.6856005191802979\n",
      "Epoch:  10     Batch:  148  /  468     Loss_generator:  0.7116178870201111     Loss_discriminator:  0.685204029083252\n",
      "Epoch:  10     Batch:  149  /  468     Loss_generator:  0.7361482381820679     Loss_discriminator:  0.6955478191375732\n",
      "Epoch:  10     Batch:  150  /  468     Loss_generator:  0.7185027599334717     Loss_discriminator:  0.6898419857025146\n",
      "Epoch:  10     Batch:  151  /  468     Loss_generator:  0.7014777660369873     Loss_discriminator:  0.6822503209114075\n",
      "Epoch:  10     Batch:  152  /  468     Loss_generator:  0.7061259746551514     Loss_discriminator:  0.6773321032524109\n",
      "Epoch:  10     Batch:  153  /  468     Loss_generator:  0.6957243084907532     Loss_discriminator:  0.6866955757141113\n",
      "Epoch:  10     Batch:  154  /  468     Loss_generator:  0.7066279649734497     Loss_discriminator:  0.6885579824447632\n",
      "Epoch:  10     Batch:  155  /  468     Loss_generator:  0.7124234437942505     Loss_discriminator:  0.6788568496704102\n",
      "Epoch:  10     Batch:  156  /  468     Loss_generator:  0.7102556228637695     Loss_discriminator:  0.6943033337593079\n",
      "Epoch:  10     Batch:  157  /  468     Loss_generator:  0.7009532451629639     Loss_discriminator:  0.6883029937744141\n",
      "Epoch:  10     Batch:  158  /  468     Loss_generator:  0.7233445644378662     Loss_discriminator:  0.6832685470581055\n",
      "Epoch:  10     Batch:  159  /  468     Loss_generator:  0.7263410687446594     Loss_discriminator:  0.6840841770172119\n",
      "Epoch:  10     Batch:  160  /  468     Loss_generator:  0.7168586254119873     Loss_discriminator:  0.6859446167945862\n",
      "Epoch:  10     Batch:  161  /  468     Loss_generator:  0.7033087015151978     Loss_discriminator:  0.679425835609436\n",
      "Epoch:  10     Batch:  162  /  468     Loss_generator:  0.6795982718467712     Loss_discriminator:  0.6779748797416687\n",
      "Epoch:  10     Batch:  163  /  468     Loss_generator:  0.6734463572502136     Loss_discriminator:  0.6780577898025513\n",
      "Epoch:  10     Batch:  164  /  468     Loss_generator:  0.7120369672775269     Loss_discriminator:  0.688267707824707\n",
      "Epoch:  10     Batch:  165  /  468     Loss_generator:  0.7443380355834961     Loss_discriminator:  0.6893202066421509\n",
      "Epoch:  10     Batch:  166  /  468     Loss_generator:  0.7422220706939697     Loss_discriminator:  0.6798110008239746\n",
      "Epoch:  10     Batch:  167  /  468     Loss_generator:  0.7480595111846924     Loss_discriminator:  0.690757691860199\n",
      "Epoch:  10     Batch:  168  /  468     Loss_generator:  0.740119218826294     Loss_discriminator:  0.6976889371871948\n",
      "Epoch:  10     Batch:  169  /  468     Loss_generator:  0.6924508213996887     Loss_discriminator:  0.6898635625839233\n",
      "Epoch:  10     Batch:  170  /  468     Loss_generator:  0.6797236204147339     Loss_discriminator:  0.6805226802825928\n",
      "Epoch:  10     Batch:  171  /  468     Loss_generator:  0.6859163641929626     Loss_discriminator:  0.6974852085113525\n",
      "Epoch:  10     Batch:  172  /  468     Loss_generator:  0.6909303665161133     Loss_discriminator:  0.6804913282394409\n",
      "Epoch:  10     Batch:  173  /  468     Loss_generator:  0.7058781981468201     Loss_discriminator:  0.6837494373321533\n",
      "Epoch:  10     Batch:  174  /  468     Loss_generator:  0.7237823009490967     Loss_discriminator:  0.6845232248306274\n",
      "Epoch:  10     Batch:  175  /  468     Loss_generator:  0.7383211851119995     Loss_discriminator:  0.6952227354049683\n",
      "Epoch:  10     Batch:  176  /  468     Loss_generator:  0.7116919159889221     Loss_discriminator:  0.6707218885421753\n",
      "Epoch:  10     Batch:  177  /  468     Loss_generator:  0.6873601675033569     Loss_discriminator:  0.6847165822982788\n",
      "Epoch:  10     Batch:  178  /  468     Loss_generator:  0.6911506056785583     Loss_discriminator:  0.6790090799331665\n",
      "Epoch:  10     Batch:  179  /  468     Loss_generator:  0.679655909538269     Loss_discriminator:  0.6948873400688171\n",
      "Epoch:  10     Batch:  180  /  468     Loss_generator:  0.680457353591919     Loss_discriminator:  0.6917643547058105\n",
      "Epoch:  10     Batch:  181  /  468     Loss_generator:  0.711230993270874     Loss_discriminator:  0.6834685802459717\n",
      "Epoch:  10     Batch:  182  /  468     Loss_generator:  0.7436636090278625     Loss_discriminator:  0.6911666393280029\n",
      "Epoch:  10     Batch:  183  /  468     Loss_generator:  0.7293437123298645     Loss_discriminator:  0.6841295957565308\n",
      "Epoch:  10     Batch:  184  /  468     Loss_generator:  0.7286300659179688     Loss_discriminator:  0.6929579973220825\n",
      "Epoch:  10     Batch:  185  /  468     Loss_generator:  0.7086454033851624     Loss_discriminator:  0.68663090467453\n",
      "Epoch:  10     Batch:  186  /  468     Loss_generator:  0.6925413608551025     Loss_discriminator:  0.6888442039489746\n",
      "Epoch:  10     Batch:  187  /  468     Loss_generator:  0.673419713973999     Loss_discriminator:  0.682930052280426\n",
      "Epoch:  10     Batch:  188  /  468     Loss_generator:  0.6743925213813782     Loss_discriminator:  0.6938354969024658\n",
      "Epoch:  10     Batch:  189  /  468     Loss_generator:  0.7059584856033325     Loss_discriminator:  0.6832942366600037\n",
      "Epoch:  10     Batch:  190  /  468     Loss_generator:  0.7310714721679688     Loss_discriminator:  0.690159797668457\n",
      "Epoch:  10     Batch:  191  /  468     Loss_generator:  0.7540983557701111     Loss_discriminator:  0.6904130578041077\n",
      "Epoch:  10     Batch:  192  /  468     Loss_generator:  0.7345572710037231     Loss_discriminator:  0.6851209998130798\n",
      "Epoch:  10     Batch:  193  /  468     Loss_generator:  0.6823410987854004     Loss_discriminator:  0.6807507276535034\n",
      "Epoch:  10     Batch:  194  /  468     Loss_generator:  0.6603727340698242     Loss_discriminator:  0.6774348020553589\n",
      "Epoch:  10     Batch:  195  /  468     Loss_generator:  0.6574162244796753     Loss_discriminator:  0.6777467727661133\n",
      "Epoch:  10     Batch:  196  /  468     Loss_generator:  0.6854557991027832     Loss_discriminator:  0.6836029887199402\n",
      "Epoch:  10     Batch:  197  /  468     Loss_generator:  0.683112621307373     Loss_discriminator:  0.6810358762741089\n",
      "Epoch:  10     Batch:  198  /  468     Loss_generator:  0.7148302793502808     Loss_discriminator:  0.6760818958282471\n",
      "Epoch:  10     Batch:  199  /  468     Loss_generator:  0.7483543157577515     Loss_discriminator:  0.686061441898346\n",
      "Epoch:  10     Batch:  200  /  468     Loss_generator:  0.7292401790618896     Loss_discriminator:  0.6977157592773438\n",
      "Epoch:  10     Batch:  201  /  468     Loss_generator:  0.7343122363090515     Loss_discriminator:  0.6914989352226257\n",
      "Epoch:  10     Batch:  202  /  468     Loss_generator:  0.7207452654838562     Loss_discriminator:  0.6889897584915161\n",
      "Epoch:  10     Batch:  203  /  468     Loss_generator:  0.716181755065918     Loss_discriminator:  0.6813760995864868\n",
      "Epoch:  10     Batch:  204  /  468     Loss_generator:  0.6874240636825562     Loss_discriminator:  0.6862096786499023\n",
      "Epoch:  10     Batch:  205  /  468     Loss_generator:  0.6801565885543823     Loss_discriminator:  0.684572696685791\n",
      "Epoch:  10     Batch:  206  /  468     Loss_generator:  0.6647753715515137     Loss_discriminator:  0.6815899014472961\n",
      "Epoch:  10     Batch:  207  /  468     Loss_generator:  0.6759265661239624     Loss_discriminator:  0.6879895329475403\n",
      "Epoch:  10     Batch:  208  /  468     Loss_generator:  0.7021082639694214     Loss_discriminator:  0.6950934529304504\n",
      "Epoch:  10     Batch:  209  /  468     Loss_generator:  0.7495217323303223     Loss_discriminator:  0.6793711185455322\n",
      "Epoch:  10     Batch:  210  /  468     Loss_generator:  0.7425492405891418     Loss_discriminator:  0.6861386299133301\n",
      "Epoch:  10     Batch:  211  /  468     Loss_generator:  0.7102068662643433     Loss_discriminator:  0.6875784397125244\n",
      "Epoch:  10     Batch:  212  /  468     Loss_generator:  0.678772509098053     Loss_discriminator:  0.680168867111206\n",
      "Epoch:  10     Batch:  213  /  468     Loss_generator:  0.6583015322685242     Loss_discriminator:  0.6757022738456726\n",
      "Epoch:  10     Batch:  214  /  468     Loss_generator:  0.6744512915611267     Loss_discriminator:  0.6818229556083679\n",
      "Epoch:  10     Batch:  215  /  468     Loss_generator:  0.7328892946243286     Loss_discriminator:  0.6995357871055603\n",
      "Epoch:  10     Batch:  216  /  468     Loss_generator:  0.7772700786590576     Loss_discriminator:  0.6790115833282471\n",
      "Epoch:  10     Batch:  217  /  468     Loss_generator:  0.7871021032333374     Loss_discriminator:  0.6850780248641968\n",
      "Epoch:  10     Batch:  218  /  468     Loss_generator:  0.7485253810882568     Loss_discriminator:  0.6881902813911438\n",
      "Epoch:  10     Batch:  219  /  468     Loss_generator:  0.6867911219596863     Loss_discriminator:  0.6938251852989197\n",
      "Epoch:  10     Batch:  220  /  468     Loss_generator:  0.637192964553833     Loss_discriminator:  0.687781572341919\n",
      "Epoch:  10     Batch:  221  /  468     Loss_generator:  0.643499493598938     Loss_discriminator:  0.6913250088691711\n",
      "Epoch:  10     Batch:  222  /  468     Loss_generator:  0.6772279739379883     Loss_discriminator:  0.6818674802780151\n",
      "Epoch:  10     Batch:  223  /  468     Loss_generator:  0.7286785840988159     Loss_discriminator:  0.6853956580162048\n",
      "Epoch:  10     Batch:  224  /  468     Loss_generator:  0.7591085433959961     Loss_discriminator:  0.66936194896698\n",
      "Epoch:  10     Batch:  225  /  468     Loss_generator:  0.7474436163902283     Loss_discriminator:  0.6795675158500671\n",
      "Epoch:  10     Batch:  226  /  468     Loss_generator:  0.7145107388496399     Loss_discriminator:  0.6800137758255005\n",
      "Epoch:  10     Batch:  227  /  468     Loss_generator:  0.6935460567474365     Loss_discriminator:  0.6828793287277222\n",
      "Epoch:  10     Batch:  228  /  468     Loss_generator:  0.6713209748268127     Loss_discriminator:  0.6892343759536743\n",
      "Epoch:  10     Batch:  229  /  468     Loss_generator:  0.6734142899513245     Loss_discriminator:  0.690470278263092\n",
      "Epoch:  10     Batch:  230  /  468     Loss_generator:  0.6741043925285339     Loss_discriminator:  0.6871422529220581\n",
      "Epoch:  10     Batch:  231  /  468     Loss_generator:  0.7197383642196655     Loss_discriminator:  0.675470232963562\n",
      "Epoch:  10     Batch:  232  /  468     Loss_generator:  0.7617570161819458     Loss_discriminator:  0.6982002854347229\n",
      "Epoch:  10     Batch:  233  /  468     Loss_generator:  0.7738714814186096     Loss_discriminator:  0.6879948973655701\n",
      "Epoch:  10     Batch:  234  /  468     Loss_generator:  0.7297329306602478     Loss_discriminator:  0.6972487568855286\n",
      "Epoch:  10     Batch:  235  /  468     Loss_generator:  0.6976134777069092     Loss_discriminator:  0.6947363615036011\n",
      "Epoch:  10     Batch:  236  /  468     Loss_generator:  0.678722620010376     Loss_discriminator:  0.6853512525558472\n",
      "Epoch:  10     Batch:  237  /  468     Loss_generator:  0.6642435789108276     Loss_discriminator:  0.6792227029800415\n",
      "Epoch:  10     Batch:  238  /  468     Loss_generator:  0.6910314559936523     Loss_discriminator:  0.7008936405181885\n",
      "Epoch:  10     Batch:  239  /  468     Loss_generator:  0.732276439666748     Loss_discriminator:  0.6808063387870789\n",
      "Epoch:  10     Batch:  240  /  468     Loss_generator:  0.755043625831604     Loss_discriminator:  0.684544563293457\n",
      "Epoch:  10     Batch:  241  /  468     Loss_generator:  0.7276004552841187     Loss_discriminator:  0.6776156425476074\n",
      "Epoch:  10     Batch:  242  /  468     Loss_generator:  0.7395184636116028     Loss_discriminator:  0.6832478046417236\n",
      "Epoch:  10     Batch:  243  /  468     Loss_generator:  0.6996443867683411     Loss_discriminator:  0.693870484828949\n",
      "Epoch:  10     Batch:  244  /  468     Loss_generator:  0.6892458200454712     Loss_discriminator:  0.6814640760421753\n",
      "Epoch:  10     Batch:  245  /  468     Loss_generator:  0.6930299401283264     Loss_discriminator:  0.6925441026687622\n",
      "Epoch:  10     Batch:  246  /  468     Loss_generator:  0.6882143020629883     Loss_discriminator:  0.6805830001831055\n",
      "Epoch:  10     Batch:  247  /  468     Loss_generator:  0.7149902582168579     Loss_discriminator:  0.6941735744476318\n",
      "Epoch:  10     Batch:  248  /  468     Loss_generator:  0.7197180986404419     Loss_discriminator:  0.676594614982605\n",
      "Epoch:  10     Batch:  249  /  468     Loss_generator:  0.7028689980506897     Loss_discriminator:  0.6923612356185913\n",
      "Epoch:  10     Batch:  250  /  468     Loss_generator:  0.7009464502334595     Loss_discriminator:  0.6925070881843567\n",
      "Epoch:  10     Batch:  251  /  468     Loss_generator:  0.6993618011474609     Loss_discriminator:  0.6801611185073853\n",
      "Epoch:  10     Batch:  252  /  468     Loss_generator:  0.7167503237724304     Loss_discriminator:  0.6799622774124146\n",
      "Epoch:  10     Batch:  253  /  468     Loss_generator:  0.7354092001914978     Loss_discriminator:  0.6764898300170898\n",
      "Epoch:  10     Batch:  254  /  468     Loss_generator:  0.7317677736282349     Loss_discriminator:  0.6798555850982666\n",
      "Epoch:  10     Batch:  255  /  468     Loss_generator:  0.7364780306816101     Loss_discriminator:  0.6737803220748901\n",
      "Epoch:  10     Batch:  256  /  468     Loss_generator:  0.7080639600753784     Loss_discriminator:  0.6761739253997803\n",
      "Epoch:  10     Batch:  257  /  468     Loss_generator:  0.6845716238021851     Loss_discriminator:  0.6852761507034302\n",
      "Epoch:  10     Batch:  258  /  468     Loss_generator:  0.6793710589408875     Loss_discriminator:  0.6801145076751709\n",
      "Epoch:  10     Batch:  259  /  468     Loss_generator:  0.6763794422149658     Loss_discriminator:  0.6839011907577515\n",
      "Epoch:  10     Batch:  260  /  468     Loss_generator:  0.7109772562980652     Loss_discriminator:  0.7030529975891113\n",
      "Epoch:  10     Batch:  261  /  468     Loss_generator:  0.7409461736679077     Loss_discriminator:  0.6892644762992859\n",
      "Epoch:  10     Batch:  262  /  468     Loss_generator:  0.7784742116928101     Loss_discriminator:  0.6816010475158691\n",
      "Epoch:  10     Batch:  263  /  468     Loss_generator:  0.7740647196769714     Loss_discriminator:  0.6892591714859009\n",
      "Epoch:  10     Batch:  264  /  468     Loss_generator:  0.7205053567886353     Loss_discriminator:  0.6930698156356812\n",
      "Epoch:  10     Batch:  265  /  468     Loss_generator:  0.65416419506073     Loss_discriminator:  0.7056966423988342\n",
      "Epoch:  10     Batch:  266  /  468     Loss_generator:  0.6331527233123779     Loss_discriminator:  0.6918889880180359\n",
      "Epoch:  10     Batch:  267  /  468     Loss_generator:  0.6510827541351318     Loss_discriminator:  0.6861457824707031\n",
      "Epoch:  10     Batch:  268  /  468     Loss_generator:  0.686698853969574     Loss_discriminator:  0.6869151592254639\n",
      "Epoch:  10     Batch:  269  /  468     Loss_generator:  0.7390729784965515     Loss_discriminator:  0.6863738298416138\n",
      "Epoch:  10     Batch:  270  /  468     Loss_generator:  0.7734394073486328     Loss_discriminator:  0.6831505298614502\n",
      "Epoch:  10     Batch:  271  /  468     Loss_generator:  0.7987903356552124     Loss_discriminator:  0.6911798119544983\n",
      "Epoch:  10     Batch:  272  /  468     Loss_generator:  0.7569453716278076     Loss_discriminator:  0.6978397965431213\n",
      "Epoch:  10     Batch:  273  /  468     Loss_generator:  0.705844521522522     Loss_discriminator:  0.6865833401679993\n",
      "Epoch:  10     Batch:  274  /  468     Loss_generator:  0.6727898120880127     Loss_discriminator:  0.6842354536056519\n",
      "Epoch:  10     Batch:  275  /  468     Loss_generator:  0.6657582521438599     Loss_discriminator:  0.6860839128494263\n",
      "Epoch:  10     Batch:  276  /  468     Loss_generator:  0.6600106358528137     Loss_discriminator:  0.6853840351104736\n",
      "Epoch:  10     Batch:  277  /  468     Loss_generator:  0.6703695058822632     Loss_discriminator:  0.6777488589286804\n",
      "Epoch:  10     Batch:  278  /  468     Loss_generator:  0.7321357727050781     Loss_discriminator:  0.6787277460098267\n",
      "Epoch:  10     Batch:  279  /  468     Loss_generator:  0.798012375831604     Loss_discriminator:  0.6962733864784241\n",
      "Epoch:  10     Batch:  280  /  468     Loss_generator:  0.8066205978393555     Loss_discriminator:  0.6876041889190674\n",
      "Epoch:  10     Batch:  281  /  468     Loss_generator:  0.7462980151176453     Loss_discriminator:  0.6883479952812195\n",
      "Epoch:  10     Batch:  282  /  468     Loss_generator:  0.6984211802482605     Loss_discriminator:  0.6915451288223267\n",
      "Epoch:  10     Batch:  283  /  468     Loss_generator:  0.6680521965026855     Loss_discriminator:  0.6881557703018188\n",
      "Epoch:  10     Batch:  284  /  468     Loss_generator:  0.6430519819259644     Loss_discriminator:  0.6884130239486694\n",
      "Epoch:  10     Batch:  285  /  468     Loss_generator:  0.6576542854309082     Loss_discriminator:  0.6914394497871399\n",
      "Epoch:  10     Batch:  286  /  468     Loss_generator:  0.6819612383842468     Loss_discriminator:  0.6855925917625427\n",
      "Epoch:  10     Batch:  287  /  468     Loss_generator:  0.7493937015533447     Loss_discriminator:  0.6939986348152161\n",
      "Epoch:  10     Batch:  288  /  468     Loss_generator:  0.7700315117835999     Loss_discriminator:  0.6960445642471313\n",
      "Epoch:  10     Batch:  289  /  468     Loss_generator:  0.7602634429931641     Loss_discriminator:  0.6785827875137329\n",
      "Epoch:  10     Batch:  290  /  468     Loss_generator:  0.7391934394836426     Loss_discriminator:  0.6875102519989014\n",
      "Epoch:  10     Batch:  291  /  468     Loss_generator:  0.6851059198379517     Loss_discriminator:  0.6961703896522522\n",
      "Epoch:  10     Batch:  292  /  468     Loss_generator:  0.6689996719360352     Loss_discriminator:  0.6723344326019287\n",
      "Epoch:  10     Batch:  293  /  468     Loss_generator:  0.6410917043685913     Loss_discriminator:  0.677208662033081\n",
      "Epoch:  10     Batch:  294  /  468     Loss_generator:  0.6520529985427856     Loss_discriminator:  0.6962203979492188\n",
      "Epoch:  10     Batch:  295  /  468     Loss_generator:  0.7119641304016113     Loss_discriminator:  0.683069109916687\n",
      "Epoch:  10     Batch:  296  /  468     Loss_generator:  0.7598883509635925     Loss_discriminator:  0.6914815902709961\n",
      "Epoch:  10     Batch:  297  /  468     Loss_generator:  0.7588322758674622     Loss_discriminator:  0.6879661679267883\n",
      "Epoch:  10     Batch:  298  /  468     Loss_generator:  0.7300574779510498     Loss_discriminator:  0.6923307180404663\n",
      "Epoch:  10     Batch:  299  /  468     Loss_generator:  0.7065027952194214     Loss_discriminator:  0.6837734580039978\n",
      "Epoch:  10     Batch:  300  /  468     Loss_generator:  0.6779620051383972     Loss_discriminator:  0.6920173168182373\n",
      "Epoch:  10     Batch:  301  /  468     Loss_generator:  0.6637435555458069     Loss_discriminator:  0.6798737049102783\n",
      "Epoch:  10     Batch:  302  /  468     Loss_generator:  0.6692185401916504     Loss_discriminator:  0.6924096345901489\n",
      "Epoch:  10     Batch:  303  /  468     Loss_generator:  0.6848609447479248     Loss_discriminator:  0.6883907914161682\n",
      "Epoch:  10     Batch:  304  /  468     Loss_generator:  0.7255947589874268     Loss_discriminator:  0.6830340623855591\n",
      "Epoch:  10     Batch:  305  /  468     Loss_generator:  0.7619591951370239     Loss_discriminator:  0.6887500286102295\n",
      "Epoch:  10     Batch:  306  /  468     Loss_generator:  0.7382849454879761     Loss_discriminator:  0.6908630728721619\n",
      "Epoch:  10     Batch:  307  /  468     Loss_generator:  0.7168980836868286     Loss_discriminator:  0.6821240782737732\n",
      "Epoch:  10     Batch:  308  /  468     Loss_generator:  0.689790666103363     Loss_discriminator:  0.6813347339630127\n",
      "Epoch:  10     Batch:  309  /  468     Loss_generator:  0.6812390685081482     Loss_discriminator:  0.6834770441055298\n",
      "Epoch:  10     Batch:  310  /  468     Loss_generator:  0.7052416801452637     Loss_discriminator:  0.6883463263511658\n",
      "Epoch:  10     Batch:  311  /  468     Loss_generator:  0.7288180589675903     Loss_discriminator:  0.676339864730835\n",
      "Epoch:  10     Batch:  312  /  468     Loss_generator:  0.7226843237876892     Loss_discriminator:  0.6912930607795715\n",
      "Epoch:  10     Batch:  313  /  468     Loss_generator:  0.7345461249351501     Loss_discriminator:  0.6853017807006836\n",
      "Epoch:  10     Batch:  314  /  468     Loss_generator:  0.7323519587516785     Loss_discriminator:  0.7008557319641113\n",
      "Epoch:  10     Batch:  315  /  468     Loss_generator:  0.6850982904434204     Loss_discriminator:  0.6846557855606079\n",
      "Epoch:  10     Batch:  316  /  468     Loss_generator:  0.6694440841674805     Loss_discriminator:  0.6762944459915161\n",
      "Epoch:  10     Batch:  317  /  468     Loss_generator:  0.6897798776626587     Loss_discriminator:  0.6813899278640747\n",
      "Epoch:  10     Batch:  318  /  468     Loss_generator:  0.7134922742843628     Loss_discriminator:  0.6901311874389648\n",
      "Epoch:  10     Batch:  319  /  468     Loss_generator:  0.7389233112335205     Loss_discriminator:  0.6771027445793152\n",
      "Epoch:  10     Batch:  320  /  468     Loss_generator:  0.728466272354126     Loss_discriminator:  0.6936705112457275\n",
      "Epoch:  10     Batch:  321  /  468     Loss_generator:  0.7108221054077148     Loss_discriminator:  0.6854325532913208\n",
      "Epoch:  10     Batch:  322  /  468     Loss_generator:  0.6702438592910767     Loss_discriminator:  0.681719958782196\n",
      "Epoch:  10     Batch:  323  /  468     Loss_generator:  0.6640477180480957     Loss_discriminator:  0.6932797431945801\n",
      "Epoch:  10     Batch:  324  /  468     Loss_generator:  0.6840125918388367     Loss_discriminator:  0.6850139498710632\n",
      "Epoch:  10     Batch:  325  /  468     Loss_generator:  0.7188012003898621     Loss_discriminator:  0.6842286586761475\n",
      "Epoch:  10     Batch:  326  /  468     Loss_generator:  0.7317055463790894     Loss_discriminator:  0.6937096118927002\n",
      "Epoch:  10     Batch:  327  /  468     Loss_generator:  0.7160433530807495     Loss_discriminator:  0.6805555820465088\n",
      "Epoch:  10     Batch:  328  /  468     Loss_generator:  0.692615807056427     Loss_discriminator:  0.6815193295478821\n",
      "Epoch:  10     Batch:  329  /  468     Loss_generator:  0.7058137655258179     Loss_discriminator:  0.6897530555725098\n",
      "Epoch:  10     Batch:  330  /  468     Loss_generator:  0.6894557476043701     Loss_discriminator:  0.6946983933448792\n",
      "Epoch:  10     Batch:  331  /  468     Loss_generator:  0.6963976621627808     Loss_discriminator:  0.6827096939086914\n",
      "Epoch:  10     Batch:  332  /  468     Loss_generator:  0.6834261417388916     Loss_discriminator:  0.6857210397720337\n",
      "Epoch:  10     Batch:  333  /  468     Loss_generator:  0.7050195932388306     Loss_discriminator:  0.7041815519332886\n",
      "Epoch:  10     Batch:  334  /  468     Loss_generator:  0.7284382581710815     Loss_discriminator:  0.6968845129013062\n",
      "Epoch:  10     Batch:  335  /  468     Loss_generator:  0.7426450252532959     Loss_discriminator:  0.6912646889686584\n",
      "Epoch:  10     Batch:  336  /  468     Loss_generator:  0.7235738039016724     Loss_discriminator:  0.6942171454429626\n",
      "Epoch:  10     Batch:  337  /  468     Loss_generator:  0.700182318687439     Loss_discriminator:  0.6979340314865112\n",
      "Epoch:  10     Batch:  338  /  468     Loss_generator:  0.6822314262390137     Loss_discriminator:  0.6783435344696045\n",
      "Epoch:  10     Batch:  339  /  468     Loss_generator:  0.6707091927528381     Loss_discriminator:  0.6926199197769165\n",
      "Epoch:  10     Batch:  340  /  468     Loss_generator:  0.6737211346626282     Loss_discriminator:  0.6777635812759399\n",
      "Epoch:  10     Batch:  341  /  468     Loss_generator:  0.6982975006103516     Loss_discriminator:  0.6864781975746155\n",
      "Epoch:  10     Batch:  342  /  468     Loss_generator:  0.7177590131759644     Loss_discriminator:  0.6927808523178101\n",
      "Epoch:  10     Batch:  343  /  468     Loss_generator:  0.7281603217124939     Loss_discriminator:  0.6956477761268616\n",
      "Epoch:  10     Batch:  344  /  468     Loss_generator:  0.7086532115936279     Loss_discriminator:  0.6961977481842041\n",
      "Epoch:  10     Batch:  345  /  468     Loss_generator:  0.7065814733505249     Loss_discriminator:  0.6829679012298584\n",
      "Epoch:  10     Batch:  346  /  468     Loss_generator:  0.6986280679702759     Loss_discriminator:  0.6912730932235718\n",
      "Epoch:  10     Batch:  347  /  468     Loss_generator:  0.6787259578704834     Loss_discriminator:  0.683030366897583\n",
      "Epoch:  10     Batch:  348  /  468     Loss_generator:  0.6824800968170166     Loss_discriminator:  0.6881663799285889\n",
      "Epoch:  10     Batch:  349  /  468     Loss_generator:  0.6986125111579895     Loss_discriminator:  0.6901106238365173\n",
      "Epoch:  10     Batch:  350  /  468     Loss_generator:  0.754568338394165     Loss_discriminator:  0.6829179525375366\n",
      "Epoch:  10     Batch:  351  /  468     Loss_generator:  0.7305243015289307     Loss_discriminator:  0.6854878664016724\n",
      "Epoch:  10     Batch:  352  /  468     Loss_generator:  0.7218597531318665     Loss_discriminator:  0.6920737624168396\n",
      "Epoch:  10     Batch:  353  /  468     Loss_generator:  0.711866557598114     Loss_discriminator:  0.6828848123550415\n",
      "Epoch:  10     Batch:  354  /  468     Loss_generator:  0.7057934403419495     Loss_discriminator:  0.6847840547561646\n",
      "Epoch:  10     Batch:  355  /  468     Loss_generator:  0.7056935429573059     Loss_discriminator:  0.6842966079711914\n",
      "Epoch:  10     Batch:  356  /  468     Loss_generator:  0.7281121015548706     Loss_discriminator:  0.6840083003044128\n",
      "Epoch:  10     Batch:  357  /  468     Loss_generator:  0.7225911617279053     Loss_discriminator:  0.6875423789024353\n",
      "Epoch:  10     Batch:  358  /  468     Loss_generator:  0.7000439167022705     Loss_discriminator:  0.67241370677948\n",
      "Epoch:  10     Batch:  359  /  468     Loss_generator:  0.6778855323791504     Loss_discriminator:  0.6861885190010071\n",
      "Epoch:  10     Batch:  360  /  468     Loss_generator:  0.66584312915802     Loss_discriminator:  0.6792453527450562\n",
      "Epoch:  10     Batch:  361  /  468     Loss_generator:  0.6872907280921936     Loss_discriminator:  0.6960078477859497\n",
      "Epoch:  10     Batch:  362  /  468     Loss_generator:  0.7104955911636353     Loss_discriminator:  0.6766529083251953\n",
      "Epoch:  10     Batch:  363  /  468     Loss_generator:  0.7354951500892639     Loss_discriminator:  0.6831081509590149\n",
      "Epoch:  10     Batch:  364  /  468     Loss_generator:  0.7356648445129395     Loss_discriminator:  0.6968342065811157\n",
      "Epoch:  10     Batch:  365  /  468     Loss_generator:  0.7424055337905884     Loss_discriminator:  0.6880676746368408\n",
      "Epoch:  10     Batch:  366  /  468     Loss_generator:  0.7114046812057495     Loss_discriminator:  0.70295250415802\n",
      "Epoch:  10     Batch:  367  /  468     Loss_generator:  0.6837785840034485     Loss_discriminator:  0.6845188736915588\n",
      "Epoch:  10     Batch:  368  /  468     Loss_generator:  0.6854698657989502     Loss_discriminator:  0.6816323399543762\n",
      "Epoch:  10     Batch:  369  /  468     Loss_generator:  0.677158534526825     Loss_discriminator:  0.6850086450576782\n",
      "Epoch:  10     Batch:  370  /  468     Loss_generator:  0.6972172856330872     Loss_discriminator:  0.69273841381073\n",
      "Epoch:  10     Batch:  371  /  468     Loss_generator:  0.733756422996521     Loss_discriminator:  0.6870375275611877\n",
      "Epoch:  10     Batch:  372  /  468     Loss_generator:  0.7419602870941162     Loss_discriminator:  0.6791563034057617\n",
      "Epoch:  10     Batch:  373  /  468     Loss_generator:  0.717129111289978     Loss_discriminator:  0.6906766295433044\n",
      "Epoch:  10     Batch:  374  /  468     Loss_generator:  0.7124252915382385     Loss_discriminator:  0.6701587438583374\n",
      "Epoch:  10     Batch:  375  /  468     Loss_generator:  0.6856216788291931     Loss_discriminator:  0.6826599836349487\n",
      "Epoch:  10     Batch:  376  /  468     Loss_generator:  0.7036652565002441     Loss_discriminator:  0.6912126541137695\n",
      "Epoch:  10     Batch:  377  /  468     Loss_generator:  0.7125632166862488     Loss_discriminator:  0.6797102093696594\n",
      "Epoch:  10     Batch:  378  /  468     Loss_generator:  0.7189311981201172     Loss_discriminator:  0.6937040090560913\n",
      "Epoch:  10     Batch:  379  /  468     Loss_generator:  0.7452925443649292     Loss_discriminator:  0.6866945028305054\n",
      "Epoch:  10     Batch:  380  /  468     Loss_generator:  0.7156033515930176     Loss_discriminator:  0.6759130954742432\n",
      "Epoch:  10     Batch:  381  /  468     Loss_generator:  0.7089673280715942     Loss_discriminator:  0.6898261904716492\n",
      "Epoch:  10     Batch:  382  /  468     Loss_generator:  0.6867115497589111     Loss_discriminator:  0.6864524483680725\n",
      "Epoch:  10     Batch:  383  /  468     Loss_generator:  0.7117599248886108     Loss_discriminator:  0.6730753779411316\n",
      "Epoch:  10     Batch:  384  /  468     Loss_generator:  0.7127851247787476     Loss_discriminator:  0.6887047290802002\n",
      "Epoch:  10     Batch:  385  /  468     Loss_generator:  0.7028640508651733     Loss_discriminator:  0.692985475063324\n",
      "Epoch:  10     Batch:  386  /  468     Loss_generator:  0.7029107809066772     Loss_discriminator:  0.690200924873352\n",
      "Epoch:  10     Batch:  387  /  468     Loss_generator:  0.6886036992073059     Loss_discriminator:  0.6814005374908447\n",
      "Epoch:  10     Batch:  388  /  468     Loss_generator:  0.6888103485107422     Loss_discriminator:  0.694471001625061\n",
      "Epoch:  10     Batch:  389  /  468     Loss_generator:  0.6874071955680847     Loss_discriminator:  0.6875832676887512\n",
      "Epoch:  10     Batch:  390  /  468     Loss_generator:  0.7110334634780884     Loss_discriminator:  0.6957141757011414\n",
      "Epoch:  10     Batch:  391  /  468     Loss_generator:  0.7282773852348328     Loss_discriminator:  0.6892668604850769\n",
      "Epoch:  10     Batch:  392  /  468     Loss_generator:  0.7475035190582275     Loss_discriminator:  0.6737995147705078\n",
      "Epoch:  10     Batch:  393  /  468     Loss_generator:  0.704993724822998     Loss_discriminator:  0.6825066804885864\n",
      "Epoch:  10     Batch:  394  /  468     Loss_generator:  0.6917864084243774     Loss_discriminator:  0.691787838935852\n",
      "Epoch:  10     Batch:  395  /  468     Loss_generator:  0.6735867857933044     Loss_discriminator:  0.6845711469650269\n",
      "Epoch:  10     Batch:  396  /  468     Loss_generator:  0.676554799079895     Loss_discriminator:  0.6855684518814087\n",
      "Epoch:  10     Batch:  397  /  468     Loss_generator:  0.7133342623710632     Loss_discriminator:  0.6934797763824463\n",
      "Epoch:  10     Batch:  398  /  468     Loss_generator:  0.6948480010032654     Loss_discriminator:  0.6749268174171448\n",
      "Epoch:  10     Batch:  399  /  468     Loss_generator:  0.7051364183425903     Loss_discriminator:  0.6675344705581665\n",
      "Epoch:  10     Batch:  400  /  468     Loss_generator:  0.7252447605133057     Loss_discriminator:  0.6943775415420532\n",
      "Epoch:  10     Batch:  401  /  468     Loss_generator:  0.7402783632278442     Loss_discriminator:  0.6905417442321777\n",
      "Epoch:  10     Batch:  402  /  468     Loss_generator:  0.7013751268386841     Loss_discriminator:  0.6922913789749146\n",
      "Epoch:  10     Batch:  403  /  468     Loss_generator:  0.6907002329826355     Loss_discriminator:  0.678081750869751\n",
      "Epoch:  10     Batch:  404  /  468     Loss_generator:  0.6970043182373047     Loss_discriminator:  0.6792672872543335\n",
      "Epoch:  10     Batch:  405  /  468     Loss_generator:  0.698879599571228     Loss_discriminator:  0.6824366450309753\n",
      "Epoch:  10     Batch:  406  /  468     Loss_generator:  0.6936556696891785     Loss_discriminator:  0.6928023099899292\n",
      "Epoch:  10     Batch:  407  /  468     Loss_generator:  0.7000812292098999     Loss_discriminator:  0.6848697662353516\n",
      "Epoch:  10     Batch:  408  /  468     Loss_generator:  0.7141146063804626     Loss_discriminator:  0.6862265467643738\n",
      "Epoch:  10     Batch:  409  /  468     Loss_generator:  0.6922913193702698     Loss_discriminator:  0.6750222444534302\n",
      "Epoch:  10     Batch:  410  /  468     Loss_generator:  0.6904450058937073     Loss_discriminator:  0.691195011138916\n",
      "Epoch:  10     Batch:  411  /  468     Loss_generator:  0.6779475212097168     Loss_discriminator:  0.6767948865890503\n",
      "Epoch:  10     Batch:  412  /  468     Loss_generator:  0.7061177492141724     Loss_discriminator:  0.6807966232299805\n",
      "Epoch:  10     Batch:  413  /  468     Loss_generator:  0.749404788017273     Loss_discriminator:  0.6834873557090759\n",
      "Epoch:  10     Batch:  414  /  468     Loss_generator:  0.7718278169631958     Loss_discriminator:  0.6936031579971313\n",
      "Epoch:  10     Batch:  415  /  468     Loss_generator:  0.7308098077774048     Loss_discriminator:  0.6880279779434204\n",
      "Epoch:  10     Batch:  416  /  468     Loss_generator:  0.6915547847747803     Loss_discriminator:  0.6962857246398926\n",
      "Epoch:  10     Batch:  417  /  468     Loss_generator:  0.6596442461013794     Loss_discriminator:  0.6784331202507019\n",
      "Epoch:  10     Batch:  418  /  468     Loss_generator:  0.6564524173736572     Loss_discriminator:  0.6871418356895447\n",
      "Epoch:  10     Batch:  419  /  468     Loss_generator:  0.6583773493766785     Loss_discriminator:  0.6790492534637451\n",
      "Epoch:  10     Batch:  420  /  468     Loss_generator:  0.7086585164070129     Loss_discriminator:  0.6901578307151794\n",
      "Epoch:  10     Batch:  421  /  468     Loss_generator:  0.7368189096450806     Loss_discriminator:  0.6906000375747681\n",
      "Epoch:  10     Batch:  422  /  468     Loss_generator:  0.7085950970649719     Loss_discriminator:  0.6942262053489685\n",
      "Epoch:  10     Batch:  423  /  468     Loss_generator:  0.7181251049041748     Loss_discriminator:  0.6894437670707703\n",
      "Epoch:  10     Batch:  424  /  468     Loss_generator:  0.7056711912155151     Loss_discriminator:  0.6887995600700378\n",
      "Epoch:  10     Batch:  425  /  468     Loss_generator:  0.6990983486175537     Loss_discriminator:  0.6881940960884094\n",
      "Epoch:  10     Batch:  426  /  468     Loss_generator:  0.6740837097167969     Loss_discriminator:  0.6793063879013062\n",
      "Epoch:  10     Batch:  427  /  468     Loss_generator:  0.6971480846405029     Loss_discriminator:  0.6817759275436401\n",
      "Epoch:  10     Batch:  428  /  468     Loss_generator:  0.7059741020202637     Loss_discriminator:  0.6914218068122864\n",
      "Epoch:  10     Batch:  429  /  468     Loss_generator:  0.7118805646896362     Loss_discriminator:  0.6823245882987976\n",
      "Epoch:  10     Batch:  430  /  468     Loss_generator:  0.7244370579719543     Loss_discriminator:  0.6871239542961121\n",
      "Epoch:  10     Batch:  431  /  468     Loss_generator:  0.7258062958717346     Loss_discriminator:  0.6956378221511841\n",
      "Epoch:  10     Batch:  432  /  468     Loss_generator:  0.7099049091339111     Loss_discriminator:  0.6804894804954529\n",
      "Epoch:  10     Batch:  433  /  468     Loss_generator:  0.6751663088798523     Loss_discriminator:  0.6937792301177979\n",
      "Epoch:  10     Batch:  434  /  468     Loss_generator:  0.6559655666351318     Loss_discriminator:  0.6961964964866638\n",
      "Epoch:  10     Batch:  435  /  468     Loss_generator:  0.6904199719429016     Loss_discriminator:  0.6927409768104553\n",
      "Epoch:  10     Batch:  436  /  468     Loss_generator:  0.7058649063110352     Loss_discriminator:  0.6729831695556641\n",
      "Epoch:  10     Batch:  437  /  468     Loss_generator:  0.7324769496917725     Loss_discriminator:  0.6861369609832764\n",
      "Epoch:  10     Batch:  438  /  468     Loss_generator:  0.7481915950775146     Loss_discriminator:  0.6896048784255981\n",
      "Epoch:  10     Batch:  439  /  468     Loss_generator:  0.7366195321083069     Loss_discriminator:  0.6706643104553223\n",
      "Epoch:  10     Batch:  440  /  468     Loss_generator:  0.7114678621292114     Loss_discriminator:  0.6741748452186584\n",
      "Epoch:  10     Batch:  441  /  468     Loss_generator:  0.6983279585838318     Loss_discriminator:  0.7006512880325317\n",
      "Epoch:  10     Batch:  442  /  468     Loss_generator:  0.68903648853302     Loss_discriminator:  0.6898456811904907\n",
      "Epoch:  10     Batch:  443  /  468     Loss_generator:  0.6913857460021973     Loss_discriminator:  0.6794975399971008\n",
      "Epoch:  10     Batch:  444  /  468     Loss_generator:  0.6874213814735413     Loss_discriminator:  0.6844003200531006\n",
      "Epoch:  10     Batch:  445  /  468     Loss_generator:  0.6852282285690308     Loss_discriminator:  0.6909948587417603\n",
      "Epoch:  10     Batch:  446  /  468     Loss_generator:  0.7037680149078369     Loss_discriminator:  0.6860836744308472\n",
      "Epoch:  10     Batch:  447  /  468     Loss_generator:  0.7492235898971558     Loss_discriminator:  0.6832351088523865\n",
      "Epoch:  10     Batch:  448  /  468     Loss_generator:  0.7959957718849182     Loss_discriminator:  0.6835129261016846\n",
      "Epoch:  10     Batch:  449  /  468     Loss_generator:  0.774407148361206     Loss_discriminator:  0.6935350894927979\n",
      "Epoch:  10     Batch:  450  /  468     Loss_generator:  0.7129305601119995     Loss_discriminator:  0.6942089200019836\n",
      "Epoch:  10     Batch:  451  /  468     Loss_generator:  0.6688979864120483     Loss_discriminator:  0.6788012385368347\n",
      "Epoch:  10     Batch:  452  /  468     Loss_generator:  0.652999758720398     Loss_discriminator:  0.6838233470916748\n",
      "Epoch:  10     Batch:  453  /  468     Loss_generator:  0.6554524302482605     Loss_discriminator:  0.6932520866394043\n",
      "Epoch:  10     Batch:  454  /  468     Loss_generator:  0.6859264373779297     Loss_discriminator:  0.6870714426040649\n",
      "Epoch:  10     Batch:  455  /  468     Loss_generator:  0.7658987045288086     Loss_discriminator:  0.6727782487869263\n",
      "Epoch:  10     Batch:  456  /  468     Loss_generator:  0.7703185677528381     Loss_discriminator:  0.678774356842041\n",
      "Epoch:  10     Batch:  457  /  468     Loss_generator:  0.7665171027183533     Loss_discriminator:  0.6865329146385193\n",
      "Epoch:  10     Batch:  458  /  468     Loss_generator:  0.7303711175918579     Loss_discriminator:  0.6809319257736206\n",
      "Epoch:  10     Batch:  459  /  468     Loss_generator:  0.6837024092674255     Loss_discriminator:  0.6890160441398621\n",
      "Epoch:  10     Batch:  460  /  468     Loss_generator:  0.6574814319610596     Loss_discriminator:  0.6939724087715149\n",
      "Epoch:  10     Batch:  461  /  468     Loss_generator:  0.6655663251876831     Loss_discriminator:  0.6766483783721924\n",
      "Epoch:  10     Batch:  462  /  468     Loss_generator:  0.6543770432472229     Loss_discriminator:  0.6835751533508301\n",
      "Epoch:  10     Batch:  463  /  468     Loss_generator:  0.7267470359802246     Loss_discriminator:  0.7051384449005127\n",
      "Epoch:  10     Batch:  464  /  468     Loss_generator:  0.7760182023048401     Loss_discriminator:  0.69385826587677\n",
      "Epoch:  10     Batch:  465  /  468     Loss_generator:  0.7733538150787354     Loss_discriminator:  0.6797938346862793\n",
      "Epoch:  10     Batch:  466  /  468     Loss_generator:  0.7343229651451111     Loss_discriminator:  0.6837877035140991\n",
      "Epoch:  10     Batch:  467  /  468     Loss_generator:  0.6861246824264526     Loss_discriminator:  0.6810108423233032\n",
      "Epoch:  11     Batch:  0  /  468     Loss_generator:  0.6674238443374634     Loss_discriminator:  0.6911724209785461\n",
      "Epoch:  11     Batch:  1  /  468     Loss_generator:  0.6347131133079529     Loss_discriminator:  0.6726280450820923\n",
      "Epoch:  11     Batch:  2  /  468     Loss_generator:  0.6755580902099609     Loss_discriminator:  0.68117755651474\n",
      "Epoch:  11     Batch:  3  /  468     Loss_generator:  0.7197110056877136     Loss_discriminator:  0.6834794282913208\n",
      "Epoch:  11     Batch:  4  /  468     Loss_generator:  0.7816737294197083     Loss_discriminator:  0.6911352872848511\n",
      "Epoch:  11     Batch:  5  /  468     Loss_generator:  0.7858971357345581     Loss_discriminator:  0.677198052406311\n",
      "Epoch:  11     Batch:  6  /  468     Loss_generator:  0.7783000469207764     Loss_discriminator:  0.6913210153579712\n",
      "Epoch:  11     Batch:  7  /  468     Loss_generator:  0.6731156706809998     Loss_discriminator:  0.69730544090271\n",
      "Epoch:  11     Batch:  8  /  468     Loss_generator:  0.6539204120635986     Loss_discriminator:  0.6874256134033203\n",
      "Epoch:  11     Batch:  9  /  468     Loss_generator:  0.6533074378967285     Loss_discriminator:  0.6898458003997803\n",
      "Epoch:  11     Batch:  10  /  468     Loss_generator:  0.6663751006126404     Loss_discriminator:  0.6955430507659912\n",
      "Epoch:  11     Batch:  11  /  468     Loss_generator:  0.7265176773071289     Loss_discriminator:  0.696700394153595\n",
      "Epoch:  11     Batch:  12  /  468     Loss_generator:  0.7520825266838074     Loss_discriminator:  0.6847160458564758\n",
      "Epoch:  11     Batch:  13  /  468     Loss_generator:  0.7594027519226074     Loss_discriminator:  0.691754937171936\n",
      "Epoch:  11     Batch:  14  /  468     Loss_generator:  0.7261273264884949     Loss_discriminator:  0.6829071640968323\n",
      "Epoch:  11     Batch:  15  /  468     Loss_generator:  0.6892870664596558     Loss_discriminator:  0.6747905015945435\n",
      "Epoch:  11     Batch:  16  /  468     Loss_generator:  0.6725037693977356     Loss_discriminator:  0.6852307915687561\n",
      "Epoch:  11     Batch:  17  /  468     Loss_generator:  0.664725124835968     Loss_discriminator:  0.6914017200469971\n",
      "Epoch:  11     Batch:  18  /  468     Loss_generator:  0.6951057314872742     Loss_discriminator:  0.6738656759262085\n",
      "Epoch:  11     Batch:  19  /  468     Loss_generator:  0.7134480476379395     Loss_discriminator:  0.6837334632873535\n",
      "Epoch:  11     Batch:  20  /  468     Loss_generator:  0.7353155612945557     Loss_discriminator:  0.6841202974319458\n",
      "Epoch:  11     Batch:  21  /  468     Loss_generator:  0.7445271015167236     Loss_discriminator:  0.6750780940055847\n",
      "Epoch:  11     Batch:  22  /  468     Loss_generator:  0.7473448514938354     Loss_discriminator:  0.6950545310974121\n",
      "Epoch:  11     Batch:  23  /  468     Loss_generator:  0.7259560823440552     Loss_discriminator:  0.6850537061691284\n",
      "Epoch:  11     Batch:  24  /  468     Loss_generator:  0.7192626595497131     Loss_discriminator:  0.688032865524292\n",
      "Epoch:  11     Batch:  25  /  468     Loss_generator:  0.6931454539299011     Loss_discriminator:  0.6771529912948608\n",
      "Epoch:  11     Batch:  26  /  468     Loss_generator:  0.6689786314964294     Loss_discriminator:  0.693564772605896\n",
      "Epoch:  11     Batch:  27  /  468     Loss_generator:  0.6767102479934692     Loss_discriminator:  0.6940906047821045\n",
      "Epoch:  11     Batch:  28  /  468     Loss_generator:  0.7065560221672058     Loss_discriminator:  0.6998207569122314\n",
      "Epoch:  11     Batch:  29  /  468     Loss_generator:  0.7388988137245178     Loss_discriminator:  0.6806096434593201\n",
      "Epoch:  11     Batch:  30  /  468     Loss_generator:  0.7382785081863403     Loss_discriminator:  0.679289698600769\n",
      "Epoch:  11     Batch:  31  /  468     Loss_generator:  0.7369376420974731     Loss_discriminator:  0.6771003007888794\n",
      "Epoch:  11     Batch:  32  /  468     Loss_generator:  0.7178815007209778     Loss_discriminator:  0.6715577244758606\n",
      "Epoch:  11     Batch:  33  /  468     Loss_generator:  0.6890640258789062     Loss_discriminator:  0.6894661784172058\n",
      "Epoch:  11     Batch:  34  /  468     Loss_generator:  0.6762356162071228     Loss_discriminator:  0.6829029321670532\n",
      "Epoch:  11     Batch:  35  /  468     Loss_generator:  0.7110833525657654     Loss_discriminator:  0.6846132278442383\n",
      "Epoch:  11     Batch:  36  /  468     Loss_generator:  0.7157682180404663     Loss_discriminator:  0.68057781457901\n",
      "Epoch:  11     Batch:  37  /  468     Loss_generator:  0.7229130268096924     Loss_discriminator:  0.6667711734771729\n",
      "Epoch:  11     Batch:  38  /  468     Loss_generator:  0.7239599823951721     Loss_discriminator:  0.6874681711196899\n",
      "Epoch:  11     Batch:  39  /  468     Loss_generator:  0.708927571773529     Loss_discriminator:  0.6746221780776978\n",
      "Epoch:  11     Batch:  40  /  468     Loss_generator:  0.6816108226776123     Loss_discriminator:  0.6952550411224365\n",
      "Epoch:  11     Batch:  41  /  468     Loss_generator:  0.684456467628479     Loss_discriminator:  0.6923441290855408\n",
      "Epoch:  11     Batch:  42  /  468     Loss_generator:  0.7038221955299377     Loss_discriminator:  0.6818150281906128\n",
      "Epoch:  11     Batch:  43  /  468     Loss_generator:  0.7199816703796387     Loss_discriminator:  0.6879658699035645\n",
      "Epoch:  11     Batch:  44  /  468     Loss_generator:  0.7134262323379517     Loss_discriminator:  0.6907942295074463\n",
      "Epoch:  11     Batch:  45  /  468     Loss_generator:  0.7366348505020142     Loss_discriminator:  0.6859444975852966\n",
      "Epoch:  11     Batch:  46  /  468     Loss_generator:  0.7137799859046936     Loss_discriminator:  0.6935471892356873\n",
      "Epoch:  11     Batch:  47  /  468     Loss_generator:  0.6858789920806885     Loss_discriminator:  0.6889587640762329\n",
      "Epoch:  11     Batch:  48  /  468     Loss_generator:  0.6861395835876465     Loss_discriminator:  0.6809945106506348\n",
      "Epoch:  11     Batch:  49  /  468     Loss_generator:  0.6768873333930969     Loss_discriminator:  0.686309278011322\n",
      "Epoch:  11     Batch:  50  /  468     Loss_generator:  0.7018558979034424     Loss_discriminator:  0.6700879335403442\n",
      "Epoch:  11     Batch:  51  /  468     Loss_generator:  0.7016453146934509     Loss_discriminator:  0.6887646913528442\n",
      "Epoch:  11     Batch:  52  /  468     Loss_generator:  0.7401463985443115     Loss_discriminator:  0.682523250579834\n",
      "Epoch:  11     Batch:  53  /  468     Loss_generator:  0.742621898651123     Loss_discriminator:  0.6931073665618896\n",
      "Epoch:  11     Batch:  54  /  468     Loss_generator:  0.7321718335151672     Loss_discriminator:  0.6868506073951721\n",
      "Epoch:  11     Batch:  55  /  468     Loss_generator:  0.7160046100616455     Loss_discriminator:  0.6905361413955688\n",
      "Epoch:  11     Batch:  56  /  468     Loss_generator:  0.6927382946014404     Loss_discriminator:  0.6902668476104736\n",
      "Epoch:  11     Batch:  57  /  468     Loss_generator:  0.6731549501419067     Loss_discriminator:  0.6812579035758972\n",
      "Epoch:  11     Batch:  58  /  468     Loss_generator:  0.6851440072059631     Loss_discriminator:  0.6788715124130249\n",
      "Epoch:  11     Batch:  59  /  468     Loss_generator:  0.7044939994812012     Loss_discriminator:  0.6832899451255798\n",
      "Epoch:  11     Batch:  60  /  468     Loss_generator:  0.7146468162536621     Loss_discriminator:  0.6890509128570557\n",
      "Epoch:  11     Batch:  61  /  468     Loss_generator:  0.7175981998443604     Loss_discriminator:  0.6925252079963684\n",
      "Epoch:  11     Batch:  62  /  468     Loss_generator:  0.6967213153839111     Loss_discriminator:  0.6775741577148438\n",
      "Epoch:  11     Batch:  63  /  468     Loss_generator:  0.7068408727645874     Loss_discriminator:  0.6954319477081299\n",
      "Epoch:  11     Batch:  64  /  468     Loss_generator:  0.7219109535217285     Loss_discriminator:  0.6876758337020874\n",
      "Epoch:  11     Batch:  65  /  468     Loss_generator:  0.7453278303146362     Loss_discriminator:  0.6728979349136353\n",
      "Epoch:  11     Batch:  66  /  468     Loss_generator:  0.7603069543838501     Loss_discriminator:  0.6847769021987915\n",
      "Epoch:  11     Batch:  67  /  468     Loss_generator:  0.732075572013855     Loss_discriminator:  0.6820840239524841\n",
      "Epoch:  11     Batch:  68  /  468     Loss_generator:  0.6801457405090332     Loss_discriminator:  0.689460039138794\n",
      "Epoch:  11     Batch:  69  /  468     Loss_generator:  0.6507155895233154     Loss_discriminator:  0.6896470785140991\n",
      "Epoch:  11     Batch:  70  /  468     Loss_generator:  0.6627050042152405     Loss_discriminator:  0.6836395859718323\n",
      "Epoch:  11     Batch:  71  /  468     Loss_generator:  0.6989875435829163     Loss_discriminator:  0.6891566514968872\n",
      "Epoch:  11     Batch:  72  /  468     Loss_generator:  0.7357050776481628     Loss_discriminator:  0.6764116287231445\n",
      "Epoch:  11     Batch:  73  /  468     Loss_generator:  0.7641146779060364     Loss_discriminator:  0.679335355758667\n",
      "Epoch:  11     Batch:  74  /  468     Loss_generator:  0.7431685328483582     Loss_discriminator:  0.6854074597358704\n",
      "Epoch:  11     Batch:  75  /  468     Loss_generator:  0.6781091690063477     Loss_discriminator:  0.6948366165161133\n",
      "Epoch:  11     Batch:  76  /  468     Loss_generator:  0.6486698985099792     Loss_discriminator:  0.6931117177009583\n",
      "Epoch:  11     Batch:  77  /  468     Loss_generator:  0.64559006690979     Loss_discriminator:  0.6997253894805908\n",
      "Epoch:  11     Batch:  78  /  468     Loss_generator:  0.6818745732307434     Loss_discriminator:  0.6862527132034302\n",
      "Epoch:  11     Batch:  79  /  468     Loss_generator:  0.7263730764389038     Loss_discriminator:  0.6834399700164795\n",
      "Epoch:  11     Batch:  80  /  468     Loss_generator:  0.7552309036254883     Loss_discriminator:  0.6769214868545532\n",
      "Epoch:  11     Batch:  81  /  468     Loss_generator:  0.7416900992393494     Loss_discriminator:  0.6896939873695374\n",
      "Epoch:  11     Batch:  82  /  468     Loss_generator:  0.7225613594055176     Loss_discriminator:  0.6915890574455261\n",
      "Epoch:  11     Batch:  83  /  468     Loss_generator:  0.6882227659225464     Loss_discriminator:  0.6857451796531677\n",
      "Epoch:  11     Batch:  84  /  468     Loss_generator:  0.6672929525375366     Loss_discriminator:  0.692023515701294\n",
      "Epoch:  11     Batch:  85  /  468     Loss_generator:  0.680620551109314     Loss_discriminator:  0.6782708168029785\n",
      "Epoch:  11     Batch:  86  /  468     Loss_generator:  0.7056958675384521     Loss_discriminator:  0.685197651386261\n",
      "Epoch:  11     Batch:  87  /  468     Loss_generator:  0.7104719281196594     Loss_discriminator:  0.6881370544433594\n",
      "Epoch:  11     Batch:  88  /  468     Loss_generator:  0.7364206314086914     Loss_discriminator:  0.6901575326919556\n",
      "Epoch:  11     Batch:  89  /  468     Loss_generator:  0.7113262414932251     Loss_discriminator:  0.6959208250045776\n",
      "Epoch:  11     Batch:  90  /  468     Loss_generator:  0.7025099992752075     Loss_discriminator:  0.6862432956695557\n",
      "Epoch:  11     Batch:  91  /  468     Loss_generator:  0.6843550205230713     Loss_discriminator:  0.6968927979469299\n",
      "Epoch:  11     Batch:  92  /  468     Loss_generator:  0.6697987914085388     Loss_discriminator:  0.6810901761054993\n",
      "Epoch:  11     Batch:  93  /  468     Loss_generator:  0.676532506942749     Loss_discriminator:  0.6863459348678589\n",
      "Epoch:  11     Batch:  94  /  468     Loss_generator:  0.7219884395599365     Loss_discriminator:  0.6783219575881958\n",
      "Epoch:  11     Batch:  95  /  468     Loss_generator:  0.7885500192642212     Loss_discriminator:  0.6794122457504272\n",
      "Epoch:  11     Batch:  96  /  468     Loss_generator:  0.7684601545333862     Loss_discriminator:  0.6938859224319458\n",
      "Epoch:  11     Batch:  97  /  468     Loss_generator:  0.717156171798706     Loss_discriminator:  0.692979097366333\n",
      "Epoch:  11     Batch:  98  /  468     Loss_generator:  0.6580390930175781     Loss_discriminator:  0.692314088344574\n",
      "Epoch:  11     Batch:  99  /  468     Loss_generator:  0.6471779942512512     Loss_discriminator:  0.6881027817726135\n",
      "Epoch:  11     Batch:  100  /  468     Loss_generator:  0.6590192317962646     Loss_discriminator:  0.6894039511680603\n",
      "Epoch:  11     Batch:  101  /  468     Loss_generator:  0.6788214445114136     Loss_discriminator:  0.685733437538147\n",
      "Epoch:  11     Batch:  102  /  468     Loss_generator:  0.7224507927894592     Loss_discriminator:  0.6798535585403442\n",
      "Epoch:  11     Batch:  103  /  468     Loss_generator:  0.765195369720459     Loss_discriminator:  0.6751770377159119\n",
      "Epoch:  11     Batch:  104  /  468     Loss_generator:  0.7594793438911438     Loss_discriminator:  0.6845158338546753\n",
      "Epoch:  11     Batch:  105  /  468     Loss_generator:  0.7492965459823608     Loss_discriminator:  0.6919727325439453\n",
      "Epoch:  11     Batch:  106  /  468     Loss_generator:  0.70526522397995     Loss_discriminator:  0.6824862957000732\n",
      "Epoch:  11     Batch:  107  /  468     Loss_generator:  0.6712969541549683     Loss_discriminator:  0.6802724599838257\n",
      "Epoch:  11     Batch:  108  /  468     Loss_generator:  0.6633166670799255     Loss_discriminator:  0.6882661581039429\n",
      "Epoch:  11     Batch:  109  /  468     Loss_generator:  0.6728590726852417     Loss_discriminator:  0.679466962814331\n",
      "Epoch:  11     Batch:  110  /  468     Loss_generator:  0.6894524693489075     Loss_discriminator:  0.6815551519393921\n",
      "Epoch:  11     Batch:  111  /  468     Loss_generator:  0.7297760844230652     Loss_discriminator:  0.6963870525360107\n",
      "Epoch:  11     Batch:  112  /  468     Loss_generator:  0.7726357579231262     Loss_discriminator:  0.6822435855865479\n",
      "Epoch:  11     Batch:  113  /  468     Loss_generator:  0.7515009045600891     Loss_discriminator:  0.6919313669204712\n",
      "Epoch:  11     Batch:  114  /  468     Loss_generator:  0.6988760828971863     Loss_discriminator:  0.693030059337616\n",
      "Epoch:  11     Batch:  115  /  468     Loss_generator:  0.682626485824585     Loss_discriminator:  0.6836633682250977\n",
      "Epoch:  11     Batch:  116  /  468     Loss_generator:  0.6909765005111694     Loss_discriminator:  0.6787270307540894\n",
      "Epoch:  11     Batch:  117  /  468     Loss_generator:  0.6948819756507874     Loss_discriminator:  0.6795218586921692\n",
      "Epoch:  11     Batch:  118  /  468     Loss_generator:  0.6959578990936279     Loss_discriminator:  0.6739128232002258\n",
      "Epoch:  11     Batch:  119  /  468     Loss_generator:  0.6856380105018616     Loss_discriminator:  0.6783828735351562\n",
      "Epoch:  11     Batch:  120  /  468     Loss_generator:  0.6947497725486755     Loss_discriminator:  0.6870645880699158\n",
      "Epoch:  11     Batch:  121  /  468     Loss_generator:  0.7000771760940552     Loss_discriminator:  0.6825540065765381\n",
      "Epoch:  11     Batch:  122  /  468     Loss_generator:  0.7341652512550354     Loss_discriminator:  0.6866510510444641\n",
      "Epoch:  11     Batch:  123  /  468     Loss_generator:  0.7582340240478516     Loss_discriminator:  0.6721069812774658\n",
      "Epoch:  11     Batch:  124  /  468     Loss_generator:  0.7364723682403564     Loss_discriminator:  0.6728270053863525\n",
      "Epoch:  11     Batch:  125  /  468     Loss_generator:  0.7344388961791992     Loss_discriminator:  0.6805574893951416\n",
      "Epoch:  11     Batch:  126  /  468     Loss_generator:  0.7057605385780334     Loss_discriminator:  0.6829433441162109\n",
      "Epoch:  11     Batch:  127  /  468     Loss_generator:  0.6920539140701294     Loss_discriminator:  0.6831783056259155\n",
      "Epoch:  11     Batch:  128  /  468     Loss_generator:  0.6873438358306885     Loss_discriminator:  0.6813702583312988\n",
      "Epoch:  11     Batch:  129  /  468     Loss_generator:  0.6710282564163208     Loss_discriminator:  0.6741524338722229\n",
      "Epoch:  11     Batch:  130  /  468     Loss_generator:  0.669074296951294     Loss_discriminator:  0.6694985628128052\n",
      "Epoch:  11     Batch:  131  /  468     Loss_generator:  0.7056042551994324     Loss_discriminator:  0.6756585240364075\n",
      "Epoch:  11     Batch:  132  /  468     Loss_generator:  0.7127808332443237     Loss_discriminator:  0.6870409846305847\n",
      "Epoch:  11     Batch:  133  /  468     Loss_generator:  0.7094001173973083     Loss_discriminator:  0.6901413798332214\n",
      "Epoch:  11     Batch:  134  /  468     Loss_generator:  0.7094396352767944     Loss_discriminator:  0.6923750042915344\n",
      "Epoch:  11     Batch:  135  /  468     Loss_generator:  0.7018312215805054     Loss_discriminator:  0.6952372193336487\n",
      "Epoch:  11     Batch:  136  /  468     Loss_generator:  0.7132829427719116     Loss_discriminator:  0.6765580177307129\n",
      "Epoch:  11     Batch:  137  /  468     Loss_generator:  0.7246977090835571     Loss_discriminator:  0.6748216152191162\n",
      "Epoch:  11     Batch:  138  /  468     Loss_generator:  0.7127771377563477     Loss_discriminator:  0.6881380081176758\n",
      "Epoch:  11     Batch:  139  /  468     Loss_generator:  0.7064403891563416     Loss_discriminator:  0.6853864192962646\n",
      "Epoch:  11     Batch:  140  /  468     Loss_generator:  0.7075655460357666     Loss_discriminator:  0.6859346628189087\n",
      "Epoch:  11     Batch:  141  /  468     Loss_generator:  0.7092226147651672     Loss_discriminator:  0.684953510761261\n",
      "Epoch:  11     Batch:  142  /  468     Loss_generator:  0.6805425882339478     Loss_discriminator:  0.6854192614555359\n",
      "Epoch:  11     Batch:  143  /  468     Loss_generator:  0.6613423824310303     Loss_discriminator:  0.6897808313369751\n",
      "Epoch:  11     Batch:  144  /  468     Loss_generator:  0.6773878335952759     Loss_discriminator:  0.6968788504600525\n",
      "Epoch:  11     Batch:  145  /  468     Loss_generator:  0.716040313243866     Loss_discriminator:  0.675044059753418\n",
      "Epoch:  11     Batch:  146  /  468     Loss_generator:  0.7137101888656616     Loss_discriminator:  0.6820005178451538\n",
      "Epoch:  11     Batch:  147  /  468     Loss_generator:  0.7241189479827881     Loss_discriminator:  0.6913291215896606\n",
      "Epoch:  11     Batch:  148  /  468     Loss_generator:  0.7501856684684753     Loss_discriminator:  0.6899054050445557\n",
      "Epoch:  11     Batch:  149  /  468     Loss_generator:  0.7619987726211548     Loss_discriminator:  0.6774399280548096\n",
      "Epoch:  11     Batch:  150  /  468     Loss_generator:  0.7386182546615601     Loss_discriminator:  0.6786882877349854\n",
      "Epoch:  11     Batch:  151  /  468     Loss_generator:  0.6887955069541931     Loss_discriminator:  0.6834520101547241\n",
      "Epoch:  11     Batch:  152  /  468     Loss_generator:  0.650456964969635     Loss_discriminator:  0.691095232963562\n",
      "Epoch:  11     Batch:  153  /  468     Loss_generator:  0.6195842623710632     Loss_discriminator:  0.6790981292724609\n",
      "Epoch:  11     Batch:  154  /  468     Loss_generator:  0.6504161357879639     Loss_discriminator:  0.6959575414657593\n",
      "Epoch:  11     Batch:  155  /  468     Loss_generator:  0.7335041761398315     Loss_discriminator:  0.6884824633598328\n",
      "Epoch:  11     Batch:  156  /  468     Loss_generator:  0.8259305357933044     Loss_discriminator:  0.6900429129600525\n",
      "Epoch:  11     Batch:  157  /  468     Loss_generator:  0.8412287831306458     Loss_discriminator:  0.6811252236366272\n",
      "Epoch:  11     Batch:  158  /  468     Loss_generator:  0.7800402641296387     Loss_discriminator:  0.681439995765686\n",
      "Epoch:  11     Batch:  159  /  468     Loss_generator:  0.6927891373634338     Loss_discriminator:  0.6954866647720337\n",
      "Epoch:  11     Batch:  160  /  468     Loss_generator:  0.6503838300704956     Loss_discriminator:  0.6757365465164185\n",
      "Epoch:  11     Batch:  161  /  468     Loss_generator:  0.6289270520210266     Loss_discriminator:  0.6897825598716736\n",
      "Epoch:  11     Batch:  162  /  468     Loss_generator:  0.6402140855789185     Loss_discriminator:  0.689639151096344\n",
      "Epoch:  11     Batch:  163  /  468     Loss_generator:  0.6660105586051941     Loss_discriminator:  0.6885678768157959\n",
      "Epoch:  11     Batch:  164  /  468     Loss_generator:  0.7171487808227539     Loss_discriminator:  0.691437304019928\n",
      "Epoch:  11     Batch:  165  /  468     Loss_generator:  0.7518918514251709     Loss_discriminator:  0.6903799176216125\n",
      "Epoch:  11     Batch:  166  /  468     Loss_generator:  0.8212357759475708     Loss_discriminator:  0.684245228767395\n",
      "Epoch:  11     Batch:  167  /  468     Loss_generator:  0.7911167740821838     Loss_discriminator:  0.6792770624160767\n",
      "Epoch:  11     Batch:  168  /  468     Loss_generator:  0.7121237516403198     Loss_discriminator:  0.6881521344184875\n",
      "Epoch:  11     Batch:  169  /  468     Loss_generator:  0.6959331035614014     Loss_discriminator:  0.691764235496521\n",
      "Epoch:  11     Batch:  170  /  468     Loss_generator:  0.6825628280639648     Loss_discriminator:  0.6882492303848267\n",
      "Epoch:  11     Batch:  171  /  468     Loss_generator:  0.6770111918449402     Loss_discriminator:  0.6998609900474548\n",
      "Epoch:  11     Batch:  172  /  468     Loss_generator:  0.6754822731018066     Loss_discriminator:  0.6929627060890198\n",
      "Epoch:  11     Batch:  173  /  468     Loss_generator:  0.6862006783485413     Loss_discriminator:  0.6840310096740723\n",
      "Epoch:  11     Batch:  174  /  468     Loss_generator:  0.6889307498931885     Loss_discriminator:  0.6891868114471436\n",
      "Epoch:  11     Batch:  175  /  468     Loss_generator:  0.7024672031402588     Loss_discriminator:  0.6951800584793091\n",
      "Epoch:  11     Batch:  176  /  468     Loss_generator:  0.7327024936676025     Loss_discriminator:  0.6828026175498962\n",
      "Epoch:  11     Batch:  177  /  468     Loss_generator:  0.7427642941474915     Loss_discriminator:  0.6905573010444641\n",
      "Epoch:  11     Batch:  178  /  468     Loss_generator:  0.7497624158859253     Loss_discriminator:  0.6904491186141968\n",
      "Epoch:  11     Batch:  179  /  468     Loss_generator:  0.7132737636566162     Loss_discriminator:  0.6848605871200562\n",
      "Epoch:  11     Batch:  180  /  468     Loss_generator:  0.686942994594574     Loss_discriminator:  0.6807305216789246\n",
      "Epoch:  11     Batch:  181  /  468     Loss_generator:  0.6771820187568665     Loss_discriminator:  0.6757745742797852\n",
      "Epoch:  11     Batch:  182  /  468     Loss_generator:  0.6718536615371704     Loss_discriminator:  0.6816425323486328\n",
      "Epoch:  11     Batch:  183  /  468     Loss_generator:  0.7091953754425049     Loss_discriminator:  0.7039666771888733\n",
      "Epoch:  11     Batch:  184  /  468     Loss_generator:  0.7400518655776978     Loss_discriminator:  0.6811479330062866\n",
      "Epoch:  11     Batch:  185  /  468     Loss_generator:  0.7407130002975464     Loss_discriminator:  0.6795638799667358\n",
      "Epoch:  11     Batch:  186  /  468     Loss_generator:  0.7299982905387878     Loss_discriminator:  0.6821695566177368\n",
      "Epoch:  11     Batch:  187  /  468     Loss_generator:  0.7103309631347656     Loss_discriminator:  0.6864954233169556\n",
      "Epoch:  11     Batch:  188  /  468     Loss_generator:  0.6946123838424683     Loss_discriminator:  0.6744805574417114\n",
      "Epoch:  11     Batch:  189  /  468     Loss_generator:  0.6725848913192749     Loss_discriminator:  0.6925609111785889\n",
      "Epoch:  11     Batch:  190  /  468     Loss_generator:  0.6581047177314758     Loss_discriminator:  0.6870288848876953\n",
      "Epoch:  11     Batch:  191  /  468     Loss_generator:  0.6821474432945251     Loss_discriminator:  0.6791659593582153\n",
      "Epoch:  11     Batch:  192  /  468     Loss_generator:  0.7009602785110474     Loss_discriminator:  0.6887788772583008\n",
      "Epoch:  11     Batch:  193  /  468     Loss_generator:  0.7432942986488342     Loss_discriminator:  0.6876576542854309\n",
      "Epoch:  11     Batch:  194  /  468     Loss_generator:  0.766659677028656     Loss_discriminator:  0.6810840368270874\n",
      "Epoch:  11     Batch:  195  /  468     Loss_generator:  0.7549281120300293     Loss_discriminator:  0.6833817362785339\n",
      "Epoch:  11     Batch:  196  /  468     Loss_generator:  0.7151336669921875     Loss_discriminator:  0.6874690055847168\n",
      "Epoch:  11     Batch:  197  /  468     Loss_generator:  0.6889159679412842     Loss_discriminator:  0.6852437257766724\n",
      "Epoch:  11     Batch:  198  /  468     Loss_generator:  0.6579829454421997     Loss_discriminator:  0.6749042272567749\n",
      "Epoch:  11     Batch:  199  /  468     Loss_generator:  0.6572684645652771     Loss_discriminator:  0.6925714015960693\n",
      "Epoch:  11     Batch:  200  /  468     Loss_generator:  0.6881595253944397     Loss_discriminator:  0.693220317363739\n",
      "Epoch:  11     Batch:  201  /  468     Loss_generator:  0.7385463714599609     Loss_discriminator:  0.6906861662864685\n",
      "Epoch:  11     Batch:  202  /  468     Loss_generator:  0.7672905921936035     Loss_discriminator:  0.691906213760376\n",
      "Epoch:  11     Batch:  203  /  468     Loss_generator:  0.7610026597976685     Loss_discriminator:  0.6987627744674683\n",
      "Epoch:  11     Batch:  204  /  468     Loss_generator:  0.7239744663238525     Loss_discriminator:  0.6872837543487549\n",
      "Epoch:  11     Batch:  205  /  468     Loss_generator:  0.6717596054077148     Loss_discriminator:  0.6929985880851746\n",
      "Epoch:  11     Batch:  206  /  468     Loss_generator:  0.6612832546234131     Loss_discriminator:  0.6843553781509399\n",
      "Epoch:  11     Batch:  207  /  468     Loss_generator:  0.659637451171875     Loss_discriminator:  0.6932971477508545\n",
      "Epoch:  11     Batch:  208  /  468     Loss_generator:  0.7203761339187622     Loss_discriminator:  0.689071536064148\n",
      "Epoch:  11     Batch:  209  /  468     Loss_generator:  0.7451416254043579     Loss_discriminator:  0.6823458671569824\n",
      "Epoch:  11     Batch:  210  /  468     Loss_generator:  0.7468757629394531     Loss_discriminator:  0.6933777928352356\n",
      "Epoch:  11     Batch:  211  /  468     Loss_generator:  0.7563921213150024     Loss_discriminator:  0.6887723207473755\n",
      "Epoch:  11     Batch:  212  /  468     Loss_generator:  0.7213425040245056     Loss_discriminator:  0.6736326217651367\n",
      "Epoch:  11     Batch:  213  /  468     Loss_generator:  0.6854761242866516     Loss_discriminator:  0.6915421485900879\n",
      "Epoch:  11     Batch:  214  /  468     Loss_generator:  0.6665477156639099     Loss_discriminator:  0.6883456707000732\n",
      "Epoch:  11     Batch:  215  /  468     Loss_generator:  0.6491994857788086     Loss_discriminator:  0.6980446577072144\n",
      "Epoch:  11     Batch:  216  /  468     Loss_generator:  0.6744751334190369     Loss_discriminator:  0.6844974756240845\n",
      "Epoch:  11     Batch:  217  /  468     Loss_generator:  0.7013676166534424     Loss_discriminator:  0.6965417265892029\n",
      "Epoch:  11     Batch:  218  /  468     Loss_generator:  0.7393548488616943     Loss_discriminator:  0.6744092702865601\n",
      "Epoch:  11     Batch:  219  /  468     Loss_generator:  0.7478904724121094     Loss_discriminator:  0.686545729637146\n",
      "Epoch:  11     Batch:  220  /  468     Loss_generator:  0.7705585956573486     Loss_discriminator:  0.6890120506286621\n",
      "Epoch:  11     Batch:  221  /  468     Loss_generator:  0.7552505731582642     Loss_discriminator:  0.687997579574585\n",
      "Epoch:  11     Batch:  222  /  468     Loss_generator:  0.7238342761993408     Loss_discriminator:  0.6754022240638733\n",
      "Epoch:  11     Batch:  223  /  468     Loss_generator:  0.7056505680084229     Loss_discriminator:  0.6908599138259888\n",
      "Epoch:  11     Batch:  224  /  468     Loss_generator:  0.6873238682746887     Loss_discriminator:  0.692648708820343\n",
      "Epoch:  11     Batch:  225  /  468     Loss_generator:  0.6747421026229858     Loss_discriminator:  0.6840784549713135\n",
      "Epoch:  11     Batch:  226  /  468     Loss_generator:  0.6918217539787292     Loss_discriminator:  0.674930214881897\n",
      "Epoch:  11     Batch:  227  /  468     Loss_generator:  0.7087631225585938     Loss_discriminator:  0.6777921915054321\n",
      "Epoch:  11     Batch:  228  /  468     Loss_generator:  0.709013819694519     Loss_discriminator:  0.685267448425293\n",
      "Epoch:  11     Batch:  229  /  468     Loss_generator:  0.7061251401901245     Loss_discriminator:  0.6907035708427429\n",
      "Epoch:  11     Batch:  230  /  468     Loss_generator:  0.7118438482284546     Loss_discriminator:  0.6920560598373413\n",
      "Epoch:  11     Batch:  231  /  468     Loss_generator:  0.7199259996414185     Loss_discriminator:  0.6878488659858704\n",
      "Epoch:  11     Batch:  232  /  468     Loss_generator:  0.722112774848938     Loss_discriminator:  0.6928824186325073\n",
      "Epoch:  11     Batch:  233  /  468     Loss_generator:  0.7437114119529724     Loss_discriminator:  0.6920974254608154\n",
      "Epoch:  11     Batch:  234  /  468     Loss_generator:  0.7364559173583984     Loss_discriminator:  0.6895627975463867\n",
      "Epoch:  11     Batch:  235  /  468     Loss_generator:  0.7129765152931213     Loss_discriminator:  0.691078782081604\n",
      "Epoch:  11     Batch:  236  /  468     Loss_generator:  0.6928046941757202     Loss_discriminator:  0.6875529289245605\n",
      "Epoch:  11     Batch:  237  /  468     Loss_generator:  0.6705889701843262     Loss_discriminator:  0.6779319047927856\n",
      "Epoch:  11     Batch:  238  /  468     Loss_generator:  0.6846709251403809     Loss_discriminator:  0.6912556886672974\n",
      "Epoch:  11     Batch:  239  /  468     Loss_generator:  0.7134917974472046     Loss_discriminator:  0.6949418187141418\n",
      "Epoch:  11     Batch:  240  /  468     Loss_generator:  0.7126026749610901     Loss_discriminator:  0.7001873850822449\n",
      "Epoch:  11     Batch:  241  /  468     Loss_generator:  0.7385604381561279     Loss_discriminator:  0.6891671419143677\n",
      "Epoch:  11     Batch:  242  /  468     Loss_generator:  0.7519906759262085     Loss_discriminator:  0.7005062103271484\n",
      "Epoch:  11     Batch:  243  /  468     Loss_generator:  0.7074787020683289     Loss_discriminator:  0.6838467121124268\n",
      "Epoch:  11     Batch:  244  /  468     Loss_generator:  0.682330846786499     Loss_discriminator:  0.683152973651886\n",
      "Epoch:  11     Batch:  245  /  468     Loss_generator:  0.6742388010025024     Loss_discriminator:  0.6751000881195068\n",
      "Epoch:  11     Batch:  246  /  468     Loss_generator:  0.6729663014411926     Loss_discriminator:  0.6907237768173218\n",
      "Epoch:  11     Batch:  247  /  468     Loss_generator:  0.7021429538726807     Loss_discriminator:  0.6953193545341492\n",
      "Epoch:  11     Batch:  248  /  468     Loss_generator:  0.7260834574699402     Loss_discriminator:  0.688724160194397\n",
      "Epoch:  11     Batch:  249  /  468     Loss_generator:  0.7365396022796631     Loss_discriminator:  0.681233286857605\n",
      "Epoch:  11     Batch:  250  /  468     Loss_generator:  0.7258961200714111     Loss_discriminator:  0.6852816939353943\n",
      "Epoch:  11     Batch:  251  /  468     Loss_generator:  0.6772193312644958     Loss_discriminator:  0.697049617767334\n",
      "Epoch:  11     Batch:  252  /  468     Loss_generator:  0.6902249455451965     Loss_discriminator:  0.6876422762870789\n",
      "Epoch:  11     Batch:  253  /  468     Loss_generator:  0.7049208283424377     Loss_discriminator:  0.6905245184898376\n",
      "Epoch:  11     Batch:  254  /  468     Loss_generator:  0.7551895380020142     Loss_discriminator:  0.68815016746521\n",
      "Epoch:  11     Batch:  255  /  468     Loss_generator:  0.7654746174812317     Loss_discriminator:  0.6825571060180664\n",
      "Epoch:  11     Batch:  256  /  468     Loss_generator:  0.7358510494232178     Loss_discriminator:  0.7027636170387268\n",
      "Epoch:  11     Batch:  257  /  468     Loss_generator:  0.6981006860733032     Loss_discriminator:  0.688838005065918\n",
      "Epoch:  11     Batch:  258  /  468     Loss_generator:  0.6471272706985474     Loss_discriminator:  0.6949471235275269\n",
      "Epoch:  11     Batch:  259  /  468     Loss_generator:  0.6310471296310425     Loss_discriminator:  0.6737968921661377\n",
      "Epoch:  11     Batch:  260  /  468     Loss_generator:  0.6504718661308289     Loss_discriminator:  0.6876425743103027\n",
      "Epoch:  11     Batch:  261  /  468     Loss_generator:  0.7266565561294556     Loss_discriminator:  0.6950955390930176\n",
      "Epoch:  11     Batch:  262  /  468     Loss_generator:  0.7669090628623962     Loss_discriminator:  0.6836296319961548\n",
      "Epoch:  11     Batch:  263  /  468     Loss_generator:  0.7516504526138306     Loss_discriminator:  0.6846941709518433\n",
      "Epoch:  11     Batch:  264  /  468     Loss_generator:  0.7511464357376099     Loss_discriminator:  0.6896803379058838\n",
      "Epoch:  11     Batch:  265  /  468     Loss_generator:  0.7318587899208069     Loss_discriminator:  0.6722480058670044\n",
      "Epoch:  11     Batch:  266  /  468     Loss_generator:  0.6844701766967773     Loss_discriminator:  0.6820212006568909\n",
      "Epoch:  11     Batch:  267  /  468     Loss_generator:  0.6647728085517883     Loss_discriminator:  0.6857646703720093\n",
      "Epoch:  11     Batch:  268  /  468     Loss_generator:  0.6600015163421631     Loss_discriminator:  0.6839804649353027\n",
      "Epoch:  11     Batch:  269  /  468     Loss_generator:  0.6830118298530579     Loss_discriminator:  0.6899071931838989\n",
      "Epoch:  11     Batch:  270  /  468     Loss_generator:  0.7115833759307861     Loss_discriminator:  0.6845566630363464\n",
      "Epoch:  11     Batch:  271  /  468     Loss_generator:  0.7509857416152954     Loss_discriminator:  0.685762882232666\n",
      "Epoch:  11     Batch:  272  /  468     Loss_generator:  0.743882954120636     Loss_discriminator:  0.6852061152458191\n",
      "Epoch:  11     Batch:  273  /  468     Loss_generator:  0.6957186460494995     Loss_discriminator:  0.6805729269981384\n",
      "Epoch:  11     Batch:  274  /  468     Loss_generator:  0.6696802377700806     Loss_discriminator:  0.6765192151069641\n",
      "Epoch:  11     Batch:  275  /  468     Loss_generator:  0.6699751615524292     Loss_discriminator:  0.6796456575393677\n",
      "Epoch:  11     Batch:  276  /  468     Loss_generator:  0.6950347423553467     Loss_discriminator:  0.6926860213279724\n",
      "Epoch:  11     Batch:  277  /  468     Loss_generator:  0.7462748289108276     Loss_discriminator:  0.690089225769043\n",
      "Epoch:  11     Batch:  278  /  468     Loss_generator:  0.772951602935791     Loss_discriminator:  0.688544511795044\n",
      "Epoch:  11     Batch:  279  /  468     Loss_generator:  0.7499934434890747     Loss_discriminator:  0.6851836442947388\n",
      "Epoch:  11     Batch:  280  /  468     Loss_generator:  0.7235801815986633     Loss_discriminator:  0.6803674101829529\n",
      "Epoch:  11     Batch:  281  /  468     Loss_generator:  0.6936075687408447     Loss_discriminator:  0.6855884790420532\n",
      "Epoch:  11     Batch:  282  /  468     Loss_generator:  0.6751958131790161     Loss_discriminator:  0.6898243427276611\n",
      "Epoch:  11     Batch:  283  /  468     Loss_generator:  0.6627580523490906     Loss_discriminator:  0.6826818585395813\n",
      "Epoch:  11     Batch:  284  /  468     Loss_generator:  0.6728067398071289     Loss_discriminator:  0.6834660768508911\n",
      "Epoch:  11     Batch:  285  /  468     Loss_generator:  0.699744462966919     Loss_discriminator:  0.6862098574638367\n",
      "Epoch:  11     Batch:  286  /  468     Loss_generator:  0.7202025651931763     Loss_discriminator:  0.6839653253555298\n",
      "Epoch:  11     Batch:  287  /  468     Loss_generator:  0.7220067977905273     Loss_discriminator:  0.6884093284606934\n",
      "Epoch:  11     Batch:  288  /  468     Loss_generator:  0.7445025444030762     Loss_discriminator:  0.6904832124710083\n",
      "Epoch:  11     Batch:  289  /  468     Loss_generator:  0.7276065349578857     Loss_discriminator:  0.6892156004905701\n",
      "Epoch:  11     Batch:  290  /  468     Loss_generator:  0.7180416584014893     Loss_discriminator:  0.6786178350448608\n",
      "Epoch:  11     Batch:  291  /  468     Loss_generator:  0.6847002506256104     Loss_discriminator:  0.7029988169670105\n",
      "Epoch:  11     Batch:  292  /  468     Loss_generator:  0.6864197254180908     Loss_discriminator:  0.6885265707969666\n",
      "Epoch:  11     Batch:  293  /  468     Loss_generator:  0.6967400312423706     Loss_discriminator:  0.6972060203552246\n",
      "Epoch:  11     Batch:  294  /  468     Loss_generator:  0.733260989189148     Loss_discriminator:  0.6880461573600769\n",
      "Epoch:  11     Batch:  295  /  468     Loss_generator:  0.7111252546310425     Loss_discriminator:  0.682257890701294\n",
      "Epoch:  11     Batch:  296  /  468     Loss_generator:  0.7189095616340637     Loss_discriminator:  0.6774206161499023\n",
      "Epoch:  11     Batch:  297  /  468     Loss_generator:  0.708982527256012     Loss_discriminator:  0.684205949306488\n",
      "Epoch:  11     Batch:  298  /  468     Loss_generator:  0.685533881187439     Loss_discriminator:  0.6838923096656799\n",
      "Epoch:  11     Batch:  299  /  468     Loss_generator:  0.7225241661071777     Loss_discriminator:  0.6847447156906128\n",
      "Epoch:  11     Batch:  300  /  468     Loss_generator:  0.7211889028549194     Loss_discriminator:  0.6806525588035583\n",
      "Epoch:  11     Batch:  301  /  468     Loss_generator:  0.6995643377304077     Loss_discriminator:  0.6836274862289429\n",
      "Epoch:  11     Batch:  302  /  468     Loss_generator:  0.6999834179878235     Loss_discriminator:  0.6927846074104309\n",
      "Epoch:  11     Batch:  303  /  468     Loss_generator:  0.7191550731658936     Loss_discriminator:  0.6972557902336121\n",
      "Epoch:  11     Batch:  304  /  468     Loss_generator:  0.7265527248382568     Loss_discriminator:  0.6950342655181885\n",
      "Epoch:  11     Batch:  305  /  468     Loss_generator:  0.7086024284362793     Loss_discriminator:  0.6776042580604553\n",
      "Epoch:  11     Batch:  306  /  468     Loss_generator:  0.6892857551574707     Loss_discriminator:  0.6899609565734863\n",
      "Epoch:  11     Batch:  307  /  468     Loss_generator:  0.6897032260894775     Loss_discriminator:  0.6932935118675232\n",
      "Epoch:  11     Batch:  308  /  468     Loss_generator:  0.6963966488838196     Loss_discriminator:  0.6889457106590271\n",
      "Epoch:  11     Batch:  309  /  468     Loss_generator:  0.738584041595459     Loss_discriminator:  0.6916559934616089\n",
      "Epoch:  11     Batch:  310  /  468     Loss_generator:  0.7532822489738464     Loss_discriminator:  0.6813351511955261\n",
      "Epoch:  11     Batch:  311  /  468     Loss_generator:  0.7420746088027954     Loss_discriminator:  0.6936676502227783\n",
      "Epoch:  11     Batch:  312  /  468     Loss_generator:  0.7126548290252686     Loss_discriminator:  0.6857024431228638\n",
      "Epoch:  11     Batch:  313  /  468     Loss_generator:  0.6763200759887695     Loss_discriminator:  0.6892070770263672\n",
      "Epoch:  11     Batch:  314  /  468     Loss_generator:  0.6617878675460815     Loss_discriminator:  0.6791991591453552\n",
      "Epoch:  11     Batch:  315  /  468     Loss_generator:  0.6711147427558899     Loss_discriminator:  0.6871362328529358\n",
      "Epoch:  11     Batch:  316  /  468     Loss_generator:  0.6886730194091797     Loss_discriminator:  0.6822285056114197\n",
      "Epoch:  11     Batch:  317  /  468     Loss_generator:  0.7340601682662964     Loss_discriminator:  0.6828848719596863\n",
      "Epoch:  11     Batch:  318  /  468     Loss_generator:  0.7619832158088684     Loss_discriminator:  0.6771506667137146\n",
      "Epoch:  11     Batch:  319  /  468     Loss_generator:  0.7227671146392822     Loss_discriminator:  0.6911522150039673\n",
      "Epoch:  11     Batch:  320  /  468     Loss_generator:  0.6886690855026245     Loss_discriminator:  0.6821468472480774\n",
      "Epoch:  11     Batch:  321  /  468     Loss_generator:  0.694147527217865     Loss_discriminator:  0.6808710694313049\n",
      "Epoch:  11     Batch:  322  /  468     Loss_generator:  0.6999338865280151     Loss_discriminator:  0.6853731870651245\n",
      "Epoch:  11     Batch:  323  /  468     Loss_generator:  0.7028151750564575     Loss_discriminator:  0.6684268712997437\n",
      "Epoch:  11     Batch:  324  /  468     Loss_generator:  0.7185935974121094     Loss_discriminator:  0.6863481998443604\n",
      "Epoch:  11     Batch:  325  /  468     Loss_generator:  0.7449647784233093     Loss_discriminator:  0.6869390606880188\n",
      "Epoch:  11     Batch:  326  /  468     Loss_generator:  0.749786376953125     Loss_discriminator:  0.6773515343666077\n",
      "Epoch:  11     Batch:  327  /  468     Loss_generator:  0.7484557628631592     Loss_discriminator:  0.6899350881576538\n",
      "Epoch:  11     Batch:  328  /  468     Loss_generator:  0.7237178683280945     Loss_discriminator:  0.6799396276473999\n",
      "Epoch:  11     Batch:  329  /  468     Loss_generator:  0.6840215921401978     Loss_discriminator:  0.689745306968689\n",
      "Epoch:  11     Batch:  330  /  468     Loss_generator:  0.6773751974105835     Loss_discriminator:  0.6896190047264099\n",
      "Epoch:  11     Batch:  331  /  468     Loss_generator:  0.6813101768493652     Loss_discriminator:  0.6810581088066101\n",
      "Epoch:  11     Batch:  332  /  468     Loss_generator:  0.6942722201347351     Loss_discriminator:  0.6799755096435547\n",
      "Epoch:  11     Batch:  333  /  468     Loss_generator:  0.7173872590065002     Loss_discriminator:  0.7009580731391907\n",
      "Epoch:  11     Batch:  334  /  468     Loss_generator:  0.7495018839836121     Loss_discriminator:  0.6884592771530151\n",
      "Epoch:  11     Batch:  335  /  468     Loss_generator:  0.7581641674041748     Loss_discriminator:  0.6834077835083008\n",
      "Epoch:  11     Batch:  336  /  468     Loss_generator:  0.7231752872467041     Loss_discriminator:  0.6874837279319763\n",
      "Epoch:  11     Batch:  337  /  468     Loss_generator:  0.6851663589477539     Loss_discriminator:  0.6792305707931519\n",
      "Epoch:  11     Batch:  338  /  468     Loss_generator:  0.6575911045074463     Loss_discriminator:  0.6724340319633484\n",
      "Epoch:  11     Batch:  339  /  468     Loss_generator:  0.6518728733062744     Loss_discriminator:  0.6891088485717773\n",
      "Epoch:  11     Batch:  340  /  468     Loss_generator:  0.6780065298080444     Loss_discriminator:  0.6878859996795654\n",
      "Epoch:  11     Batch:  341  /  468     Loss_generator:  0.7080415487289429     Loss_discriminator:  0.6803882122039795\n",
      "Epoch:  11     Batch:  342  /  468     Loss_generator:  0.6983682513237     Loss_discriminator:  0.6997823715209961\n",
      "Epoch:  11     Batch:  343  /  468     Loss_generator:  0.7082091569900513     Loss_discriminator:  0.6848639249801636\n",
      "Epoch:  11     Batch:  344  /  468     Loss_generator:  0.7112641930580139     Loss_discriminator:  0.7015546560287476\n",
      "Epoch:  11     Batch:  345  /  468     Loss_generator:  0.6895208358764648     Loss_discriminator:  0.6794570684432983\n",
      "Epoch:  11     Batch:  346  /  468     Loss_generator:  0.7013360857963562     Loss_discriminator:  0.6864646077156067\n",
      "Epoch:  11     Batch:  347  /  468     Loss_generator:  0.6708185076713562     Loss_discriminator:  0.6801681518554688\n",
      "Epoch:  11     Batch:  348  /  468     Loss_generator:  0.6996157169342041     Loss_discriminator:  0.6849740743637085\n",
      "Epoch:  11     Batch:  349  /  468     Loss_generator:  0.7053358554840088     Loss_discriminator:  0.6760329604148865\n",
      "Epoch:  11     Batch:  350  /  468     Loss_generator:  0.7335134744644165     Loss_discriminator:  0.6867362260818481\n",
      "Epoch:  11     Batch:  351  /  468     Loss_generator:  0.7379995584487915     Loss_discriminator:  0.6714735627174377\n",
      "Epoch:  11     Batch:  352  /  468     Loss_generator:  0.7097306251525879     Loss_discriminator:  0.6860479712486267\n",
      "Epoch:  11     Batch:  353  /  468     Loss_generator:  0.7031042575836182     Loss_discriminator:  0.6762685775756836\n",
      "Epoch:  11     Batch:  354  /  468     Loss_generator:  0.7390159368515015     Loss_discriminator:  0.6797378659248352\n",
      "Epoch:  11     Batch:  355  /  468     Loss_generator:  0.716717004776001     Loss_discriminator:  0.693570077419281\n",
      "Epoch:  11     Batch:  356  /  468     Loss_generator:  0.7214243412017822     Loss_discriminator:  0.6930680274963379\n",
      "Epoch:  11     Batch:  357  /  468     Loss_generator:  0.7338968515396118     Loss_discriminator:  0.684188961982727\n",
      "Epoch:  11     Batch:  358  /  468     Loss_generator:  0.67921382188797     Loss_discriminator:  0.6884404420852661\n",
      "Epoch:  11     Batch:  359  /  468     Loss_generator:  0.6727126836776733     Loss_discriminator:  0.6918814182281494\n",
      "Epoch:  11     Batch:  360  /  468     Loss_generator:  0.6760606169700623     Loss_discriminator:  0.6891850829124451\n",
      "Epoch:  11     Batch:  361  /  468     Loss_generator:  0.7084813117980957     Loss_discriminator:  0.6822951436042786\n",
      "Epoch:  11     Batch:  362  /  468     Loss_generator:  0.7180576324462891     Loss_discriminator:  0.6909286975860596\n",
      "Epoch:  11     Batch:  363  /  468     Loss_generator:  0.7010645866394043     Loss_discriminator:  0.6887555122375488\n",
      "Epoch:  11     Batch:  364  /  468     Loss_generator:  0.7137124538421631     Loss_discriminator:  0.6892284154891968\n",
      "Epoch:  11     Batch:  365  /  468     Loss_generator:  0.7127183675765991     Loss_discriminator:  0.6780011057853699\n",
      "Epoch:  11     Batch:  366  /  468     Loss_generator:  0.7186316847801208     Loss_discriminator:  0.6828968524932861\n",
      "Epoch:  11     Batch:  367  /  468     Loss_generator:  0.6987104415893555     Loss_discriminator:  0.6891776919364929\n",
      "Epoch:  11     Batch:  368  /  468     Loss_generator:  0.7189414501190186     Loss_discriminator:  0.6836816072463989\n",
      "Epoch:  11     Batch:  369  /  468     Loss_generator:  0.7154407501220703     Loss_discriminator:  0.6850798726081848\n",
      "Epoch:  11     Batch:  370  /  468     Loss_generator:  0.6991431713104248     Loss_discriminator:  0.6969121694564819\n",
      "Epoch:  11     Batch:  371  /  468     Loss_generator:  0.7000387907028198     Loss_discriminator:  0.7018271088600159\n",
      "Epoch:  11     Batch:  372  /  468     Loss_generator:  0.6992722749710083     Loss_discriminator:  0.6882503032684326\n",
      "Epoch:  11     Batch:  373  /  468     Loss_generator:  0.7119091153144836     Loss_discriminator:  0.6807243227958679\n",
      "Epoch:  11     Batch:  374  /  468     Loss_generator:  0.7343572974205017     Loss_discriminator:  0.6780912280082703\n",
      "Epoch:  11     Batch:  375  /  468     Loss_generator:  0.7185037136077881     Loss_discriminator:  0.6964230537414551\n",
      "Epoch:  11     Batch:  376  /  468     Loss_generator:  0.6935030817985535     Loss_discriminator:  0.6952345371246338\n",
      "Epoch:  11     Batch:  377  /  468     Loss_generator:  0.691123902797699     Loss_discriminator:  0.6858042478561401\n",
      "Epoch:  11     Batch:  378  /  468     Loss_generator:  0.686312198638916     Loss_discriminator:  0.6810706257820129\n",
      "Epoch:  11     Batch:  379  /  468     Loss_generator:  0.6887180805206299     Loss_discriminator:  0.6902933716773987\n",
      "Epoch:  11     Batch:  380  /  468     Loss_generator:  0.711000919342041     Loss_discriminator:  0.6969190239906311\n",
      "Epoch:  11     Batch:  381  /  468     Loss_generator:  0.7162460088729858     Loss_discriminator:  0.6892471313476562\n",
      "Epoch:  11     Batch:  382  /  468     Loss_generator:  0.7256580591201782     Loss_discriminator:  0.6801965236663818\n",
      "Epoch:  11     Batch:  383  /  468     Loss_generator:  0.7174445390701294     Loss_discriminator:  0.6994626522064209\n",
      "Epoch:  11     Batch:  384  /  468     Loss_generator:  0.706026554107666     Loss_discriminator:  0.6865574717521667\n",
      "Epoch:  11     Batch:  385  /  468     Loss_generator:  0.6921297311782837     Loss_discriminator:  0.6914229393005371\n",
      "Epoch:  11     Batch:  386  /  468     Loss_generator:  0.6878480315208435     Loss_discriminator:  0.6937472820281982\n",
      "Epoch:  11     Batch:  387  /  468     Loss_generator:  0.6750677824020386     Loss_discriminator:  0.6858537197113037\n",
      "Epoch:  11     Batch:  388  /  468     Loss_generator:  0.7152966856956482     Loss_discriminator:  0.6856780648231506\n",
      "Epoch:  11     Batch:  389  /  468     Loss_generator:  0.7301615476608276     Loss_discriminator:  0.6920561194419861\n",
      "Epoch:  11     Batch:  390  /  468     Loss_generator:  0.7486475110054016     Loss_discriminator:  0.6745294332504272\n",
      "Epoch:  11     Batch:  391  /  468     Loss_generator:  0.7441323399543762     Loss_discriminator:  0.6864480972290039\n",
      "Epoch:  11     Batch:  392  /  468     Loss_generator:  0.7357994318008423     Loss_discriminator:  0.6960793137550354\n",
      "Epoch:  11     Batch:  393  /  468     Loss_generator:  0.6983771324157715     Loss_discriminator:  0.6886149644851685\n",
      "Epoch:  11     Batch:  394  /  468     Loss_generator:  0.6740483641624451     Loss_discriminator:  0.6843838691711426\n",
      "Epoch:  11     Batch:  395  /  468     Loss_generator:  0.6749845147132874     Loss_discriminator:  0.6850228309631348\n",
      "Epoch:  11     Batch:  396  /  468     Loss_generator:  0.6889468431472778     Loss_discriminator:  0.6937668323516846\n",
      "Epoch:  11     Batch:  397  /  468     Loss_generator:  0.7393664121627808     Loss_discriminator:  0.676262378692627\n",
      "Epoch:  11     Batch:  398  /  468     Loss_generator:  0.7521684169769287     Loss_discriminator:  0.6969402432441711\n",
      "Epoch:  11     Batch:  399  /  468     Loss_generator:  0.7557379007339478     Loss_discriminator:  0.6843870282173157\n",
      "Epoch:  11     Batch:  400  /  468     Loss_generator:  0.7270941734313965     Loss_discriminator:  0.6921405792236328\n",
      "Epoch:  11     Batch:  401  /  468     Loss_generator:  0.6872047781944275     Loss_discriminator:  0.6806186437606812\n",
      "Epoch:  11     Batch:  402  /  468     Loss_generator:  0.692551851272583     Loss_discriminator:  0.6837729811668396\n",
      "Epoch:  11     Batch:  403  /  468     Loss_generator:  0.6859889030456543     Loss_discriminator:  0.6871255040168762\n",
      "Epoch:  11     Batch:  404  /  468     Loss_generator:  0.7067817449569702     Loss_discriminator:  0.6785769462585449\n",
      "Epoch:  11     Batch:  405  /  468     Loss_generator:  0.733526885509491     Loss_discriminator:  0.6731569766998291\n",
      "Epoch:  11     Batch:  406  /  468     Loss_generator:  0.7194179892539978     Loss_discriminator:  0.6826211214065552\n",
      "Epoch:  11     Batch:  407  /  468     Loss_generator:  0.7191653847694397     Loss_discriminator:  0.6776340007781982\n",
      "Epoch:  11     Batch:  408  /  468     Loss_generator:  0.6910933256149292     Loss_discriminator:  0.6953611373901367\n",
      "Epoch:  11     Batch:  409  /  468     Loss_generator:  0.6730412244796753     Loss_discriminator:  0.6844089031219482\n",
      "Epoch:  11     Batch:  410  /  468     Loss_generator:  0.69180828332901     Loss_discriminator:  0.6854813098907471\n",
      "Epoch:  11     Batch:  411  /  468     Loss_generator:  0.728407621383667     Loss_discriminator:  0.68896484375\n",
      "Epoch:  11     Batch:  412  /  468     Loss_generator:  0.7796788215637207     Loss_discriminator:  0.6862765550613403\n",
      "Epoch:  11     Batch:  413  /  468     Loss_generator:  0.7631494402885437     Loss_discriminator:  0.6796465516090393\n",
      "Epoch:  11     Batch:  414  /  468     Loss_generator:  0.7299168109893799     Loss_discriminator:  0.6790142059326172\n",
      "Epoch:  11     Batch:  415  /  468     Loss_generator:  0.6781089901924133     Loss_discriminator:  0.6824201345443726\n",
      "Epoch:  11     Batch:  416  /  468     Loss_generator:  0.6546542644500732     Loss_discriminator:  0.6938229203224182\n",
      "Epoch:  11     Batch:  417  /  468     Loss_generator:  0.6628389358520508     Loss_discriminator:  0.6795231699943542\n",
      "Epoch:  11     Batch:  418  /  468     Loss_generator:  0.7002328634262085     Loss_discriminator:  0.684967041015625\n",
      "Epoch:  11     Batch:  419  /  468     Loss_generator:  0.7498884201049805     Loss_discriminator:  0.696149468421936\n",
      "Epoch:  11     Batch:  420  /  468     Loss_generator:  0.7570613622665405     Loss_discriminator:  0.7006906270980835\n",
      "Epoch:  11     Batch:  421  /  468     Loss_generator:  0.7686078548431396     Loss_discriminator:  0.6846775412559509\n",
      "Epoch:  11     Batch:  422  /  468     Loss_generator:  0.7191829681396484     Loss_discriminator:  0.6858359575271606\n",
      "Epoch:  11     Batch:  423  /  468     Loss_generator:  0.7038527131080627     Loss_discriminator:  0.6749880909919739\n",
      "Epoch:  11     Batch:  424  /  468     Loss_generator:  0.6851646304130554     Loss_discriminator:  0.6922652721405029\n",
      "Epoch:  11     Batch:  425  /  468     Loss_generator:  0.6738595962524414     Loss_discriminator:  0.6735991835594177\n",
      "Epoch:  11     Batch:  426  /  468     Loss_generator:  0.6748901605606079     Loss_discriminator:  0.6663633584976196\n",
      "Epoch:  11     Batch:  427  /  468     Loss_generator:  0.69158935546875     Loss_discriminator:  0.6837701201438904\n",
      "Epoch:  11     Batch:  428  /  468     Loss_generator:  0.7548009157180786     Loss_discriminator:  0.6994156241416931\n",
      "Epoch:  11     Batch:  429  /  468     Loss_generator:  0.769115686416626     Loss_discriminator:  0.6882109642028809\n",
      "Epoch:  11     Batch:  430  /  468     Loss_generator:  0.7283871173858643     Loss_discriminator:  0.6833305358886719\n",
      "Epoch:  11     Batch:  431  /  468     Loss_generator:  0.7098186016082764     Loss_discriminator:  0.6777082681655884\n",
      "Epoch:  11     Batch:  432  /  468     Loss_generator:  0.6801326870918274     Loss_discriminator:  0.6831908226013184\n",
      "Epoch:  11     Batch:  433  /  468     Loss_generator:  0.6940189599990845     Loss_discriminator:  0.6664739847183228\n",
      "Epoch:  11     Batch:  434  /  468     Loss_generator:  0.6997828483581543     Loss_discriminator:  0.6865228414535522\n",
      "Epoch:  11     Batch:  435  /  468     Loss_generator:  0.7190496921539307     Loss_discriminator:  0.6822277307510376\n",
      "Epoch:  11     Batch:  436  /  468     Loss_generator:  0.6975697875022888     Loss_discriminator:  0.6879726648330688\n",
      "Epoch:  11     Batch:  437  /  468     Loss_generator:  0.6947941184043884     Loss_discriminator:  0.6857123374938965\n",
      "Epoch:  11     Batch:  438  /  468     Loss_generator:  0.6945001482963562     Loss_discriminator:  0.6904720664024353\n",
      "Epoch:  11     Batch:  439  /  468     Loss_generator:  0.6986395716667175     Loss_discriminator:  0.6786760091781616\n",
      "Epoch:  11     Batch:  440  /  468     Loss_generator:  0.6930392980575562     Loss_discriminator:  0.683570384979248\n",
      "Epoch:  11     Batch:  441  /  468     Loss_generator:  0.7226223945617676     Loss_discriminator:  0.6782791614532471\n",
      "Epoch:  11     Batch:  442  /  468     Loss_generator:  0.719703197479248     Loss_discriminator:  0.7000476121902466\n",
      "Epoch:  11     Batch:  443  /  468     Loss_generator:  0.7300717830657959     Loss_discriminator:  0.6972640156745911\n",
      "Epoch:  11     Batch:  444  /  468     Loss_generator:  0.7188372611999512     Loss_discriminator:  0.6892868280410767\n",
      "Epoch:  11     Batch:  445  /  468     Loss_generator:  0.7179632186889648     Loss_discriminator:  0.6767580509185791\n",
      "Epoch:  11     Batch:  446  /  468     Loss_generator:  0.6947335004806519     Loss_discriminator:  0.6895018219947815\n",
      "Epoch:  11     Batch:  447  /  468     Loss_generator:  0.6849403977394104     Loss_discriminator:  0.6880982518196106\n",
      "Epoch:  11     Batch:  448  /  468     Loss_generator:  0.7030693888664246     Loss_discriminator:  0.6859790086746216\n",
      "Epoch:  11     Batch:  449  /  468     Loss_generator:  0.715678870677948     Loss_discriminator:  0.6883665323257446\n",
      "Epoch:  11     Batch:  450  /  468     Loss_generator:  0.7356277704238892     Loss_discriminator:  0.6862118244171143\n",
      "Epoch:  11     Batch:  451  /  468     Loss_generator:  0.7378788590431213     Loss_discriminator:  0.6822249293327332\n",
      "Epoch:  11     Batch:  452  /  468     Loss_generator:  0.7179297208786011     Loss_discriminator:  0.6995850801467896\n",
      "Epoch:  11     Batch:  453  /  468     Loss_generator:  0.6926813721656799     Loss_discriminator:  0.6822077035903931\n",
      "Epoch:  11     Batch:  454  /  468     Loss_generator:  0.6769716739654541     Loss_discriminator:  0.7075241208076477\n",
      "Epoch:  11     Batch:  455  /  468     Loss_generator:  0.6842994689941406     Loss_discriminator:  0.6865172386169434\n",
      "Epoch:  11     Batch:  456  /  468     Loss_generator:  0.6885287761688232     Loss_discriminator:  0.6911316514015198\n",
      "Epoch:  11     Batch:  457  /  468     Loss_generator:  0.7248813509941101     Loss_discriminator:  0.6894874572753906\n",
      "Epoch:  11     Batch:  458  /  468     Loss_generator:  0.7725751399993896     Loss_discriminator:  0.6988765001296997\n",
      "Epoch:  11     Batch:  459  /  468     Loss_generator:  0.7504912614822388     Loss_discriminator:  0.6903265714645386\n",
      "Epoch:  11     Batch:  460  /  468     Loss_generator:  0.7394305467605591     Loss_discriminator:  0.6875954866409302\n",
      "Epoch:  11     Batch:  461  /  468     Loss_generator:  0.7020124197006226     Loss_discriminator:  0.6859821081161499\n",
      "Epoch:  11     Batch:  462  /  468     Loss_generator:  0.6820971965789795     Loss_discriminator:  0.6794429421424866\n",
      "Epoch:  11     Batch:  463  /  468     Loss_generator:  0.6557307839393616     Loss_discriminator:  0.6871915459632874\n",
      "Epoch:  11     Batch:  464  /  468     Loss_generator:  0.6850491762161255     Loss_discriminator:  0.6911345720291138\n",
      "Epoch:  11     Batch:  465  /  468     Loss_generator:  0.7038862705230713     Loss_discriminator:  0.6772762537002563\n",
      "Epoch:  11     Batch:  466  /  468     Loss_generator:  0.7505426406860352     Loss_discriminator:  0.6846994161605835\n",
      "Epoch:  11     Batch:  467  /  468     Loss_generator:  0.7615317702293396     Loss_discriminator:  0.6889233589172363\n",
      "Epoch:  12     Batch:  0  /  468     Loss_generator:  0.7743656039237976     Loss_discriminator:  0.6926642656326294\n",
      "Epoch:  12     Batch:  1  /  468     Loss_generator:  0.7152547836303711     Loss_discriminator:  0.6895214915275574\n",
      "Epoch:  12     Batch:  2  /  468     Loss_generator:  0.6860844492912292     Loss_discriminator:  0.68913733959198\n",
      "Epoch:  12     Batch:  3  /  468     Loss_generator:  0.6674237251281738     Loss_discriminator:  0.6832990646362305\n",
      "Epoch:  12     Batch:  4  /  468     Loss_generator:  0.6744310259819031     Loss_discriminator:  0.6948205828666687\n",
      "Epoch:  12     Batch:  5  /  468     Loss_generator:  0.6866092681884766     Loss_discriminator:  0.6894363164901733\n",
      "Epoch:  12     Batch:  6  /  468     Loss_generator:  0.7209755182266235     Loss_discriminator:  0.6864672303199768\n",
      "Epoch:  12     Batch:  7  /  468     Loss_generator:  0.7229567170143127     Loss_discriminator:  0.6921689510345459\n",
      "Epoch:  12     Batch:  8  /  468     Loss_generator:  0.7409579157829285     Loss_discriminator:  0.7010809183120728\n",
      "Epoch:  12     Batch:  9  /  468     Loss_generator:  0.6971577405929565     Loss_discriminator:  0.7103726863861084\n",
      "Epoch:  12     Batch:  10  /  468     Loss_generator:  0.6972869634628296     Loss_discriminator:  0.6884967088699341\n",
      "Epoch:  12     Batch:  11  /  468     Loss_generator:  0.6947602033615112     Loss_discriminator:  0.684054970741272\n",
      "Epoch:  12     Batch:  12  /  468     Loss_generator:  0.7361304759979248     Loss_discriminator:  0.687029242515564\n",
      "Epoch:  12     Batch:  13  /  468     Loss_generator:  0.7712659239768982     Loss_discriminator:  0.6790664792060852\n",
      "Epoch:  12     Batch:  14  /  468     Loss_generator:  0.7492476105690002     Loss_discriminator:  0.6777920722961426\n",
      "Epoch:  12     Batch:  15  /  468     Loss_generator:  0.727378249168396     Loss_discriminator:  0.6971673369407654\n",
      "Epoch:  12     Batch:  16  /  468     Loss_generator:  0.7055368423461914     Loss_discriminator:  0.6842175722122192\n",
      "Epoch:  12     Batch:  17  /  468     Loss_generator:  0.6683215498924255     Loss_discriminator:  0.6932129859924316\n",
      "Epoch:  12     Batch:  18  /  468     Loss_generator:  0.6497049331665039     Loss_discriminator:  0.6817800402641296\n",
      "Epoch:  12     Batch:  19  /  468     Loss_generator:  0.6420011520385742     Loss_discriminator:  0.6890579462051392\n",
      "Epoch:  12     Batch:  20  /  468     Loss_generator:  0.6929223537445068     Loss_discriminator:  0.6888003349304199\n",
      "Epoch:  12     Batch:  21  /  468     Loss_generator:  0.7112563848495483     Loss_discriminator:  0.6867597103118896\n",
      "Epoch:  12     Batch:  22  /  468     Loss_generator:  0.7394527196884155     Loss_discriminator:  0.6790645122528076\n",
      "Epoch:  12     Batch:  23  /  468     Loss_generator:  0.7524775266647339     Loss_discriminator:  0.7026259303092957\n",
      "Epoch:  12     Batch:  24  /  468     Loss_generator:  0.729916512966156     Loss_discriminator:  0.6785246133804321\n",
      "Epoch:  12     Batch:  25  /  468     Loss_generator:  0.710025429725647     Loss_discriminator:  0.6829190850257874\n",
      "Epoch:  12     Batch:  26  /  468     Loss_generator:  0.6982057094573975     Loss_discriminator:  0.6949081420898438\n",
      "Epoch:  12     Batch:  27  /  468     Loss_generator:  0.7248346209526062     Loss_discriminator:  0.6917962431907654\n",
      "Epoch:  12     Batch:  28  /  468     Loss_generator:  0.7087122201919556     Loss_discriminator:  0.680182695388794\n",
      "Epoch:  12     Batch:  29  /  468     Loss_generator:  0.7221872806549072     Loss_discriminator:  0.6915639638900757\n",
      "Epoch:  12     Batch:  30  /  468     Loss_generator:  0.7273598909378052     Loss_discriminator:  0.6831151843070984\n",
      "Epoch:  12     Batch:  31  /  468     Loss_generator:  0.6945818662643433     Loss_discriminator:  0.6912951469421387\n",
      "Epoch:  12     Batch:  32  /  468     Loss_generator:  0.6617168188095093     Loss_discriminator:  0.678147554397583\n",
      "Epoch:  12     Batch:  33  /  468     Loss_generator:  0.6584815979003906     Loss_discriminator:  0.6873007416725159\n",
      "Epoch:  12     Batch:  34  /  468     Loss_generator:  0.6952770948410034     Loss_discriminator:  0.6921186447143555\n",
      "Epoch:  12     Batch:  35  /  468     Loss_generator:  0.7655762434005737     Loss_discriminator:  0.6957480907440186\n",
      "Epoch:  12     Batch:  36  /  468     Loss_generator:  0.790369987487793     Loss_discriminator:  0.6783754825592041\n",
      "Epoch:  12     Batch:  37  /  468     Loss_generator:  0.7563979029655457     Loss_discriminator:  0.6896190047264099\n",
      "Epoch:  12     Batch:  38  /  468     Loss_generator:  0.686739981174469     Loss_discriminator:  0.6834114789962769\n",
      "Epoch:  12     Batch:  39  /  468     Loss_generator:  0.645777702331543     Loss_discriminator:  0.6929877400398254\n",
      "Epoch:  12     Batch:  40  /  468     Loss_generator:  0.6232917308807373     Loss_discriminator:  0.6934006214141846\n",
      "Epoch:  12     Batch:  41  /  468     Loss_generator:  0.6583446860313416     Loss_discriminator:  0.6847697496414185\n",
      "Epoch:  12     Batch:  42  /  468     Loss_generator:  0.724626898765564     Loss_discriminator:  0.6891794204711914\n",
      "Epoch:  12     Batch:  43  /  468     Loss_generator:  0.8068544268608093     Loss_discriminator:  0.6892455816268921\n",
      "Epoch:  12     Batch:  44  /  468     Loss_generator:  0.792577862739563     Loss_discriminator:  0.6830607652664185\n",
      "Epoch:  12     Batch:  45  /  468     Loss_generator:  0.7634892463684082     Loss_discriminator:  0.6788457632064819\n",
      "Epoch:  12     Batch:  46  /  468     Loss_generator:  0.6958692669868469     Loss_discriminator:  0.6826432347297668\n",
      "Epoch:  12     Batch:  47  /  468     Loss_generator:  0.6565790176391602     Loss_discriminator:  0.6934196949005127\n",
      "Epoch:  12     Batch:  48  /  468     Loss_generator:  0.6464520692825317     Loss_discriminator:  0.6912585496902466\n",
      "Epoch:  12     Batch:  49  /  468     Loss_generator:  0.6899649500846863     Loss_discriminator:  0.6888999938964844\n",
      "Epoch:  12     Batch:  50  /  468     Loss_generator:  0.6983729600906372     Loss_discriminator:  0.6897739768028259\n",
      "Epoch:  12     Batch:  51  /  468     Loss_generator:  0.7427058219909668     Loss_discriminator:  0.6762224435806274\n",
      "Epoch:  12     Batch:  52  /  468     Loss_generator:  0.7756496667861938     Loss_discriminator:  0.6766431331634521\n",
      "Epoch:  12     Batch:  53  /  468     Loss_generator:  0.7517619132995605     Loss_discriminator:  0.6757537126541138\n",
      "Epoch:  12     Batch:  54  /  468     Loss_generator:  0.7303717136383057     Loss_discriminator:  0.6735972762107849\n",
      "Epoch:  12     Batch:  55  /  468     Loss_generator:  0.7022455334663391     Loss_discriminator:  0.6930925846099854\n",
      "Epoch:  12     Batch:  56  /  468     Loss_generator:  0.6661676168441772     Loss_discriminator:  0.6903549432754517\n",
      "Epoch:  12     Batch:  57  /  468     Loss_generator:  0.6665953993797302     Loss_discriminator:  0.6749985218048096\n",
      "Epoch:  12     Batch:  58  /  468     Loss_generator:  0.6634359359741211     Loss_discriminator:  0.6877909302711487\n",
      "Epoch:  12     Batch:  59  /  468     Loss_generator:  0.7122036218643188     Loss_discriminator:  0.6890628337860107\n",
      "Epoch:  12     Batch:  60  /  468     Loss_generator:  0.7526652812957764     Loss_discriminator:  0.6980106234550476\n",
      "Epoch:  12     Batch:  61  /  468     Loss_generator:  0.738102376461029     Loss_discriminator:  0.6874940991401672\n",
      "Epoch:  12     Batch:  62  /  468     Loss_generator:  0.7259520888328552     Loss_discriminator:  0.6825814843177795\n",
      "Epoch:  12     Batch:  63  /  468     Loss_generator:  0.687725841999054     Loss_discriminator:  0.6760973930358887\n",
      "Epoch:  12     Batch:  64  /  468     Loss_generator:  0.6932428479194641     Loss_discriminator:  0.6900146007537842\n",
      "Epoch:  12     Batch:  65  /  468     Loss_generator:  0.7103961706161499     Loss_discriminator:  0.6921771764755249\n",
      "Epoch:  12     Batch:  66  /  468     Loss_generator:  0.7390535473823547     Loss_discriminator:  0.6911441087722778\n",
      "Epoch:  12     Batch:  67  /  468     Loss_generator:  0.7335535287857056     Loss_discriminator:  0.6987206339836121\n",
      "Epoch:  12     Batch:  68  /  468     Loss_generator:  0.7296386957168579     Loss_discriminator:  0.6821773052215576\n",
      "Epoch:  12     Batch:  69  /  468     Loss_generator:  0.722475528717041     Loss_discriminator:  0.6788303852081299\n",
      "Epoch:  12     Batch:  70  /  468     Loss_generator:  0.7239037752151489     Loss_discriminator:  0.6835222244262695\n",
      "Epoch:  12     Batch:  71  /  468     Loss_generator:  0.6881836652755737     Loss_discriminator:  0.6822781562805176\n",
      "Epoch:  12     Batch:  72  /  468     Loss_generator:  0.6641994118690491     Loss_discriminator:  0.6905809044837952\n",
      "Epoch:  12     Batch:  73  /  468     Loss_generator:  0.6977123618125916     Loss_discriminator:  0.682878851890564\n",
      "Epoch:  12     Batch:  74  /  468     Loss_generator:  0.7222222685813904     Loss_discriminator:  0.6829218864440918\n",
      "Epoch:  12     Batch:  75  /  468     Loss_generator:  0.721215546131134     Loss_discriminator:  0.6823326349258423\n",
      "Epoch:  12     Batch:  76  /  468     Loss_generator:  0.7311984300613403     Loss_discriminator:  0.6882266402244568\n",
      "Epoch:  12     Batch:  77  /  468     Loss_generator:  0.7180681228637695     Loss_discriminator:  0.6725171804428101\n",
      "Epoch:  12     Batch:  78  /  468     Loss_generator:  0.7113473415374756     Loss_discriminator:  0.6763285398483276\n",
      "Epoch:  12     Batch:  79  /  468     Loss_generator:  0.7080434560775757     Loss_discriminator:  0.6880749464035034\n",
      "Epoch:  12     Batch:  80  /  468     Loss_generator:  0.7034331560134888     Loss_discriminator:  0.6787258386611938\n",
      "Epoch:  12     Batch:  81  /  468     Loss_generator:  0.6889806985855103     Loss_discriminator:  0.6882814168930054\n",
      "Epoch:  12     Batch:  82  /  468     Loss_generator:  0.6958473920822144     Loss_discriminator:  0.6937865018844604\n",
      "Epoch:  12     Batch:  83  /  468     Loss_generator:  0.7481778860092163     Loss_discriminator:  0.6886149644851685\n",
      "Epoch:  12     Batch:  84  /  468     Loss_generator:  0.7334455847740173     Loss_discriminator:  0.6760510206222534\n",
      "Epoch:  12     Batch:  85  /  468     Loss_generator:  0.7294430732727051     Loss_discriminator:  0.6922429203987122\n",
      "Epoch:  12     Batch:  86  /  468     Loss_generator:  0.702582836151123     Loss_discriminator:  0.6892948150634766\n",
      "Epoch:  12     Batch:  87  /  468     Loss_generator:  0.6810070276260376     Loss_discriminator:  0.6880484819412231\n",
      "Epoch:  12     Batch:  88  /  468     Loss_generator:  0.6907716393470764     Loss_discriminator:  0.6783311367034912\n",
      "Epoch:  12     Batch:  89  /  468     Loss_generator:  0.7026249170303345     Loss_discriminator:  0.6907250881195068\n",
      "Epoch:  12     Batch:  90  /  468     Loss_generator:  0.7113097906112671     Loss_discriminator:  0.6824902296066284\n",
      "Epoch:  12     Batch:  91  /  468     Loss_generator:  0.7339572310447693     Loss_discriminator:  0.6847090125083923\n",
      "Epoch:  12     Batch:  92  /  468     Loss_generator:  0.7546350955963135     Loss_discriminator:  0.6873947381973267\n",
      "Epoch:  12     Batch:  93  /  468     Loss_generator:  0.7352659702301025     Loss_discriminator:  0.6872355937957764\n",
      "Epoch:  12     Batch:  94  /  468     Loss_generator:  0.718525767326355     Loss_discriminator:  0.6875662803649902\n",
      "Epoch:  12     Batch:  95  /  468     Loss_generator:  0.6690893173217773     Loss_discriminator:  0.6912245750427246\n",
      "Epoch:  12     Batch:  96  /  468     Loss_generator:  0.6565119028091431     Loss_discriminator:  0.6775954961776733\n",
      "Epoch:  12     Batch:  97  /  468     Loss_generator:  0.6955519318580627     Loss_discriminator:  0.6930897235870361\n",
      "Epoch:  12     Batch:  98  /  468     Loss_generator:  0.7334745526313782     Loss_discriminator:  0.6879987716674805\n",
      "Epoch:  12     Batch:  99  /  468     Loss_generator:  0.7469775080680847     Loss_discriminator:  0.6848459243774414\n",
      "Epoch:  12     Batch:  100  /  468     Loss_generator:  0.740018904209137     Loss_discriminator:  0.6889060735702515\n",
      "Epoch:  12     Batch:  101  /  468     Loss_generator:  0.7067110538482666     Loss_discriminator:  0.6970261335372925\n",
      "Epoch:  12     Batch:  102  /  468     Loss_generator:  0.6858558654785156     Loss_discriminator:  0.6763873100280762\n",
      "Epoch:  12     Batch:  103  /  468     Loss_generator:  0.6796063184738159     Loss_discriminator:  0.6933069229125977\n",
      "Epoch:  12     Batch:  104  /  468     Loss_generator:  0.7183097004890442     Loss_discriminator:  0.6858408451080322\n",
      "Epoch:  12     Batch:  105  /  468     Loss_generator:  0.7217893600463867     Loss_discriminator:  0.6995382905006409\n",
      "Epoch:  12     Batch:  106  /  468     Loss_generator:  0.7587972283363342     Loss_discriminator:  0.6883909702301025\n",
      "Epoch:  12     Batch:  107  /  468     Loss_generator:  0.7219588756561279     Loss_discriminator:  0.6765064597129822\n",
      "Epoch:  12     Batch:  108  /  468     Loss_generator:  0.7164117097854614     Loss_discriminator:  0.6818109750747681\n",
      "Epoch:  12     Batch:  109  /  468     Loss_generator:  0.7116760611534119     Loss_discriminator:  0.6879616379737854\n",
      "Epoch:  12     Batch:  110  /  468     Loss_generator:  0.6742592453956604     Loss_discriminator:  0.6853177547454834\n",
      "Epoch:  12     Batch:  111  /  468     Loss_generator:  0.6606350541114807     Loss_discriminator:  0.6836938858032227\n",
      "Epoch:  12     Batch:  112  /  468     Loss_generator:  0.6941099166870117     Loss_discriminator:  0.6933486461639404\n",
      "Epoch:  12     Batch:  113  /  468     Loss_generator:  0.7442824244499207     Loss_discriminator:  0.6859492063522339\n",
      "Epoch:  12     Batch:  114  /  468     Loss_generator:  0.7739684581756592     Loss_discriminator:  0.6756677031517029\n",
      "Epoch:  12     Batch:  115  /  468     Loss_generator:  0.7678120136260986     Loss_discriminator:  0.6904797554016113\n",
      "Epoch:  12     Batch:  116  /  468     Loss_generator:  0.7391625046730042     Loss_discriminator:  0.6794348955154419\n",
      "Epoch:  12     Batch:  117  /  468     Loss_generator:  0.6963235139846802     Loss_discriminator:  0.6928582787513733\n",
      "Epoch:  12     Batch:  118  /  468     Loss_generator:  0.6831626296043396     Loss_discriminator:  0.6860865354537964\n",
      "Epoch:  12     Batch:  119  /  468     Loss_generator:  0.6961702108383179     Loss_discriminator:  0.6854004263877869\n",
      "Epoch:  12     Batch:  120  /  468     Loss_generator:  0.699211061000824     Loss_discriminator:  0.6906099915504456\n",
      "Epoch:  12     Batch:  121  /  468     Loss_generator:  0.7182859778404236     Loss_discriminator:  0.6808807253837585\n",
      "Epoch:  12     Batch:  122  /  468     Loss_generator:  0.7160042524337769     Loss_discriminator:  0.69012850522995\n",
      "Epoch:  12     Batch:  123  /  468     Loss_generator:  0.7177474498748779     Loss_discriminator:  0.6743429899215698\n",
      "Epoch:  12     Batch:  124  /  468     Loss_generator:  0.7033590078353882     Loss_discriminator:  0.6723031401634216\n",
      "Epoch:  12     Batch:  125  /  468     Loss_generator:  0.6905025243759155     Loss_discriminator:  0.6826719641685486\n",
      "Epoch:  12     Batch:  126  /  468     Loss_generator:  0.7315403819084167     Loss_discriminator:  0.6943222284317017\n",
      "Epoch:  12     Batch:  127  /  468     Loss_generator:  0.7052997350692749     Loss_discriminator:  0.6944618225097656\n",
      "Epoch:  12     Batch:  128  /  468     Loss_generator:  0.7015626430511475     Loss_discriminator:  0.690934956073761\n",
      "Epoch:  12     Batch:  129  /  468     Loss_generator:  0.6964820027351379     Loss_discriminator:  0.6865797638893127\n",
      "Epoch:  12     Batch:  130  /  468     Loss_generator:  0.7173244953155518     Loss_discriminator:  0.6847560405731201\n",
      "Epoch:  12     Batch:  131  /  468     Loss_generator:  0.7034123539924622     Loss_discriminator:  0.6836309432983398\n",
      "Epoch:  12     Batch:  132  /  468     Loss_generator:  0.6784752607345581     Loss_discriminator:  0.6847178936004639\n",
      "Epoch:  12     Batch:  133  /  468     Loss_generator:  0.6890053749084473     Loss_discriminator:  0.6868630051612854\n",
      "Epoch:  12     Batch:  134  /  468     Loss_generator:  0.7195131778717041     Loss_discriminator:  0.694522500038147\n",
      "Epoch:  12     Batch:  135  /  468     Loss_generator:  0.712940514087677     Loss_discriminator:  0.6763401031494141\n",
      "Epoch:  12     Batch:  136  /  468     Loss_generator:  0.7188065052032471     Loss_discriminator:  0.6979761123657227\n",
      "Epoch:  12     Batch:  137  /  468     Loss_generator:  0.7132196426391602     Loss_discriminator:  0.6939178705215454\n",
      "Epoch:  12     Batch:  138  /  468     Loss_generator:  0.6899098753929138     Loss_discriminator:  0.6891124844551086\n",
      "Epoch:  12     Batch:  139  /  468     Loss_generator:  0.6936784982681274     Loss_discriminator:  0.6830384731292725\n",
      "Epoch:  12     Batch:  140  /  468     Loss_generator:  0.7116684913635254     Loss_discriminator:  0.6870996952056885\n",
      "Epoch:  12     Batch:  141  /  468     Loss_generator:  0.7033486366271973     Loss_discriminator:  0.6933797597885132\n",
      "Epoch:  12     Batch:  142  /  468     Loss_generator:  0.7197862267494202     Loss_discriminator:  0.6888636350631714\n",
      "Epoch:  12     Batch:  143  /  468     Loss_generator:  0.7144684791564941     Loss_discriminator:  0.6812801361083984\n",
      "Epoch:  12     Batch:  144  /  468     Loss_generator:  0.7089993953704834     Loss_discriminator:  0.685556948184967\n",
      "Epoch:  12     Batch:  145  /  468     Loss_generator:  0.707091748714447     Loss_discriminator:  0.6971160173416138\n",
      "Epoch:  12     Batch:  146  /  468     Loss_generator:  0.7060670256614685     Loss_discriminator:  0.6862691640853882\n",
      "Epoch:  12     Batch:  147  /  468     Loss_generator:  0.702285647392273     Loss_discriminator:  0.6746068596839905\n",
      "Epoch:  12     Batch:  148  /  468     Loss_generator:  0.7383289933204651     Loss_discriminator:  0.6988089084625244\n",
      "Epoch:  12     Batch:  149  /  468     Loss_generator:  0.7262922525405884     Loss_discriminator:  0.6908004879951477\n",
      "Epoch:  12     Batch:  150  /  468     Loss_generator:  0.6880451440811157     Loss_discriminator:  0.6776747703552246\n",
      "Epoch:  12     Batch:  151  /  468     Loss_generator:  0.6889958381652832     Loss_discriminator:  0.6817126870155334\n",
      "Epoch:  12     Batch:  152  /  468     Loss_generator:  0.6742616891860962     Loss_discriminator:  0.6739640235900879\n",
      "Epoch:  12     Batch:  153  /  468     Loss_generator:  0.6868802309036255     Loss_discriminator:  0.6940349340438843\n",
      "Epoch:  12     Batch:  154  /  468     Loss_generator:  0.7354118824005127     Loss_discriminator:  0.690521776676178\n",
      "Epoch:  12     Batch:  155  /  468     Loss_generator:  0.8022593259811401     Loss_discriminator:  0.6815364360809326\n",
      "Epoch:  12     Batch:  156  /  468     Loss_generator:  0.8027805089950562     Loss_discriminator:  0.6872594356536865\n",
      "Epoch:  12     Batch:  157  /  468     Loss_generator:  0.7377511262893677     Loss_discriminator:  0.688206672668457\n",
      "Epoch:  12     Batch:  158  /  468     Loss_generator:  0.6664126515388489     Loss_discriminator:  0.6823773384094238\n",
      "Epoch:  12     Batch:  159  /  468     Loss_generator:  0.6333561539649963     Loss_discriminator:  0.6770702600479126\n",
      "Epoch:  12     Batch:  160  /  468     Loss_generator:  0.6518657207489014     Loss_discriminator:  0.690322995185852\n",
      "Epoch:  12     Batch:  161  /  468     Loss_generator:  0.6952338218688965     Loss_discriminator:  0.6810780167579651\n",
      "Epoch:  12     Batch:  162  /  468     Loss_generator:  0.7562494874000549     Loss_discriminator:  0.6937813758850098\n",
      "Epoch:  12     Batch:  163  /  468     Loss_generator:  0.8152706027030945     Loss_discriminator:  0.6955093145370483\n",
      "Epoch:  12     Batch:  164  /  468     Loss_generator:  0.7851383686065674     Loss_discriminator:  0.6923180818557739\n",
      "Epoch:  12     Batch:  165  /  468     Loss_generator:  0.730521023273468     Loss_discriminator:  0.6783733367919922\n",
      "Epoch:  12     Batch:  166  /  468     Loss_generator:  0.6884812116622925     Loss_discriminator:  0.6902585625648499\n",
      "Epoch:  12     Batch:  167  /  468     Loss_generator:  0.6473559141159058     Loss_discriminator:  0.6984868049621582\n",
      "Epoch:  12     Batch:  168  /  468     Loss_generator:  0.6504197120666504     Loss_discriminator:  0.6849563121795654\n",
      "Epoch:  12     Batch:  169  /  468     Loss_generator:  0.6724722981452942     Loss_discriminator:  0.6816328167915344\n",
      "Epoch:  12     Batch:  170  /  468     Loss_generator:  0.7062007188796997     Loss_discriminator:  0.6842459440231323\n",
      "Epoch:  12     Batch:  171  /  468     Loss_generator:  0.7655919194221497     Loss_discriminator:  0.6895694136619568\n",
      "Epoch:  12     Batch:  172  /  468     Loss_generator:  0.7631161212921143     Loss_discriminator:  0.690110445022583\n",
      "Epoch:  12     Batch:  173  /  468     Loss_generator:  0.753108561038971     Loss_discriminator:  0.6885180473327637\n",
      "Epoch:  12     Batch:  174  /  468     Loss_generator:  0.7269271612167358     Loss_discriminator:  0.6904938220977783\n",
      "Epoch:  12     Batch:  175  /  468     Loss_generator:  0.6899044513702393     Loss_discriminator:  0.6917707920074463\n",
      "Epoch:  12     Batch:  176  /  468     Loss_generator:  0.6582236289978027     Loss_discriminator:  0.697347104549408\n",
      "Epoch:  12     Batch:  177  /  468     Loss_generator:  0.6435772180557251     Loss_discriminator:  0.6737240552902222\n",
      "Epoch:  12     Batch:  178  /  468     Loss_generator:  0.6756291389465332     Loss_discriminator:  0.6930347681045532\n",
      "Epoch:  12     Batch:  179  /  468     Loss_generator:  0.732894778251648     Loss_discriminator:  0.6800196170806885\n",
      "Epoch:  12     Batch:  180  /  468     Loss_generator:  0.7469302415847778     Loss_discriminator:  0.6871601939201355\n",
      "Epoch:  12     Batch:  181  /  468     Loss_generator:  0.7631252408027649     Loss_discriminator:  0.6905918717384338\n",
      "Epoch:  12     Batch:  182  /  468     Loss_generator:  0.7359299063682556     Loss_discriminator:  0.6968501806259155\n",
      "Epoch:  12     Batch:  183  /  468     Loss_generator:  0.7081671953201294     Loss_discriminator:  0.6907897591590881\n",
      "Epoch:  12     Batch:  184  /  468     Loss_generator:  0.6767325401306152     Loss_discriminator:  0.6754124760627747\n",
      "Epoch:  12     Batch:  185  /  468     Loss_generator:  0.6848604679107666     Loss_discriminator:  0.6861545443534851\n",
      "Epoch:  12     Batch:  186  /  468     Loss_generator:  0.6737897396087646     Loss_discriminator:  0.692922830581665\n",
      "Epoch:  12     Batch:  187  /  468     Loss_generator:  0.7026005387306213     Loss_discriminator:  0.6945004463195801\n",
      "Epoch:  12     Batch:  188  /  468     Loss_generator:  0.7091255187988281     Loss_discriminator:  0.6830465793609619\n",
      "Epoch:  12     Batch:  189  /  468     Loss_generator:  0.7050577402114868     Loss_discriminator:  0.6738793849945068\n",
      "Epoch:  12     Batch:  190  /  468     Loss_generator:  0.7026162147521973     Loss_discriminator:  0.6775021553039551\n",
      "Epoch:  12     Batch:  191  /  468     Loss_generator:  0.6846129298210144     Loss_discriminator:  0.6887071132659912\n",
      "Epoch:  12     Batch:  192  /  468     Loss_generator:  0.7149083018302917     Loss_discriminator:  0.6816614270210266\n",
      "Epoch:  12     Batch:  193  /  468     Loss_generator:  0.7063426971435547     Loss_discriminator:  0.6920831203460693\n",
      "Epoch:  12     Batch:  194  /  468     Loss_generator:  0.7313425540924072     Loss_discriminator:  0.6761099696159363\n",
      "Epoch:  12     Batch:  195  /  468     Loss_generator:  0.6840872764587402     Loss_discriminator:  0.679031491279602\n",
      "Epoch:  12     Batch:  196  /  468     Loss_generator:  0.7135571241378784     Loss_discriminator:  0.6877655982971191\n",
      "Epoch:  12     Batch:  197  /  468     Loss_generator:  0.6893354654312134     Loss_discriminator:  0.6765652894973755\n",
      "Epoch:  12     Batch:  198  /  468     Loss_generator:  0.6792056560516357     Loss_discriminator:  0.6926352977752686\n",
      "Epoch:  12     Batch:  199  /  468     Loss_generator:  0.6859664916992188     Loss_discriminator:  0.696615993976593\n",
      "Epoch:  12     Batch:  200  /  468     Loss_generator:  0.7112612128257751     Loss_discriminator:  0.6907137036323547\n",
      "Epoch:  12     Batch:  201  /  468     Loss_generator:  0.740461528301239     Loss_discriminator:  0.681358814239502\n",
      "Epoch:  12     Batch:  202  /  468     Loss_generator:  0.7513578534126282     Loss_discriminator:  0.6855118274688721\n",
      "Epoch:  12     Batch:  203  /  468     Loss_generator:  0.7332961559295654     Loss_discriminator:  0.6864900588989258\n",
      "Epoch:  12     Batch:  204  /  468     Loss_generator:  0.6961311101913452     Loss_discriminator:  0.6729205846786499\n",
      "Epoch:  12     Batch:  205  /  468     Loss_generator:  0.6807582378387451     Loss_discriminator:  0.6934831142425537\n",
      "Epoch:  12     Batch:  206  /  468     Loss_generator:  0.6595991849899292     Loss_discriminator:  0.6747689843177795\n",
      "Epoch:  12     Batch:  207  /  468     Loss_generator:  0.6622551083564758     Loss_discriminator:  0.6756238341331482\n",
      "Epoch:  12     Batch:  208  /  468     Loss_generator:  0.6830762028694153     Loss_discriminator:  0.6883600950241089\n",
      "Epoch:  12     Batch:  209  /  468     Loss_generator:  0.7560160160064697     Loss_discriminator:  0.6938638687133789\n",
      "Epoch:  12     Batch:  210  /  468     Loss_generator:  0.7980899810791016     Loss_discriminator:  0.6876490712165833\n",
      "Epoch:  12     Batch:  211  /  468     Loss_generator:  0.7486765384674072     Loss_discriminator:  0.7006734609603882\n",
      "Epoch:  12     Batch:  212  /  468     Loss_generator:  0.7092212438583374     Loss_discriminator:  0.6862781047821045\n",
      "Epoch:  12     Batch:  213  /  468     Loss_generator:  0.6609703302383423     Loss_discriminator:  0.6913444399833679\n",
      "Epoch:  12     Batch:  214  /  468     Loss_generator:  0.6781161427497864     Loss_discriminator:  0.699177622795105\n",
      "Epoch:  12     Batch:  215  /  468     Loss_generator:  0.7027450799942017     Loss_discriminator:  0.6929036974906921\n",
      "Epoch:  12     Batch:  216  /  468     Loss_generator:  0.703894853591919     Loss_discriminator:  0.6896910667419434\n",
      "Epoch:  12     Batch:  217  /  468     Loss_generator:  0.726351797580719     Loss_discriminator:  0.6879088878631592\n",
      "Epoch:  12     Batch:  218  /  468     Loss_generator:  0.733660101890564     Loss_discriminator:  0.6941475868225098\n",
      "Epoch:  12     Batch:  219  /  468     Loss_generator:  0.7135568261146545     Loss_discriminator:  0.6881790161132812\n",
      "Epoch:  12     Batch:  220  /  468     Loss_generator:  0.7167752981185913     Loss_discriminator:  0.6856434941291809\n",
      "Epoch:  12     Batch:  221  /  468     Loss_generator:  0.7209240794181824     Loss_discriminator:  0.6941173672676086\n",
      "Epoch:  12     Batch:  222  /  468     Loss_generator:  0.6853748559951782     Loss_discriminator:  0.6907440423965454\n",
      "Epoch:  12     Batch:  223  /  468     Loss_generator:  0.7077854871749878     Loss_discriminator:  0.6874609589576721\n",
      "Epoch:  12     Batch:  224  /  468     Loss_generator:  0.719833254814148     Loss_discriminator:  0.6871340870857239\n",
      "Epoch:  12     Batch:  225  /  468     Loss_generator:  0.7113759517669678     Loss_discriminator:  0.6833454370498657\n",
      "Epoch:  12     Batch:  226  /  468     Loss_generator:  0.7017260193824768     Loss_discriminator:  0.6776049137115479\n",
      "Epoch:  12     Batch:  227  /  468     Loss_generator:  0.7090381383895874     Loss_discriminator:  0.6822109222412109\n",
      "Epoch:  12     Batch:  228  /  468     Loss_generator:  0.699566662311554     Loss_discriminator:  0.6820375919342041\n",
      "Epoch:  12     Batch:  229  /  468     Loss_generator:  0.6842502355575562     Loss_discriminator:  0.6835758686065674\n",
      "Epoch:  12     Batch:  230  /  468     Loss_generator:  0.7016184329986572     Loss_discriminator:  0.6957871317863464\n",
      "Epoch:  12     Batch:  231  /  468     Loss_generator:  0.7160701751708984     Loss_discriminator:  0.6838683485984802\n",
      "Epoch:  12     Batch:  232  /  468     Loss_generator:  0.7392421960830688     Loss_discriminator:  0.6875848770141602\n",
      "Epoch:  12     Batch:  233  /  468     Loss_generator:  0.7091479897499084     Loss_discriminator:  0.6934294700622559\n",
      "Epoch:  12     Batch:  234  /  468     Loss_generator:  0.7093874216079712     Loss_discriminator:  0.6862521171569824\n",
      "Epoch:  12     Batch:  235  /  468     Loss_generator:  0.6998838186264038     Loss_discriminator:  0.6855090260505676\n",
      "Epoch:  12     Batch:  236  /  468     Loss_generator:  0.7106508612632751     Loss_discriminator:  0.6850549578666687\n",
      "Epoch:  12     Batch:  237  /  468     Loss_generator:  0.7117304801940918     Loss_discriminator:  0.6788052916526794\n",
      "Epoch:  12     Batch:  238  /  468     Loss_generator:  0.7266486883163452     Loss_discriminator:  0.6854641437530518\n",
      "Epoch:  12     Batch:  239  /  468     Loss_generator:  0.6895861029624939     Loss_discriminator:  0.6858465075492859\n",
      "Epoch:  12     Batch:  240  /  468     Loss_generator:  0.6982829570770264     Loss_discriminator:  0.6827189922332764\n",
      "Epoch:  12     Batch:  241  /  468     Loss_generator:  0.7056383490562439     Loss_discriminator:  0.6812078952789307\n",
      "Epoch:  12     Batch:  242  /  468     Loss_generator:  0.7204540371894836     Loss_discriminator:  0.6825646758079529\n",
      "Epoch:  12     Batch:  243  /  468     Loss_generator:  0.7085795402526855     Loss_discriminator:  0.684761643409729\n",
      "Epoch:  12     Batch:  244  /  468     Loss_generator:  0.70146244764328     Loss_discriminator:  0.6869275569915771\n",
      "Epoch:  12     Batch:  245  /  468     Loss_generator:  0.6999824047088623     Loss_discriminator:  0.6903944611549377\n",
      "Epoch:  12     Batch:  246  /  468     Loss_generator:  0.6705156564712524     Loss_discriminator:  0.6801674962043762\n",
      "Epoch:  12     Batch:  247  /  468     Loss_generator:  0.688862144947052     Loss_discriminator:  0.6778554320335388\n",
      "Epoch:  12     Batch:  248  /  468     Loss_generator:  0.7182031273841858     Loss_discriminator:  0.6857948303222656\n",
      "Epoch:  12     Batch:  249  /  468     Loss_generator:  0.7425171136856079     Loss_discriminator:  0.6879241466522217\n",
      "Epoch:  12     Batch:  250  /  468     Loss_generator:  0.7274312973022461     Loss_discriminator:  0.6937321424484253\n",
      "Epoch:  12     Batch:  251  /  468     Loss_generator:  0.7035055756568909     Loss_discriminator:  0.6911188364028931\n",
      "Epoch:  12     Batch:  252  /  468     Loss_generator:  0.690497636795044     Loss_discriminator:  0.6810368299484253\n",
      "Epoch:  12     Batch:  253  /  468     Loss_generator:  0.7105177044868469     Loss_discriminator:  0.6737773418426514\n",
      "Epoch:  12     Batch:  254  /  468     Loss_generator:  0.7122422456741333     Loss_discriminator:  0.686508059501648\n",
      "Epoch:  12     Batch:  255  /  468     Loss_generator:  0.6886357069015503     Loss_discriminator:  0.696091890335083\n",
      "Epoch:  12     Batch:  256  /  468     Loss_generator:  0.6978411078453064     Loss_discriminator:  0.6738616824150085\n",
      "Epoch:  12     Batch:  257  /  468     Loss_generator:  0.7040108442306519     Loss_discriminator:  0.6743869185447693\n",
      "Epoch:  12     Batch:  258  /  468     Loss_generator:  0.7155207395553589     Loss_discriminator:  0.6718074083328247\n",
      "Epoch:  12     Batch:  259  /  468     Loss_generator:  0.700049102306366     Loss_discriminator:  0.6745829582214355\n",
      "Epoch:  12     Batch:  260  /  468     Loss_generator:  0.7095463275909424     Loss_discriminator:  0.6921138167381287\n",
      "Epoch:  12     Batch:  261  /  468     Loss_generator:  0.7315012812614441     Loss_discriminator:  0.6825708150863647\n",
      "Epoch:  12     Batch:  262  /  468     Loss_generator:  0.7156193852424622     Loss_discriminator:  0.673312246799469\n",
      "Epoch:  12     Batch:  263  /  468     Loss_generator:  0.6927849054336548     Loss_discriminator:  0.681801974773407\n",
      "Epoch:  12     Batch:  264  /  468     Loss_generator:  0.6627991199493408     Loss_discriminator:  0.6839413642883301\n",
      "Epoch:  12     Batch:  265  /  468     Loss_generator:  0.6712565422058105     Loss_discriminator:  0.6719738245010376\n",
      "Epoch:  12     Batch:  266  /  468     Loss_generator:  0.7232437133789062     Loss_discriminator:  0.687933623790741\n",
      "Epoch:  12     Batch:  267  /  468     Loss_generator:  0.768169105052948     Loss_discriminator:  0.6817948222160339\n",
      "Epoch:  12     Batch:  268  /  468     Loss_generator:  0.7676246762275696     Loss_discriminator:  0.6824585199356079\n",
      "Epoch:  12     Batch:  269  /  468     Loss_generator:  0.7321659326553345     Loss_discriminator:  0.6922208070755005\n",
      "Epoch:  12     Batch:  270  /  468     Loss_generator:  0.6865567564964294     Loss_discriminator:  0.6856789588928223\n",
      "Epoch:  12     Batch:  271  /  468     Loss_generator:  0.6762276291847229     Loss_discriminator:  0.6813805103302002\n",
      "Epoch:  12     Batch:  272  /  468     Loss_generator:  0.6797206401824951     Loss_discriminator:  0.6957032084465027\n",
      "Epoch:  12     Batch:  273  /  468     Loss_generator:  0.718469500541687     Loss_discriminator:  0.6989011168479919\n",
      "Epoch:  12     Batch:  274  /  468     Loss_generator:  0.7227495908737183     Loss_discriminator:  0.6765660643577576\n",
      "Epoch:  12     Batch:  275  /  468     Loss_generator:  0.7167482972145081     Loss_discriminator:  0.6863991022109985\n",
      "Epoch:  12     Batch:  276  /  468     Loss_generator:  0.7117406129837036     Loss_discriminator:  0.6955891251564026\n",
      "Epoch:  12     Batch:  277  /  468     Loss_generator:  0.7002067565917969     Loss_discriminator:  0.6779180765151978\n",
      "Epoch:  12     Batch:  278  /  468     Loss_generator:  0.6949090957641602     Loss_discriminator:  0.6672481298446655\n",
      "Epoch:  12     Batch:  279  /  468     Loss_generator:  0.7267141342163086     Loss_discriminator:  0.6915785074234009\n",
      "Epoch:  12     Batch:  280  /  468     Loss_generator:  0.7099987864494324     Loss_discriminator:  0.6961288452148438\n",
      "Epoch:  12     Batch:  281  /  468     Loss_generator:  0.7233262062072754     Loss_discriminator:  0.685490608215332\n",
      "Epoch:  12     Batch:  282  /  468     Loss_generator:  0.7472728490829468     Loss_discriminator:  0.6690143346786499\n",
      "Epoch:  12     Batch:  283  /  468     Loss_generator:  0.7118961215019226     Loss_discriminator:  0.6935684680938721\n",
      "Epoch:  12     Batch:  284  /  468     Loss_generator:  0.6903549432754517     Loss_discriminator:  0.6768120527267456\n",
      "Epoch:  12     Batch:  285  /  468     Loss_generator:  0.6860993504524231     Loss_discriminator:  0.6838078498840332\n",
      "Epoch:  12     Batch:  286  /  468     Loss_generator:  0.6761554479598999     Loss_discriminator:  0.6957651972770691\n",
      "Epoch:  12     Batch:  287  /  468     Loss_generator:  0.6972132921218872     Loss_discriminator:  0.6814311742782593\n",
      "Epoch:  12     Batch:  288  /  468     Loss_generator:  0.7310203909873962     Loss_discriminator:  0.680854082107544\n",
      "Epoch:  12     Batch:  289  /  468     Loss_generator:  0.7039365768432617     Loss_discriminator:  0.6876446604728699\n",
      "Epoch:  12     Batch:  290  /  468     Loss_generator:  0.6934841871261597     Loss_discriminator:  0.6699368953704834\n",
      "Epoch:  12     Batch:  291  /  468     Loss_generator:  0.6933537721633911     Loss_discriminator:  0.6823543906211853\n",
      "Epoch:  12     Batch:  292  /  468     Loss_generator:  0.695357620716095     Loss_discriminator:  0.690222442150116\n",
      "Epoch:  12     Batch:  293  /  468     Loss_generator:  0.6985206007957458     Loss_discriminator:  0.6893783807754517\n",
      "Epoch:  12     Batch:  294  /  468     Loss_generator:  0.713786780834198     Loss_discriminator:  0.6929816007614136\n",
      "Epoch:  12     Batch:  295  /  468     Loss_generator:  0.7319029569625854     Loss_discriminator:  0.6791633367538452\n",
      "Epoch:  12     Batch:  296  /  468     Loss_generator:  0.7450108528137207     Loss_discriminator:  0.6755378246307373\n",
      "Epoch:  12     Batch:  297  /  468     Loss_generator:  0.7496270537376404     Loss_discriminator:  0.6817939281463623\n",
      "Epoch:  12     Batch:  298  /  468     Loss_generator:  0.7480109930038452     Loss_discriminator:  0.6939788460731506\n",
      "Epoch:  12     Batch:  299  /  468     Loss_generator:  0.7055811882019043     Loss_discriminator:  0.6716591715812683\n",
      "Epoch:  12     Batch:  300  /  468     Loss_generator:  0.6978576183319092     Loss_discriminator:  0.6793900728225708\n",
      "Epoch:  12     Batch:  301  /  468     Loss_generator:  0.6765438914299011     Loss_discriminator:  0.6920919418334961\n",
      "Epoch:  12     Batch:  302  /  468     Loss_generator:  0.6672810316085815     Loss_discriminator:  0.6948295831680298\n",
      "Epoch:  12     Batch:  303  /  468     Loss_generator:  0.6657678484916687     Loss_discriminator:  0.6861370801925659\n",
      "Epoch:  12     Batch:  304  /  468     Loss_generator:  0.6817944645881653     Loss_discriminator:  0.685129702091217\n",
      "Epoch:  12     Batch:  305  /  468     Loss_generator:  0.7192709445953369     Loss_discriminator:  0.6849645972251892\n",
      "Epoch:  12     Batch:  306  /  468     Loss_generator:  0.7316450476646423     Loss_discriminator:  0.6916553974151611\n",
      "Epoch:  12     Batch:  307  /  468     Loss_generator:  0.7241823673248291     Loss_discriminator:  0.6687532663345337\n",
      "Epoch:  12     Batch:  308  /  468     Loss_generator:  0.7214188575744629     Loss_discriminator:  0.6891226768493652\n",
      "Epoch:  12     Batch:  309  /  468     Loss_generator:  0.7234519124031067     Loss_discriminator:  0.680745005607605\n",
      "Epoch:  12     Batch:  310  /  468     Loss_generator:  0.6971426010131836     Loss_discriminator:  0.6810901165008545\n",
      "Epoch:  12     Batch:  311  /  468     Loss_generator:  0.7012681365013123     Loss_discriminator:  0.6980966925621033\n",
      "Epoch:  12     Batch:  312  /  468     Loss_generator:  0.739630401134491     Loss_discriminator:  0.7033168077468872\n",
      "Epoch:  12     Batch:  313  /  468     Loss_generator:  0.7332167625427246     Loss_discriminator:  0.6847389936447144\n",
      "Epoch:  12     Batch:  314  /  468     Loss_generator:  0.7162851095199585     Loss_discriminator:  0.6887756586074829\n",
      "Epoch:  12     Batch:  315  /  468     Loss_generator:  0.6977882981300354     Loss_discriminator:  0.6814653277397156\n",
      "Epoch:  12     Batch:  316  /  468     Loss_generator:  0.6623539924621582     Loss_discriminator:  0.695816159248352\n",
      "Epoch:  12     Batch:  317  /  468     Loss_generator:  0.6892215013504028     Loss_discriminator:  0.678126335144043\n",
      "Epoch:  12     Batch:  318  /  468     Loss_generator:  0.6888189911842346     Loss_discriminator:  0.6942378282546997\n",
      "Epoch:  12     Batch:  319  /  468     Loss_generator:  0.6980392336845398     Loss_discriminator:  0.680419385433197\n",
      "Epoch:  12     Batch:  320  /  468     Loss_generator:  0.7152515053749084     Loss_discriminator:  0.6868782639503479\n",
      "Epoch:  12     Batch:  321  /  468     Loss_generator:  0.7515636682510376     Loss_discriminator:  0.6737349033355713\n",
      "Epoch:  12     Batch:  322  /  468     Loss_generator:  0.7604182958602905     Loss_discriminator:  0.6834420561790466\n",
      "Epoch:  12     Batch:  323  /  468     Loss_generator:  0.7415368556976318     Loss_discriminator:  0.6743204593658447\n",
      "Epoch:  12     Batch:  324  /  468     Loss_generator:  0.6896991729736328     Loss_discriminator:  0.6950652003288269\n",
      "Epoch:  12     Batch:  325  /  468     Loss_generator:  0.6636824607849121     Loss_discriminator:  0.6871110200881958\n",
      "Epoch:  12     Batch:  326  /  468     Loss_generator:  0.6497827768325806     Loss_discriminator:  0.6792285442352295\n",
      "Epoch:  12     Batch:  327  /  468     Loss_generator:  0.6787189841270447     Loss_discriminator:  0.6765561699867249\n",
      "Epoch:  12     Batch:  328  /  468     Loss_generator:  0.7211896181106567     Loss_discriminator:  0.690502405166626\n",
      "Epoch:  12     Batch:  329  /  468     Loss_generator:  0.7423075437545776     Loss_discriminator:  0.6913021802902222\n",
      "Epoch:  12     Batch:  330  /  468     Loss_generator:  0.7413361072540283     Loss_discriminator:  0.687846839427948\n",
      "Epoch:  12     Batch:  331  /  468     Loss_generator:  0.7165038585662842     Loss_discriminator:  0.6754786372184753\n",
      "Epoch:  12     Batch:  332  /  468     Loss_generator:  0.6915704011917114     Loss_discriminator:  0.6937013864517212\n",
      "Epoch:  12     Batch:  333  /  468     Loss_generator:  0.7062238454818726     Loss_discriminator:  0.6947475671768188\n",
      "Epoch:  12     Batch:  334  /  468     Loss_generator:  0.7215932607650757     Loss_discriminator:  0.6847898960113525\n",
      "Epoch:  12     Batch:  335  /  468     Loss_generator:  0.7085738182067871     Loss_discriminator:  0.6814493536949158\n",
      "Epoch:  12     Batch:  336  /  468     Loss_generator:  0.7025383114814758     Loss_discriminator:  0.6840095520019531\n",
      "Epoch:  12     Batch:  337  /  468     Loss_generator:  0.7405911684036255     Loss_discriminator:  0.689591646194458\n",
      "Epoch:  12     Batch:  338  /  468     Loss_generator:  0.7148946523666382     Loss_discriminator:  0.6805077195167542\n",
      "Epoch:  12     Batch:  339  /  468     Loss_generator:  0.7112195491790771     Loss_discriminator:  0.6852357387542725\n",
      "Epoch:  12     Batch:  340  /  468     Loss_generator:  0.7047497034072876     Loss_discriminator:  0.6834419965744019\n",
      "Epoch:  12     Batch:  341  /  468     Loss_generator:  0.687574565410614     Loss_discriminator:  0.6876096725463867\n",
      "Epoch:  12     Batch:  342  /  468     Loss_generator:  0.6910116672515869     Loss_discriminator:  0.6836918592453003\n",
      "Epoch:  12     Batch:  343  /  468     Loss_generator:  0.7063649892807007     Loss_discriminator:  0.6889534592628479\n",
      "Epoch:  12     Batch:  344  /  468     Loss_generator:  0.7255100011825562     Loss_discriminator:  0.7005560398101807\n",
      "Epoch:  12     Batch:  345  /  468     Loss_generator:  0.7321065664291382     Loss_discriminator:  0.6886039972305298\n",
      "Epoch:  12     Batch:  346  /  468     Loss_generator:  0.6962892413139343     Loss_discriminator:  0.6807912588119507\n",
      "Epoch:  12     Batch:  347  /  468     Loss_generator:  0.6931432485580444     Loss_discriminator:  0.6799365282058716\n",
      "Epoch:  12     Batch:  348  /  468     Loss_generator:  0.6987923383712769     Loss_discriminator:  0.6961971521377563\n",
      "Epoch:  12     Batch:  349  /  468     Loss_generator:  0.7338410019874573     Loss_discriminator:  0.677810549736023\n",
      "Epoch:  12     Batch:  350  /  468     Loss_generator:  0.7318700551986694     Loss_discriminator:  0.6973469257354736\n",
      "Epoch:  12     Batch:  351  /  468     Loss_generator:  0.7194645404815674     Loss_discriminator:  0.6870505809783936\n",
      "Epoch:  12     Batch:  352  /  468     Loss_generator:  0.672358512878418     Loss_discriminator:  0.6824535131454468\n",
      "Epoch:  12     Batch:  353  /  468     Loss_generator:  0.6752625703811646     Loss_discriminator:  0.6882355213165283\n",
      "Epoch:  12     Batch:  354  /  468     Loss_generator:  0.6984102129936218     Loss_discriminator:  0.6927546262741089\n",
      "Epoch:  12     Batch:  355  /  468     Loss_generator:  0.7027843594551086     Loss_discriminator:  0.6910159587860107\n",
      "Epoch:  12     Batch:  356  /  468     Loss_generator:  0.7253239154815674     Loss_discriminator:  0.6820179224014282\n",
      "Epoch:  12     Batch:  357  /  468     Loss_generator:  0.7380638718605042     Loss_discriminator:  0.6896876096725464\n",
      "Epoch:  12     Batch:  358  /  468     Loss_generator:  0.7325796484947205     Loss_discriminator:  0.6864884495735168\n",
      "Epoch:  12     Batch:  359  /  468     Loss_generator:  0.7034235000610352     Loss_discriminator:  0.682343065738678\n",
      "Epoch:  12     Batch:  360  /  468     Loss_generator:  0.6821576356887817     Loss_discriminator:  0.7014660835266113\n",
      "Epoch:  12     Batch:  361  /  468     Loss_generator:  0.6755349636077881     Loss_discriminator:  0.676292359828949\n",
      "Epoch:  12     Batch:  362  /  468     Loss_generator:  0.6733511686325073     Loss_discriminator:  0.6834661960601807\n",
      "Epoch:  12     Batch:  363  /  468     Loss_generator:  0.7403197288513184     Loss_discriminator:  0.6767848134040833\n",
      "Epoch:  12     Batch:  364  /  468     Loss_generator:  0.7462279796600342     Loss_discriminator:  0.6776853203773499\n",
      "Epoch:  12     Batch:  365  /  468     Loss_generator:  0.722087025642395     Loss_discriminator:  0.684104323387146\n",
      "Epoch:  12     Batch:  366  /  468     Loss_generator:  0.6999455690383911     Loss_discriminator:  0.6970112323760986\n",
      "Epoch:  12     Batch:  367  /  468     Loss_generator:  0.663538932800293     Loss_discriminator:  0.6832956075668335\n",
      "Epoch:  12     Batch:  368  /  468     Loss_generator:  0.6665517091751099     Loss_discriminator:  0.6835699081420898\n",
      "Epoch:  12     Batch:  369  /  468     Loss_generator:  0.7106630802154541     Loss_discriminator:  0.696764349937439\n",
      "Epoch:  12     Batch:  370  /  468     Loss_generator:  0.7197314500808716     Loss_discriminator:  0.6890296936035156\n",
      "Epoch:  12     Batch:  371  /  468     Loss_generator:  0.727496862411499     Loss_discriminator:  0.6694142818450928\n",
      "Epoch:  12     Batch:  372  /  468     Loss_generator:  0.7160137891769409     Loss_discriminator:  0.6747279763221741\n",
      "Epoch:  12     Batch:  373  /  468     Loss_generator:  0.7270663976669312     Loss_discriminator:  0.6839888095855713\n",
      "Epoch:  12     Batch:  374  /  468     Loss_generator:  0.7140331268310547     Loss_discriminator:  0.6862369775772095\n",
      "Epoch:  12     Batch:  375  /  468     Loss_generator:  0.6882046461105347     Loss_discriminator:  0.6900644898414612\n",
      "Epoch:  12     Batch:  376  /  468     Loss_generator:  0.6848123669624329     Loss_discriminator:  0.7029017210006714\n",
      "Epoch:  12     Batch:  377  /  468     Loss_generator:  0.6756064891815186     Loss_discriminator:  0.6794165372848511\n",
      "Epoch:  12     Batch:  378  /  468     Loss_generator:  0.6904826164245605     Loss_discriminator:  0.6911544799804688\n",
      "Epoch:  12     Batch:  379  /  468     Loss_generator:  0.7061374187469482     Loss_discriminator:  0.6790987253189087\n",
      "Epoch:  12     Batch:  380  /  468     Loss_generator:  0.7480922341346741     Loss_discriminator:  0.6877334117889404\n",
      "Epoch:  12     Batch:  381  /  468     Loss_generator:  0.7663873434066772     Loss_discriminator:  0.6863154768943787\n",
      "Epoch:  12     Batch:  382  /  468     Loss_generator:  0.7217104434967041     Loss_discriminator:  0.6938520669937134\n",
      "Epoch:  12     Batch:  383  /  468     Loss_generator:  0.6822035312652588     Loss_discriminator:  0.6928544044494629\n",
      "Epoch:  12     Batch:  384  /  468     Loss_generator:  0.6753474473953247     Loss_discriminator:  0.6827770471572876\n",
      "Epoch:  12     Batch:  385  /  468     Loss_generator:  0.6742744445800781     Loss_discriminator:  0.685498833656311\n",
      "Epoch:  12     Batch:  386  /  468     Loss_generator:  0.714129626750946     Loss_discriminator:  0.6884726285934448\n",
      "Epoch:  12     Batch:  387  /  468     Loss_generator:  0.7126163840293884     Loss_discriminator:  0.684589684009552\n",
      "Epoch:  12     Batch:  388  /  468     Loss_generator:  0.7125508189201355     Loss_discriminator:  0.6917884945869446\n",
      "Epoch:  12     Batch:  389  /  468     Loss_generator:  0.6901199221611023     Loss_discriminator:  0.6804541945457458\n",
      "Epoch:  12     Batch:  390  /  468     Loss_generator:  0.7118231058120728     Loss_discriminator:  0.6818176507949829\n",
      "Epoch:  12     Batch:  391  /  468     Loss_generator:  0.7005009055137634     Loss_discriminator:  0.6909359693527222\n",
      "Epoch:  12     Batch:  392  /  468     Loss_generator:  0.6969131827354431     Loss_discriminator:  0.6781031489372253\n",
      "Epoch:  12     Batch:  393  /  468     Loss_generator:  0.7086766362190247     Loss_discriminator:  0.6922395825386047\n",
      "Epoch:  12     Batch:  394  /  468     Loss_generator:  0.7452991008758545     Loss_discriminator:  0.6794500350952148\n",
      "Epoch:  12     Batch:  395  /  468     Loss_generator:  0.7640540599822998     Loss_discriminator:  0.6969071626663208\n",
      "Epoch:  12     Batch:  396  /  468     Loss_generator:  0.7530603408813477     Loss_discriminator:  0.6792149543762207\n",
      "Epoch:  12     Batch:  397  /  468     Loss_generator:  0.7028374671936035     Loss_discriminator:  0.686248242855072\n",
      "Epoch:  12     Batch:  398  /  468     Loss_generator:  0.6743711829185486     Loss_discriminator:  0.6923400163650513\n",
      "Epoch:  12     Batch:  399  /  468     Loss_generator:  0.6778138279914856     Loss_discriminator:  0.6811332702636719\n",
      "Epoch:  12     Batch:  400  /  468     Loss_generator:  0.6736100912094116     Loss_discriminator:  0.6950233578681946\n",
      "Epoch:  12     Batch:  401  /  468     Loss_generator:  0.6721010804176331     Loss_discriminator:  0.6891136169433594\n",
      "Epoch:  12     Batch:  402  /  468     Loss_generator:  0.6833066940307617     Loss_discriminator:  0.6910567879676819\n",
      "Epoch:  12     Batch:  403  /  468     Loss_generator:  0.7153028249740601     Loss_discriminator:  0.6849765181541443\n",
      "Epoch:  12     Batch:  404  /  468     Loss_generator:  0.7261434197425842     Loss_discriminator:  0.6874957084655762\n",
      "Epoch:  12     Batch:  405  /  468     Loss_generator:  0.7397685647010803     Loss_discriminator:  0.68748939037323\n",
      "Epoch:  12     Batch:  406  /  468     Loss_generator:  0.7569363117218018     Loss_discriminator:  0.6906689405441284\n",
      "Epoch:  12     Batch:  407  /  468     Loss_generator:  0.746162474155426     Loss_discriminator:  0.6860612630844116\n",
      "Epoch:  12     Batch:  408  /  468     Loss_generator:  0.7262140512466431     Loss_discriminator:  0.6769408583641052\n",
      "Epoch:  12     Batch:  409  /  468     Loss_generator:  0.7133188843727112     Loss_discriminator:  0.6925935745239258\n",
      "Epoch:  12     Batch:  410  /  468     Loss_generator:  0.6978627443313599     Loss_discriminator:  0.6842188835144043\n",
      "Epoch:  12     Batch:  411  /  468     Loss_generator:  0.7040550112724304     Loss_discriminator:  0.6730524301528931\n",
      "Epoch:  12     Batch:  412  /  468     Loss_generator:  0.7053298354148865     Loss_discriminator:  0.6873652935028076\n",
      "Epoch:  12     Batch:  413  /  468     Loss_generator:  0.7029723525047302     Loss_discriminator:  0.6756990551948547\n",
      "Epoch:  12     Batch:  414  /  468     Loss_generator:  0.7245488166809082     Loss_discriminator:  0.6829193830490112\n",
      "Epoch:  12     Batch:  415  /  468     Loss_generator:  0.696250319480896     Loss_discriminator:  0.6895043849945068\n",
      "Epoch:  12     Batch:  416  /  468     Loss_generator:  0.6763514876365662     Loss_discriminator:  0.6950345039367676\n",
      "Epoch:  12     Batch:  417  /  468     Loss_generator:  0.6944401860237122     Loss_discriminator:  0.6824281811714172\n",
      "Epoch:  12     Batch:  418  /  468     Loss_generator:  0.7022273540496826     Loss_discriminator:  0.6925820112228394\n",
      "Epoch:  12     Batch:  419  /  468     Loss_generator:  0.720359206199646     Loss_discriminator:  0.6943837404251099\n",
      "Epoch:  12     Batch:  420  /  468     Loss_generator:  0.714277446269989     Loss_discriminator:  0.7026742696762085\n",
      "Epoch:  12     Batch:  421  /  468     Loss_generator:  0.6749703884124756     Loss_discriminator:  0.6787201166152954\n",
      "Epoch:  12     Batch:  422  /  468     Loss_generator:  0.654968798160553     Loss_discriminator:  0.6672744750976562\n",
      "Epoch:  12     Batch:  423  /  468     Loss_generator:  0.7142569422721863     Loss_discriminator:  0.6799326539039612\n",
      "Epoch:  12     Batch:  424  /  468     Loss_generator:  0.7621049284934998     Loss_discriminator:  0.6837157011032104\n",
      "Epoch:  12     Batch:  425  /  468     Loss_generator:  0.7590612173080444     Loss_discriminator:  0.6827431917190552\n",
      "Epoch:  12     Batch:  426  /  468     Loss_generator:  0.731556236743927     Loss_discriminator:  0.6794008016586304\n",
      "Epoch:  12     Batch:  427  /  468     Loss_generator:  0.7216315865516663     Loss_discriminator:  0.6820802688598633\n",
      "Epoch:  12     Batch:  428  /  468     Loss_generator:  0.7094016075134277     Loss_discriminator:  0.6814982295036316\n",
      "Epoch:  12     Batch:  429  /  468     Loss_generator:  0.7014623880386353     Loss_discriminator:  0.67549067735672\n",
      "Epoch:  12     Batch:  430  /  468     Loss_generator:  0.6773252487182617     Loss_discriminator:  0.6850016117095947\n",
      "Epoch:  12     Batch:  431  /  468     Loss_generator:  0.6928012371063232     Loss_discriminator:  0.6821939945220947\n",
      "Epoch:  12     Batch:  432  /  468     Loss_generator:  0.7285629510879517     Loss_discriminator:  0.6944723725318909\n",
      "Epoch:  12     Batch:  433  /  468     Loss_generator:  0.732555627822876     Loss_discriminator:  0.6926800012588501\n",
      "Epoch:  12     Batch:  434  /  468     Loss_generator:  0.7378685474395752     Loss_discriminator:  0.6921144127845764\n",
      "Epoch:  12     Batch:  435  /  468     Loss_generator:  0.7244538068771362     Loss_discriminator:  0.6879068613052368\n",
      "Epoch:  12     Batch:  436  /  468     Loss_generator:  0.6803803443908691     Loss_discriminator:  0.6903495192527771\n",
      "Epoch:  12     Batch:  437  /  468     Loss_generator:  0.6858742237091064     Loss_discriminator:  0.6910473704338074\n",
      "Epoch:  12     Batch:  438  /  468     Loss_generator:  0.6829272508621216     Loss_discriminator:  0.6823825836181641\n",
      "Epoch:  12     Batch:  439  /  468     Loss_generator:  0.7142684459686279     Loss_discriminator:  0.686263918876648\n",
      "Epoch:  12     Batch:  440  /  468     Loss_generator:  0.7601479887962341     Loss_discriminator:  0.6846076250076294\n",
      "Epoch:  12     Batch:  441  /  468     Loss_generator:  0.753145694732666     Loss_discriminator:  0.6902537941932678\n",
      "Epoch:  12     Batch:  442  /  468     Loss_generator:  0.7296322584152222     Loss_discriminator:  0.6859174966812134\n",
      "Epoch:  12     Batch:  443  /  468     Loss_generator:  0.6890170574188232     Loss_discriminator:  0.6913202404975891\n",
      "Epoch:  12     Batch:  444  /  468     Loss_generator:  0.6562445759773254     Loss_discriminator:  0.6777581572532654\n",
      "Epoch:  12     Batch:  445  /  468     Loss_generator:  0.6994518637657166     Loss_discriminator:  0.6899089813232422\n",
      "Epoch:  12     Batch:  446  /  468     Loss_generator:  0.706396222114563     Loss_discriminator:  0.6887754201889038\n",
      "Epoch:  12     Batch:  447  /  468     Loss_generator:  0.7519826889038086     Loss_discriminator:  0.6886813044548035\n",
      "Epoch:  12     Batch:  448  /  468     Loss_generator:  0.7283968329429626     Loss_discriminator:  0.7048728466033936\n",
      "Epoch:  12     Batch:  449  /  468     Loss_generator:  0.6949270963668823     Loss_discriminator:  0.6873264908790588\n",
      "Epoch:  12     Batch:  450  /  468     Loss_generator:  0.6637078523635864     Loss_discriminator:  0.6811978816986084\n",
      "Epoch:  12     Batch:  451  /  468     Loss_generator:  0.6916109919548035     Loss_discriminator:  0.7009357810020447\n",
      "Epoch:  12     Batch:  452  /  468     Loss_generator:  0.7379993796348572     Loss_discriminator:  0.6787848472595215\n",
      "Epoch:  12     Batch:  453  /  468     Loss_generator:  0.7746196389198303     Loss_discriminator:  0.6853029727935791\n",
      "Epoch:  12     Batch:  454  /  468     Loss_generator:  0.7333649396896362     Loss_discriminator:  0.6986820697784424\n",
      "Epoch:  12     Batch:  455  /  468     Loss_generator:  0.6991536021232605     Loss_discriminator:  0.671281099319458\n",
      "Epoch:  12     Batch:  456  /  468     Loss_generator:  0.6793559789657593     Loss_discriminator:  0.6829143762588501\n",
      "Epoch:  12     Batch:  457  /  468     Loss_generator:  0.6809277534484863     Loss_discriminator:  0.6961826086044312\n",
      "Epoch:  12     Batch:  458  /  468     Loss_generator:  0.6868323683738708     Loss_discriminator:  0.6865281462669373\n",
      "Epoch:  12     Batch:  459  /  468     Loss_generator:  0.7056397199630737     Loss_discriminator:  0.6831939220428467\n",
      "Epoch:  12     Batch:  460  /  468     Loss_generator:  0.7337403297424316     Loss_discriminator:  0.6828870177268982\n",
      "Epoch:  12     Batch:  461  /  468     Loss_generator:  0.7262889742851257     Loss_discriminator:  0.6995241641998291\n",
      "Epoch:  12     Batch:  462  /  468     Loss_generator:  0.7274525165557861     Loss_discriminator:  0.6938049793243408\n",
      "Epoch:  12     Batch:  463  /  468     Loss_generator:  0.6744585633277893     Loss_discriminator:  0.6829179525375366\n",
      "Epoch:  12     Batch:  464  /  468     Loss_generator:  0.6824139356613159     Loss_discriminator:  0.6930921077728271\n",
      "Epoch:  12     Batch:  465  /  468     Loss_generator:  0.6860275268554688     Loss_discriminator:  0.692335307598114\n",
      "Epoch:  12     Batch:  466  /  468     Loss_generator:  0.7225326895713806     Loss_discriminator:  0.694342315196991\n",
      "Epoch:  12     Batch:  467  /  468     Loss_generator:  0.7140488624572754     Loss_discriminator:  0.6770652532577515\n",
      "Epoch:  13     Batch:  0  /  468     Loss_generator:  0.7522852420806885     Loss_discriminator:  0.682373046875\n",
      "Epoch:  13     Batch:  1  /  468     Loss_generator:  0.7229661345481873     Loss_discriminator:  0.6792805790901184\n",
      "Epoch:  13     Batch:  2  /  468     Loss_generator:  0.6852442026138306     Loss_discriminator:  0.6744847297668457\n",
      "Epoch:  13     Batch:  3  /  468     Loss_generator:  0.7032821178436279     Loss_discriminator:  0.6808328628540039\n",
      "Epoch:  13     Batch:  4  /  468     Loss_generator:  0.6966367959976196     Loss_discriminator:  0.6851847767829895\n",
      "Epoch:  13     Batch:  5  /  468     Loss_generator:  0.7003825902938843     Loss_discriminator:  0.6895945072174072\n",
      "Epoch:  13     Batch:  6  /  468     Loss_generator:  0.6851940155029297     Loss_discriminator:  0.684789776802063\n",
      "Epoch:  13     Batch:  7  /  468     Loss_generator:  0.7046539187431335     Loss_discriminator:  0.6794044971466064\n",
      "Epoch:  13     Batch:  8  /  468     Loss_generator:  0.7313244938850403     Loss_discriminator:  0.6744073629379272\n",
      "Epoch:  13     Batch:  9  /  468     Loss_generator:  0.712192714214325     Loss_discriminator:  0.6842617988586426\n",
      "Epoch:  13     Batch:  10  /  468     Loss_generator:  0.7020915150642395     Loss_discriminator:  0.6772177219390869\n",
      "Epoch:  13     Batch:  11  /  468     Loss_generator:  0.7208454608917236     Loss_discriminator:  0.6807830333709717\n",
      "Epoch:  13     Batch:  12  /  468     Loss_generator:  0.730789065361023     Loss_discriminator:  0.7035506367683411\n",
      "Epoch:  13     Batch:  13  /  468     Loss_generator:  0.7446044683456421     Loss_discriminator:  0.6828966736793518\n",
      "Epoch:  13     Batch:  14  /  468     Loss_generator:  0.7274395823478699     Loss_discriminator:  0.6854129433631897\n",
      "Epoch:  13     Batch:  15  /  468     Loss_generator:  0.700863242149353     Loss_discriminator:  0.6948646306991577\n",
      "Epoch:  13     Batch:  16  /  468     Loss_generator:  0.6894785761833191     Loss_discriminator:  0.6815097332000732\n",
      "Epoch:  13     Batch:  17  /  468     Loss_generator:  0.7201897501945496     Loss_discriminator:  0.6926223039627075\n",
      "Epoch:  13     Batch:  18  /  468     Loss_generator:  0.729156494140625     Loss_discriminator:  0.6829712390899658\n",
      "Epoch:  13     Batch:  19  /  468     Loss_generator:  0.7423766255378723     Loss_discriminator:  0.6671582460403442\n",
      "Epoch:  13     Batch:  20  /  468     Loss_generator:  0.7067306041717529     Loss_discriminator:  0.6857084631919861\n",
      "Epoch:  13     Batch:  21  /  468     Loss_generator:  0.7021825909614563     Loss_discriminator:  0.6952313780784607\n",
      "Epoch:  13     Batch:  22  /  468     Loss_generator:  0.6780064105987549     Loss_discriminator:  0.6840091943740845\n",
      "Epoch:  13     Batch:  23  /  468     Loss_generator:  0.6951501369476318     Loss_discriminator:  0.6843321919441223\n",
      "Epoch:  13     Batch:  24  /  468     Loss_generator:  0.7010464072227478     Loss_discriminator:  0.686627984046936\n",
      "Epoch:  13     Batch:  25  /  468     Loss_generator:  0.7057739496231079     Loss_discriminator:  0.6798148155212402\n",
      "Epoch:  13     Batch:  26  /  468     Loss_generator:  0.697368860244751     Loss_discriminator:  0.6849608421325684\n",
      "Epoch:  13     Batch:  27  /  468     Loss_generator:  0.7024998068809509     Loss_discriminator:  0.6773598194122314\n",
      "Epoch:  13     Batch:  28  /  468     Loss_generator:  0.7203668355941772     Loss_discriminator:  0.69969642162323\n",
      "Epoch:  13     Batch:  29  /  468     Loss_generator:  0.7187035083770752     Loss_discriminator:  0.6901432275772095\n",
      "Epoch:  13     Batch:  30  /  468     Loss_generator:  0.730270266532898     Loss_discriminator:  0.6895002126693726\n",
      "Epoch:  13     Batch:  31  /  468     Loss_generator:  0.7212120294570923     Loss_discriminator:  0.6928495168685913\n",
      "Epoch:  13     Batch:  32  /  468     Loss_generator:  0.7204298973083496     Loss_discriminator:  0.6824131608009338\n",
      "Epoch:  13     Batch:  33  /  468     Loss_generator:  0.7099552154541016     Loss_discriminator:  0.6946145296096802\n",
      "Epoch:  13     Batch:  34  /  468     Loss_generator:  0.722877025604248     Loss_discriminator:  0.6883383393287659\n",
      "Epoch:  13     Batch:  35  /  468     Loss_generator:  0.7118937969207764     Loss_discriminator:  0.6798511743545532\n",
      "Epoch:  13     Batch:  36  /  468     Loss_generator:  0.6895585060119629     Loss_discriminator:  0.696777880191803\n",
      "Epoch:  13     Batch:  37  /  468     Loss_generator:  0.7041240930557251     Loss_discriminator:  0.6915321946144104\n",
      "Epoch:  13     Batch:  38  /  468     Loss_generator:  0.7309324741363525     Loss_discriminator:  0.6889811158180237\n",
      "Epoch:  13     Batch:  39  /  468     Loss_generator:  0.7192964553833008     Loss_discriminator:  0.672000527381897\n",
      "Epoch:  13     Batch:  40  /  468     Loss_generator:  0.7254891991615295     Loss_discriminator:  0.6822970509529114\n",
      "Epoch:  13     Batch:  41  /  468     Loss_generator:  0.7014977931976318     Loss_discriminator:  0.6920692324638367\n",
      "Epoch:  13     Batch:  42  /  468     Loss_generator:  0.6700387001037598     Loss_discriminator:  0.6765874624252319\n",
      "Epoch:  13     Batch:  43  /  468     Loss_generator:  0.6667254567146301     Loss_discriminator:  0.6846181154251099\n",
      "Epoch:  13     Batch:  44  /  468     Loss_generator:  0.6804524660110474     Loss_discriminator:  0.6795816421508789\n",
      "Epoch:  13     Batch:  45  /  468     Loss_generator:  0.7094404697418213     Loss_discriminator:  0.6752181053161621\n",
      "Epoch:  13     Batch:  46  /  468     Loss_generator:  0.7387648820877075     Loss_discriminator:  0.6771811246871948\n",
      "Epoch:  13     Batch:  47  /  468     Loss_generator:  0.752840518951416     Loss_discriminator:  0.6815255880355835\n",
      "Epoch:  13     Batch:  48  /  468     Loss_generator:  0.7321807742118835     Loss_discriminator:  0.6985806226730347\n",
      "Epoch:  13     Batch:  49  /  468     Loss_generator:  0.6893893480300903     Loss_discriminator:  0.683920681476593\n",
      "Epoch:  13     Batch:  50  /  468     Loss_generator:  0.6632462739944458     Loss_discriminator:  0.6834917664527893\n",
      "Epoch:  13     Batch:  51  /  468     Loss_generator:  0.6814769506454468     Loss_discriminator:  0.6794559359550476\n",
      "Epoch:  13     Batch:  52  /  468     Loss_generator:  0.7263062000274658     Loss_discriminator:  0.6902061700820923\n",
      "Epoch:  13     Batch:  53  /  468     Loss_generator:  0.7688478231430054     Loss_discriminator:  0.6895740032196045\n",
      "Epoch:  13     Batch:  54  /  468     Loss_generator:  0.7659468650817871     Loss_discriminator:  0.681503415107727\n",
      "Epoch:  13     Batch:  55  /  468     Loss_generator:  0.7385358810424805     Loss_discriminator:  0.6929692625999451\n",
      "Epoch:  13     Batch:  56  /  468     Loss_generator:  0.7080844640731812     Loss_discriminator:  0.6835497617721558\n",
      "Epoch:  13     Batch:  57  /  468     Loss_generator:  0.6833731532096863     Loss_discriminator:  0.6864758729934692\n",
      "Epoch:  13     Batch:  58  /  468     Loss_generator:  0.6713107824325562     Loss_discriminator:  0.6814329028129578\n",
      "Epoch:  13     Batch:  59  /  468     Loss_generator:  0.692810595035553     Loss_discriminator:  0.6899989247322083\n",
      "Epoch:  13     Batch:  60  /  468     Loss_generator:  0.7203315496444702     Loss_discriminator:  0.681982159614563\n",
      "Epoch:  13     Batch:  61  /  468     Loss_generator:  0.718827486038208     Loss_discriminator:  0.6865601539611816\n",
      "Epoch:  13     Batch:  62  /  468     Loss_generator:  0.7392855882644653     Loss_discriminator:  0.6768823862075806\n",
      "Epoch:  13     Batch:  63  /  468     Loss_generator:  0.7494425773620605     Loss_discriminator:  0.6771776676177979\n",
      "Epoch:  13     Batch:  64  /  468     Loss_generator:  0.7153065204620361     Loss_discriminator:  0.6916443109512329\n",
      "Epoch:  13     Batch:  65  /  468     Loss_generator:  0.6940960884094238     Loss_discriminator:  0.6839249730110168\n",
      "Epoch:  13     Batch:  66  /  468     Loss_generator:  0.6901443004608154     Loss_discriminator:  0.7042151689529419\n",
      "Epoch:  13     Batch:  67  /  468     Loss_generator:  0.7023841142654419     Loss_discriminator:  0.6979416608810425\n",
      "Epoch:  13     Batch:  68  /  468     Loss_generator:  0.6817355155944824     Loss_discriminator:  0.6849709153175354\n",
      "Epoch:  13     Batch:  69  /  468     Loss_generator:  0.6850684881210327     Loss_discriminator:  0.6905304193496704\n",
      "Epoch:  13     Batch:  70  /  468     Loss_generator:  0.6907368898391724     Loss_discriminator:  0.7073346972465515\n",
      "Epoch:  13     Batch:  71  /  468     Loss_generator:  0.750209391117096     Loss_discriminator:  0.6867659091949463\n",
      "Epoch:  13     Batch:  72  /  468     Loss_generator:  0.768773078918457     Loss_discriminator:  0.6985481977462769\n",
      "Epoch:  13     Batch:  73  /  468     Loss_generator:  0.7180852890014648     Loss_discriminator:  0.6897294521331787\n",
      "Epoch:  13     Batch:  74  /  468     Loss_generator:  0.6806207299232483     Loss_discriminator:  0.675123929977417\n",
      "Epoch:  13     Batch:  75  /  468     Loss_generator:  0.6586203575134277     Loss_discriminator:  0.6774203777313232\n",
      "Epoch:  13     Batch:  76  /  468     Loss_generator:  0.6754075288772583     Loss_discriminator:  0.6752591133117676\n",
      "Epoch:  13     Batch:  77  /  468     Loss_generator:  0.7361377477645874     Loss_discriminator:  0.6906164884567261\n",
      "Epoch:  13     Batch:  78  /  468     Loss_generator:  0.7663248181343079     Loss_discriminator:  0.687195897102356\n",
      "Epoch:  13     Batch:  79  /  468     Loss_generator:  0.7323276996612549     Loss_discriminator:  0.6828263401985168\n",
      "Epoch:  13     Batch:  80  /  468     Loss_generator:  0.680933952331543     Loss_discriminator:  0.6906589269638062\n",
      "Epoch:  13     Batch:  81  /  468     Loss_generator:  0.6651139855384827     Loss_discriminator:  0.6860527396202087\n",
      "Epoch:  13     Batch:  82  /  468     Loss_generator:  0.6783941388130188     Loss_discriminator:  0.682004451751709\n",
      "Epoch:  13     Batch:  83  /  468     Loss_generator:  0.6879308819770813     Loss_discriminator:  0.6651266813278198\n",
      "Epoch:  13     Batch:  84  /  468     Loss_generator:  0.726172924041748     Loss_discriminator:  0.6801646947860718\n",
      "Epoch:  13     Batch:  85  /  468     Loss_generator:  0.7210969924926758     Loss_discriminator:  0.6817648410797119\n",
      "Epoch:  13     Batch:  86  /  468     Loss_generator:  0.7191507816314697     Loss_discriminator:  0.6719833612442017\n",
      "Epoch:  13     Batch:  87  /  468     Loss_generator:  0.7210971117019653     Loss_discriminator:  0.6878561973571777\n",
      "Epoch:  13     Batch:  88  /  468     Loss_generator:  0.6881203651428223     Loss_discriminator:  0.687318742275238\n",
      "Epoch:  13     Batch:  89  /  468     Loss_generator:  0.6739029884338379     Loss_discriminator:  0.6842150688171387\n",
      "Epoch:  13     Batch:  90  /  468     Loss_generator:  0.7161591053009033     Loss_discriminator:  0.6888263821601868\n",
      "Epoch:  13     Batch:  91  /  468     Loss_generator:  0.7342068552970886     Loss_discriminator:  0.6777082681655884\n",
      "Epoch:  13     Batch:  92  /  468     Loss_generator:  0.7207123637199402     Loss_discriminator:  0.6770779490470886\n",
      "Epoch:  13     Batch:  93  /  468     Loss_generator:  0.6987173557281494     Loss_discriminator:  0.6864013075828552\n",
      "Epoch:  13     Batch:  94  /  468     Loss_generator:  0.6951758861541748     Loss_discriminator:  0.6898504495620728\n",
      "Epoch:  13     Batch:  95  /  468     Loss_generator:  0.6742157340049744     Loss_discriminator:  0.6742745041847229\n",
      "Epoch:  13     Batch:  96  /  468     Loss_generator:  0.6966782808303833     Loss_discriminator:  0.6900095343589783\n",
      "Epoch:  13     Batch:  97  /  468     Loss_generator:  0.7084306478500366     Loss_discriminator:  0.6804871559143066\n",
      "Epoch:  13     Batch:  98  /  468     Loss_generator:  0.7026875019073486     Loss_discriminator:  0.6806245446205139\n",
      "Epoch:  13     Batch:  99  /  468     Loss_generator:  0.7169142961502075     Loss_discriminator:  0.691767692565918\n",
      "Epoch:  13     Batch:  100  /  468     Loss_generator:  0.7048051357269287     Loss_discriminator:  0.6791660785675049\n",
      "Epoch:  13     Batch:  101  /  468     Loss_generator:  0.7174456119537354     Loss_discriminator:  0.6890832781791687\n",
      "Epoch:  13     Batch:  102  /  468     Loss_generator:  0.7297747135162354     Loss_discriminator:  0.6880941390991211\n",
      "Epoch:  13     Batch:  103  /  468     Loss_generator:  0.7703393697738647     Loss_discriminator:  0.6879397630691528\n",
      "Epoch:  13     Batch:  104  /  468     Loss_generator:  0.7584437727928162     Loss_discriminator:  0.681377649307251\n",
      "Epoch:  13     Batch:  105  /  468     Loss_generator:  0.6937146782875061     Loss_discriminator:  0.6856895685195923\n",
      "Epoch:  13     Batch:  106  /  468     Loss_generator:  0.6542974710464478     Loss_discriminator:  0.6952400207519531\n",
      "Epoch:  13     Batch:  107  /  468     Loss_generator:  0.6434560418128967     Loss_discriminator:  0.6951797008514404\n",
      "Epoch:  13     Batch:  108  /  468     Loss_generator:  0.6476074457168579     Loss_discriminator:  0.6829349398612976\n",
      "Epoch:  13     Batch:  109  /  468     Loss_generator:  0.7072632312774658     Loss_discriminator:  0.6932145357131958\n",
      "Epoch:  13     Batch:  110  /  468     Loss_generator:  0.7474881410598755     Loss_discriminator:  0.674163281917572\n",
      "Epoch:  13     Batch:  111  /  468     Loss_generator:  0.7630358934402466     Loss_discriminator:  0.6966771483421326\n",
      "Epoch:  13     Batch:  112  /  468     Loss_generator:  0.775428831577301     Loss_discriminator:  0.6848249435424805\n",
      "Epoch:  13     Batch:  113  /  468     Loss_generator:  0.7560285925865173     Loss_discriminator:  0.6842055320739746\n",
      "Epoch:  13     Batch:  114  /  468     Loss_generator:  0.7310357093811035     Loss_discriminator:  0.6856257319450378\n",
      "Epoch:  13     Batch:  115  /  468     Loss_generator:  0.6943291425704956     Loss_discriminator:  0.6791974902153015\n",
      "Epoch:  13     Batch:  116  /  468     Loss_generator:  0.6814190745353699     Loss_discriminator:  0.6867808699607849\n",
      "Epoch:  13     Batch:  117  /  468     Loss_generator:  0.679059624671936     Loss_discriminator:  0.6927983164787292\n",
      "Epoch:  13     Batch:  118  /  468     Loss_generator:  0.6904863119125366     Loss_discriminator:  0.6887962818145752\n",
      "Epoch:  13     Batch:  119  /  468     Loss_generator:  0.7487704753875732     Loss_discriminator:  0.6728382110595703\n",
      "Epoch:  13     Batch:  120  /  468     Loss_generator:  0.7548235058784485     Loss_discriminator:  0.6816073656082153\n",
      "Epoch:  13     Batch:  121  /  468     Loss_generator:  0.7424015402793884     Loss_discriminator:  0.6728423833847046\n",
      "Epoch:  13     Batch:  122  /  468     Loss_generator:  0.6892964243888855     Loss_discriminator:  0.691045880317688\n",
      "Epoch:  13     Batch:  123  /  468     Loss_generator:  0.6666014790534973     Loss_discriminator:  0.6794155836105347\n",
      "Epoch:  13     Batch:  124  /  468     Loss_generator:  0.6622753143310547     Loss_discriminator:  0.6969280242919922\n",
      "Epoch:  13     Batch:  125  /  468     Loss_generator:  0.6806312799453735     Loss_discriminator:  0.678847074508667\n",
      "Epoch:  13     Batch:  126  /  468     Loss_generator:  0.7437131404876709     Loss_discriminator:  0.67682284116745\n",
      "Epoch:  13     Batch:  127  /  468     Loss_generator:  0.7594512701034546     Loss_discriminator:  0.6860165596008301\n",
      "Epoch:  13     Batch:  128  /  468     Loss_generator:  0.7508354187011719     Loss_discriminator:  0.694451093673706\n",
      "Epoch:  13     Batch:  129  /  468     Loss_generator:  0.7159792184829712     Loss_discriminator:  0.6954389810562134\n",
      "Epoch:  13     Batch:  130  /  468     Loss_generator:  0.7040766477584839     Loss_discriminator:  0.690960168838501\n",
      "Epoch:  13     Batch:  131  /  468     Loss_generator:  0.733405351638794     Loss_discriminator:  0.6854105591773987\n",
      "Epoch:  13     Batch:  132  /  468     Loss_generator:  0.7004444003105164     Loss_discriminator:  0.6784093976020813\n",
      "Epoch:  13     Batch:  133  /  468     Loss_generator:  0.6930056810379028     Loss_discriminator:  0.6880282163619995\n",
      "Epoch:  13     Batch:  134  /  468     Loss_generator:  0.6894804835319519     Loss_discriminator:  0.696641206741333\n",
      "Epoch:  13     Batch:  135  /  468     Loss_generator:  0.7025889754295349     Loss_discriminator:  0.6904059648513794\n",
      "Epoch:  13     Batch:  136  /  468     Loss_generator:  0.7001689076423645     Loss_discriminator:  0.6739680767059326\n",
      "Epoch:  13     Batch:  137  /  468     Loss_generator:  0.7203257083892822     Loss_discriminator:  0.6795305609703064\n",
      "Epoch:  13     Batch:  138  /  468     Loss_generator:  0.7114852666854858     Loss_discriminator:  0.6889212131500244\n",
      "Epoch:  13     Batch:  139  /  468     Loss_generator:  0.6851702928543091     Loss_discriminator:  0.6698628664016724\n",
      "Epoch:  13     Batch:  140  /  468     Loss_generator:  0.6788569092750549     Loss_discriminator:  0.682411789894104\n",
      "Epoch:  13     Batch:  141  /  468     Loss_generator:  0.7213925123214722     Loss_discriminator:  0.6885145306587219\n",
      "Epoch:  13     Batch:  142  /  468     Loss_generator:  0.7392821311950684     Loss_discriminator:  0.6833864450454712\n",
      "Epoch:  13     Batch:  143  /  468     Loss_generator:  0.7583810687065125     Loss_discriminator:  0.6832491159439087\n",
      "Epoch:  13     Batch:  144  /  468     Loss_generator:  0.7233614921569824     Loss_discriminator:  0.6843123435974121\n",
      "Epoch:  13     Batch:  145  /  468     Loss_generator:  0.6783391237258911     Loss_discriminator:  0.6853724122047424\n",
      "Epoch:  13     Batch:  146  /  468     Loss_generator:  0.6553409695625305     Loss_discriminator:  0.69001305103302\n",
      "Epoch:  13     Batch:  147  /  468     Loss_generator:  0.6507569551467896     Loss_discriminator:  0.6868866086006165\n",
      "Epoch:  13     Batch:  148  /  468     Loss_generator:  0.7334818243980408     Loss_discriminator:  0.6898084878921509\n",
      "Epoch:  13     Batch:  149  /  468     Loss_generator:  0.7645687460899353     Loss_discriminator:  0.6877885460853577\n",
      "Epoch:  13     Batch:  150  /  468     Loss_generator:  0.7611840963363647     Loss_discriminator:  0.6779364347457886\n",
      "Epoch:  13     Batch:  151  /  468     Loss_generator:  0.7378239631652832     Loss_discriminator:  0.6865615844726562\n",
      "Epoch:  13     Batch:  152  /  468     Loss_generator:  0.6912066340446472     Loss_discriminator:  0.6920676827430725\n",
      "Epoch:  13     Batch:  153  /  468     Loss_generator:  0.6678971648216248     Loss_discriminator:  0.6630983352661133\n",
      "Epoch:  13     Batch:  154  /  468     Loss_generator:  0.6593716144561768     Loss_discriminator:  0.6791306734085083\n",
      "Epoch:  13     Batch:  155  /  468     Loss_generator:  0.6796026825904846     Loss_discriminator:  0.6789388656616211\n",
      "Epoch:  13     Batch:  156  /  468     Loss_generator:  0.7444708347320557     Loss_discriminator:  0.6816162467002869\n",
      "Epoch:  13     Batch:  157  /  468     Loss_generator:  0.7392443418502808     Loss_discriminator:  0.6772006750106812\n",
      "Epoch:  13     Batch:  158  /  468     Loss_generator:  0.7499837279319763     Loss_discriminator:  0.6925294399261475\n",
      "Epoch:  13     Batch:  159  /  468     Loss_generator:  0.7530820369720459     Loss_discriminator:  0.6934899091720581\n",
      "Epoch:  13     Batch:  160  /  468     Loss_generator:  0.7320364713668823     Loss_discriminator:  0.6815598011016846\n",
      "Epoch:  13     Batch:  161  /  468     Loss_generator:  0.7033067941665649     Loss_discriminator:  0.6748500466346741\n",
      "Epoch:  13     Batch:  162  /  468     Loss_generator:  0.6587997078895569     Loss_discriminator:  0.6950000524520874\n",
      "Epoch:  13     Batch:  163  /  468     Loss_generator:  0.6871046423912048     Loss_discriminator:  0.6836404800415039\n",
      "Epoch:  13     Batch:  164  /  468     Loss_generator:  0.7032022476196289     Loss_discriminator:  0.6889133453369141\n",
      "Epoch:  13     Batch:  165  /  468     Loss_generator:  0.7358899116516113     Loss_discriminator:  0.6898089647293091\n",
      "Epoch:  13     Batch:  166  /  468     Loss_generator:  0.7511025667190552     Loss_discriminator:  0.6853634119033813\n",
      "Epoch:  13     Batch:  167  /  468     Loss_generator:  0.7153064012527466     Loss_discriminator:  0.678783118724823\n",
      "Epoch:  13     Batch:  168  /  468     Loss_generator:  0.7128143310546875     Loss_discriminator:  0.6899106502532959\n",
      "Epoch:  13     Batch:  169  /  468     Loss_generator:  0.7033020257949829     Loss_discriminator:  0.6956662535667419\n",
      "Epoch:  13     Batch:  170  /  468     Loss_generator:  0.7345829606056213     Loss_discriminator:  0.692065954208374\n",
      "Epoch:  13     Batch:  171  /  468     Loss_generator:  0.7153216600418091     Loss_discriminator:  0.6805238723754883\n",
      "Epoch:  13     Batch:  172  /  468     Loss_generator:  0.7170721292495728     Loss_discriminator:  0.6843140721321106\n",
      "Epoch:  13     Batch:  173  /  468     Loss_generator:  0.7111272811889648     Loss_discriminator:  0.6940613985061646\n",
      "Epoch:  13     Batch:  174  /  468     Loss_generator:  0.747488796710968     Loss_discriminator:  0.6961123943328857\n",
      "Epoch:  13     Batch:  175  /  468     Loss_generator:  0.7407517433166504     Loss_discriminator:  0.6928889751434326\n",
      "Epoch:  13     Batch:  176  /  468     Loss_generator:  0.7126463651657104     Loss_discriminator:  0.688335120677948\n",
      "Epoch:  13     Batch:  177  /  468     Loss_generator:  0.6928934454917908     Loss_discriminator:  0.6911957263946533\n",
      "Epoch:  13     Batch:  178  /  468     Loss_generator:  0.6679948568344116     Loss_discriminator:  0.673876941204071\n",
      "Epoch:  13     Batch:  179  /  468     Loss_generator:  0.6659865379333496     Loss_discriminator:  0.6837079524993896\n",
      "Epoch:  13     Batch:  180  /  468     Loss_generator:  0.7201031446456909     Loss_discriminator:  0.6998089551925659\n",
      "Epoch:  13     Batch:  181  /  468     Loss_generator:  0.7537634968757629     Loss_discriminator:  0.6891525983810425\n",
      "Epoch:  13     Batch:  182  /  468     Loss_generator:  0.7376408576965332     Loss_discriminator:  0.6935369968414307\n",
      "Epoch:  13     Batch:  183  /  468     Loss_generator:  0.7107620239257812     Loss_discriminator:  0.6646231412887573\n",
      "Epoch:  13     Batch:  184  /  468     Loss_generator:  0.6931049823760986     Loss_discriminator:  0.6730812788009644\n",
      "Epoch:  13     Batch:  185  /  468     Loss_generator:  0.7088923454284668     Loss_discriminator:  0.6831191778182983\n",
      "Epoch:  13     Batch:  186  /  468     Loss_generator:  0.7111020088195801     Loss_discriminator:  0.686778724193573\n",
      "Epoch:  13     Batch:  187  /  468     Loss_generator:  0.6986322999000549     Loss_discriminator:  0.6848025321960449\n",
      "Epoch:  13     Batch:  188  /  468     Loss_generator:  0.7164080142974854     Loss_discriminator:  0.6781326532363892\n",
      "Epoch:  13     Batch:  189  /  468     Loss_generator:  0.7162623405456543     Loss_discriminator:  0.6951501369476318\n",
      "Epoch:  13     Batch:  190  /  468     Loss_generator:  0.7077270746231079     Loss_discriminator:  0.6908454895019531\n",
      "Epoch:  13     Batch:  191  /  468     Loss_generator:  0.691810131072998     Loss_discriminator:  0.694105863571167\n",
      "Epoch:  13     Batch:  192  /  468     Loss_generator:  0.7163875699043274     Loss_discriminator:  0.6764750480651855\n",
      "Epoch:  13     Batch:  193  /  468     Loss_generator:  0.7244418859481812     Loss_discriminator:  0.6776732802391052\n",
      "Epoch:  13     Batch:  194  /  468     Loss_generator:  0.7087520956993103     Loss_discriminator:  0.6825687289237976\n",
      "Epoch:  13     Batch:  195  /  468     Loss_generator:  0.7042766213417053     Loss_discriminator:  0.6805759072303772\n",
      "Epoch:  13     Batch:  196  /  468     Loss_generator:  0.7230801582336426     Loss_discriminator:  0.6819812059402466\n",
      "Epoch:  13     Batch:  197  /  468     Loss_generator:  0.7328617572784424     Loss_discriminator:  0.6858934164047241\n",
      "Epoch:  13     Batch:  198  /  468     Loss_generator:  0.7107638120651245     Loss_discriminator:  0.6884716749191284\n",
      "Epoch:  13     Batch:  199  /  468     Loss_generator:  0.7011818885803223     Loss_discriminator:  0.6833750009536743\n",
      "Epoch:  13     Batch:  200  /  468     Loss_generator:  0.698844850063324     Loss_discriminator:  0.7008405327796936\n",
      "Epoch:  13     Batch:  201  /  468     Loss_generator:  0.7102779150009155     Loss_discriminator:  0.6690731048583984\n",
      "Epoch:  13     Batch:  202  /  468     Loss_generator:  0.7055936455726624     Loss_discriminator:  0.6872972249984741\n",
      "Epoch:  13     Batch:  203  /  468     Loss_generator:  0.6853886842727661     Loss_discriminator:  0.6799722909927368\n",
      "Epoch:  13     Batch:  204  /  468     Loss_generator:  0.6818674802780151     Loss_discriminator:  0.6772585511207581\n",
      "Epoch:  13     Batch:  205  /  468     Loss_generator:  0.679322361946106     Loss_discriminator:  0.6838875412940979\n",
      "Epoch:  13     Batch:  206  /  468     Loss_generator:  0.691123366355896     Loss_discriminator:  0.6930949687957764\n",
      "Epoch:  13     Batch:  207  /  468     Loss_generator:  0.7309924364089966     Loss_discriminator:  0.6821727752685547\n",
      "Epoch:  13     Batch:  208  /  468     Loss_generator:  0.8293077945709229     Loss_discriminator:  0.6864933967590332\n",
      "Epoch:  13     Batch:  209  /  468     Loss_generator:  0.8166884183883667     Loss_discriminator:  0.6822744607925415\n",
      "Epoch:  13     Batch:  210  /  468     Loss_generator:  0.7193076610565186     Loss_discriminator:  0.6884169578552246\n",
      "Epoch:  13     Batch:  211  /  468     Loss_generator:  0.6500364542007446     Loss_discriminator:  0.6773576736450195\n",
      "Epoch:  13     Batch:  212  /  468     Loss_generator:  0.6186439990997314     Loss_discriminator:  0.6833102703094482\n",
      "Epoch:  13     Batch:  213  /  468     Loss_generator:  0.6278716325759888     Loss_discriminator:  0.7011568546295166\n",
      "Epoch:  13     Batch:  214  /  468     Loss_generator:  0.6970193386077881     Loss_discriminator:  0.706856369972229\n",
      "Epoch:  13     Batch:  215  /  468     Loss_generator:  0.7742314338684082     Loss_discriminator:  0.6749203205108643\n",
      "Epoch:  13     Batch:  216  /  468     Loss_generator:  0.787629246711731     Loss_discriminator:  0.6850197911262512\n",
      "Epoch:  13     Batch:  217  /  468     Loss_generator:  0.7946874499320984     Loss_discriminator:  0.6895906925201416\n",
      "Epoch:  13     Batch:  218  /  468     Loss_generator:  0.7118866443634033     Loss_discriminator:  0.6924235820770264\n",
      "Epoch:  13     Batch:  219  /  468     Loss_generator:  0.6558680534362793     Loss_discriminator:  0.7025713324546814\n",
      "Epoch:  13     Batch:  220  /  468     Loss_generator:  0.6438969373703003     Loss_discriminator:  0.6893851161003113\n",
      "Epoch:  13     Batch:  221  /  468     Loss_generator:  0.684502124786377     Loss_discriminator:  0.6758208274841309\n",
      "Epoch:  13     Batch:  222  /  468     Loss_generator:  0.7107810974121094     Loss_discriminator:  0.6950080990791321\n",
      "Epoch:  13     Batch:  223  /  468     Loss_generator:  0.7345971465110779     Loss_discriminator:  0.6774107217788696\n",
      "Epoch:  13     Batch:  224  /  468     Loss_generator:  0.7277382612228394     Loss_discriminator:  0.6816798448562622\n",
      "Epoch:  13     Batch:  225  /  468     Loss_generator:  0.7464897632598877     Loss_discriminator:  0.6715279221534729\n",
      "Epoch:  13     Batch:  226  /  468     Loss_generator:  0.7459142208099365     Loss_discriminator:  0.6972320079803467\n",
      "Epoch:  13     Batch:  227  /  468     Loss_generator:  0.7162781953811646     Loss_discriminator:  0.6798573732376099\n",
      "Epoch:  13     Batch:  228  /  468     Loss_generator:  0.6733443737030029     Loss_discriminator:  0.6713225841522217\n",
      "Epoch:  13     Batch:  229  /  468     Loss_generator:  0.6526005864143372     Loss_discriminator:  0.6966544389724731\n",
      "Epoch:  13     Batch:  230  /  468     Loss_generator:  0.6640812158584595     Loss_discriminator:  0.6618411540985107\n",
      "Epoch:  13     Batch:  231  /  468     Loss_generator:  0.7285489439964294     Loss_discriminator:  0.6887499094009399\n",
      "Epoch:  13     Batch:  232  /  468     Loss_generator:  0.727622926235199     Loss_discriminator:  0.6878402233123779\n",
      "Epoch:  13     Batch:  233  /  468     Loss_generator:  0.7002537250518799     Loss_discriminator:  0.697083592414856\n",
      "Epoch:  13     Batch:  234  /  468     Loss_generator:  0.7052211761474609     Loss_discriminator:  0.6752240061759949\n",
      "Epoch:  13     Batch:  235  /  468     Loss_generator:  0.7276755571365356     Loss_discriminator:  0.689408540725708\n",
      "Epoch:  13     Batch:  236  /  468     Loss_generator:  0.7802983522415161     Loss_discriminator:  0.691624641418457\n",
      "Epoch:  13     Batch:  237  /  468     Loss_generator:  0.7352063655853271     Loss_discriminator:  0.6997750401496887\n",
      "Epoch:  13     Batch:  238  /  468     Loss_generator:  0.7054146528244019     Loss_discriminator:  0.6870774030685425\n",
      "Epoch:  13     Batch:  239  /  468     Loss_generator:  0.690669059753418     Loss_discriminator:  0.667492151260376\n",
      "Epoch:  13     Batch:  240  /  468     Loss_generator:  0.7027378678321838     Loss_discriminator:  0.6813462972640991\n",
      "Epoch:  13     Batch:  241  /  468     Loss_generator:  0.7139594554901123     Loss_discriminator:  0.6865312457084656\n",
      "Epoch:  13     Batch:  242  /  468     Loss_generator:  0.7136383056640625     Loss_discriminator:  0.6941025257110596\n",
      "Epoch:  13     Batch:  243  /  468     Loss_generator:  0.7166647911071777     Loss_discriminator:  0.6805101037025452\n",
      "Epoch:  13     Batch:  244  /  468     Loss_generator:  0.7012523412704468     Loss_discriminator:  0.6935821175575256\n",
      "Epoch:  13     Batch:  245  /  468     Loss_generator:  0.707070529460907     Loss_discriminator:  0.6854476928710938\n",
      "Epoch:  13     Batch:  246  /  468     Loss_generator:  0.6984711289405823     Loss_discriminator:  0.6891275644302368\n",
      "Epoch:  13     Batch:  247  /  468     Loss_generator:  0.7059838175773621     Loss_discriminator:  0.6659427881240845\n",
      "Epoch:  13     Batch:  248  /  468     Loss_generator:  0.711793839931488     Loss_discriminator:  0.6777957081794739\n",
      "Epoch:  13     Batch:  249  /  468     Loss_generator:  0.7144792079925537     Loss_discriminator:  0.6919928193092346\n",
      "Epoch:  13     Batch:  250  /  468     Loss_generator:  0.74092698097229     Loss_discriminator:  0.6918619871139526\n",
      "Epoch:  13     Batch:  251  /  468     Loss_generator:  0.7176341414451599     Loss_discriminator:  0.6849309206008911\n",
      "Epoch:  13     Batch:  252  /  468     Loss_generator:  0.7183864116668701     Loss_discriminator:  0.6848859190940857\n",
      "Epoch:  13     Batch:  253  /  468     Loss_generator:  0.7221261858940125     Loss_discriminator:  0.6901165246963501\n",
      "Epoch:  13     Batch:  254  /  468     Loss_generator:  0.7462491393089294     Loss_discriminator:  0.6845200657844543\n",
      "Epoch:  13     Batch:  255  /  468     Loss_generator:  0.7328851819038391     Loss_discriminator:  0.6905661225318909\n",
      "Epoch:  13     Batch:  256  /  468     Loss_generator:  0.7388368248939514     Loss_discriminator:  0.6716704368591309\n",
      "Epoch:  13     Batch:  257  /  468     Loss_generator:  0.7447341680526733     Loss_discriminator:  0.6824620366096497\n",
      "Epoch:  13     Batch:  258  /  468     Loss_generator:  0.6882129907608032     Loss_discriminator:  0.6724048256874084\n",
      "Epoch:  13     Batch:  259  /  468     Loss_generator:  0.6851233243942261     Loss_discriminator:  0.6818855404853821\n",
      "Epoch:  13     Batch:  260  /  468     Loss_generator:  0.6703016757965088     Loss_discriminator:  0.6905125379562378\n",
      "Epoch:  13     Batch:  261  /  468     Loss_generator:  0.6971131563186646     Loss_discriminator:  0.686837911605835\n",
      "Epoch:  13     Batch:  262  /  468     Loss_generator:  0.6961342692375183     Loss_discriminator:  0.6845424771308899\n",
      "Epoch:  13     Batch:  263  /  468     Loss_generator:  0.7858222723007202     Loss_discriminator:  0.6688153147697449\n",
      "Epoch:  13     Batch:  264  /  468     Loss_generator:  0.8403162956237793     Loss_discriminator:  0.6974338889122009\n",
      "Epoch:  13     Batch:  265  /  468     Loss_generator:  0.8077137470245361     Loss_discriminator:  0.7049322128295898\n",
      "Epoch:  13     Batch:  266  /  468     Loss_generator:  0.7169110774993896     Loss_discriminator:  0.6953837275505066\n",
      "Epoch:  13     Batch:  267  /  468     Loss_generator:  0.6559690237045288     Loss_discriminator:  0.6890896558761597\n",
      "Epoch:  13     Batch:  268  /  468     Loss_generator:  0.616471529006958     Loss_discriminator:  0.6836450695991516\n",
      "Epoch:  13     Batch:  269  /  468     Loss_generator:  0.6583415865898132     Loss_discriminator:  0.6891770362854004\n",
      "Epoch:  13     Batch:  270  /  468     Loss_generator:  0.703682541847229     Loss_discriminator:  0.6987591981887817\n",
      "Epoch:  13     Batch:  271  /  468     Loss_generator:  0.7194206714630127     Loss_discriminator:  0.6810418367385864\n",
      "Epoch:  13     Batch:  272  /  468     Loss_generator:  0.7237081527709961     Loss_discriminator:  0.6780539155006409\n",
      "Epoch:  13     Batch:  273  /  468     Loss_generator:  0.7045096755027771     Loss_discriminator:  0.6889406442642212\n",
      "Epoch:  13     Batch:  274  /  468     Loss_generator:  0.6933529376983643     Loss_discriminator:  0.6716800928115845\n",
      "Epoch:  13     Batch:  275  /  468     Loss_generator:  0.6890122890472412     Loss_discriminator:  0.6902741193771362\n",
      "Epoch:  13     Batch:  276  /  468     Loss_generator:  0.7424802780151367     Loss_discriminator:  0.6905462145805359\n",
      "Epoch:  13     Batch:  277  /  468     Loss_generator:  0.7620440721511841     Loss_discriminator:  0.676727831363678\n",
      "Epoch:  13     Batch:  278  /  468     Loss_generator:  0.7537972927093506     Loss_discriminator:  0.6785280704498291\n",
      "Epoch:  13     Batch:  279  /  468     Loss_generator:  0.7433104515075684     Loss_discriminator:  0.6765331029891968\n",
      "Epoch:  13     Batch:  280  /  468     Loss_generator:  0.7082570195198059     Loss_discriminator:  0.6898788213729858\n",
      "Epoch:  13     Batch:  281  /  468     Loss_generator:  0.6774790287017822     Loss_discriminator:  0.6930524110794067\n",
      "Epoch:  13     Batch:  282  /  468     Loss_generator:  0.656309962272644     Loss_discriminator:  0.6897586584091187\n",
      "Epoch:  13     Batch:  283  /  468     Loss_generator:  0.6671500205993652     Loss_discriminator:  0.6834017038345337\n",
      "Epoch:  13     Batch:  284  /  468     Loss_generator:  0.7215351462364197     Loss_discriminator:  0.6925487518310547\n",
      "Epoch:  13     Batch:  285  /  468     Loss_generator:  0.7380093336105347     Loss_discriminator:  0.6919634938240051\n",
      "Epoch:  13     Batch:  286  /  468     Loss_generator:  0.7538394927978516     Loss_discriminator:  0.6869761943817139\n",
      "Epoch:  13     Batch:  287  /  468     Loss_generator:  0.7192342281341553     Loss_discriminator:  0.6955281496047974\n",
      "Epoch:  13     Batch:  288  /  468     Loss_generator:  0.6682567000389099     Loss_discriminator:  0.6864964962005615\n",
      "Epoch:  13     Batch:  289  /  468     Loss_generator:  0.66478431224823     Loss_discriminator:  0.678126335144043\n",
      "Epoch:  13     Batch:  290  /  468     Loss_generator:  0.6966899037361145     Loss_discriminator:  0.7004520893096924\n",
      "Epoch:  13     Batch:  291  /  468     Loss_generator:  0.7465938329696655     Loss_discriminator:  0.6660100221633911\n",
      "Epoch:  13     Batch:  292  /  468     Loss_generator:  0.7956402897834778     Loss_discriminator:  0.6693011522293091\n",
      "Epoch:  13     Batch:  293  /  468     Loss_generator:  0.7889074087142944     Loss_discriminator:  0.6843669414520264\n",
      "Epoch:  13     Batch:  294  /  468     Loss_generator:  0.7204581499099731     Loss_discriminator:  0.6944772005081177\n",
      "Epoch:  13     Batch:  295  /  468     Loss_generator:  0.6728904843330383     Loss_discriminator:  0.698041558265686\n",
      "Epoch:  13     Batch:  296  /  468     Loss_generator:  0.6509121656417847     Loss_discriminator:  0.6871813535690308\n",
      "Epoch:  13     Batch:  297  /  468     Loss_generator:  0.65423983335495     Loss_discriminator:  0.6807984113693237\n",
      "Epoch:  13     Batch:  298  /  468     Loss_generator:  0.7210955619812012     Loss_discriminator:  0.6731218099594116\n",
      "Epoch:  13     Batch:  299  /  468     Loss_generator:  0.7615034580230713     Loss_discriminator:  0.6821012496948242\n",
      "Epoch:  13     Batch:  300  /  468     Loss_generator:  0.7655949592590332     Loss_discriminator:  0.6908172369003296\n",
      "Epoch:  13     Batch:  301  /  468     Loss_generator:  0.6971695423126221     Loss_discriminator:  0.6826820969581604\n",
      "Epoch:  13     Batch:  302  /  468     Loss_generator:  0.6912418007850647     Loss_discriminator:  0.6835667490959167\n",
      "Epoch:  13     Batch:  303  /  468     Loss_generator:  0.6867265701293945     Loss_discriminator:  0.6872046589851379\n",
      "Epoch:  13     Batch:  304  /  468     Loss_generator:  0.7198680639266968     Loss_discriminator:  0.6778380274772644\n",
      "Epoch:  13     Batch:  305  /  468     Loss_generator:  0.7145708799362183     Loss_discriminator:  0.6824061870574951\n",
      "Epoch:  13     Batch:  306  /  468     Loss_generator:  0.7181598544120789     Loss_discriminator:  0.6865196824073792\n",
      "Epoch:  13     Batch:  307  /  468     Loss_generator:  0.7335777282714844     Loss_discriminator:  0.6770175695419312\n",
      "Epoch:  13     Batch:  308  /  468     Loss_generator:  0.7308186888694763     Loss_discriminator:  0.6885189414024353\n",
      "Epoch:  13     Batch:  309  /  468     Loss_generator:  0.6982505321502686     Loss_discriminator:  0.688088059425354\n",
      "Epoch:  13     Batch:  310  /  468     Loss_generator:  0.6722025275230408     Loss_discriminator:  0.6895148754119873\n",
      "Epoch:  13     Batch:  311  /  468     Loss_generator:  0.6975145936012268     Loss_discriminator:  0.6819837093353271\n",
      "Epoch:  13     Batch:  312  /  468     Loss_generator:  0.7099035978317261     Loss_discriminator:  0.6917218565940857\n",
      "Epoch:  13     Batch:  313  /  468     Loss_generator:  0.7252766489982605     Loss_discriminator:  0.6818689107894897\n",
      "Epoch:  13     Batch:  314  /  468     Loss_generator:  0.752297043800354     Loss_discriminator:  0.6859824061393738\n",
      "Epoch:  13     Batch:  315  /  468     Loss_generator:  0.7443562150001526     Loss_discriminator:  0.6803772449493408\n",
      "Epoch:  13     Batch:  316  /  468     Loss_generator:  0.7133477926254272     Loss_discriminator:  0.6848409175872803\n",
      "Epoch:  13     Batch:  317  /  468     Loss_generator:  0.6851741075515747     Loss_discriminator:  0.6877288818359375\n",
      "Epoch:  13     Batch:  318  /  468     Loss_generator:  0.6601650714874268     Loss_discriminator:  0.6927720904350281\n",
      "Epoch:  13     Batch:  319  /  468     Loss_generator:  0.6808354258537292     Loss_discriminator:  0.6790193319320679\n",
      "Epoch:  13     Batch:  320  /  468     Loss_generator:  0.6975115537643433     Loss_discriminator:  0.6917513608932495\n",
      "Epoch:  13     Batch:  321  /  468     Loss_generator:  0.7512797713279724     Loss_discriminator:  0.6884405612945557\n",
      "Epoch:  13     Batch:  322  /  468     Loss_generator:  0.7595072984695435     Loss_discriminator:  0.6875917911529541\n",
      "Epoch:  13     Batch:  323  /  468     Loss_generator:  0.7247665524482727     Loss_discriminator:  0.6814348101615906\n",
      "Epoch:  13     Batch:  324  /  468     Loss_generator:  0.6722801327705383     Loss_discriminator:  0.6896513104438782\n",
      "Epoch:  13     Batch:  325  /  468     Loss_generator:  0.6659444570541382     Loss_discriminator:  0.6856552362442017\n",
      "Epoch:  13     Batch:  326  /  468     Loss_generator:  0.6749744415283203     Loss_discriminator:  0.68306565284729\n",
      "Epoch:  13     Batch:  327  /  468     Loss_generator:  0.7395392656326294     Loss_discriminator:  0.6877754926681519\n",
      "Epoch:  13     Batch:  328  /  468     Loss_generator:  0.7752198576927185     Loss_discriminator:  0.6804063320159912\n",
      "Epoch:  13     Batch:  329  /  468     Loss_generator:  0.749901533126831     Loss_discriminator:  0.6825554370880127\n",
      "Epoch:  13     Batch:  330  /  468     Loss_generator:  0.7028472423553467     Loss_discriminator:  0.682327151298523\n",
      "Epoch:  13     Batch:  331  /  468     Loss_generator:  0.660730242729187     Loss_discriminator:  0.6874281167984009\n",
      "Epoch:  13     Batch:  332  /  468     Loss_generator:  0.675016462802887     Loss_discriminator:  0.6879920363426208\n",
      "Epoch:  13     Batch:  333  /  468     Loss_generator:  0.6915043592453003     Loss_discriminator:  0.6843202710151672\n",
      "Epoch:  13     Batch:  334  /  468     Loss_generator:  0.7278084754943848     Loss_discriminator:  0.692550539970398\n",
      "Epoch:  13     Batch:  335  /  468     Loss_generator:  0.7394503355026245     Loss_discriminator:  0.6841702461242676\n",
      "Epoch:  13     Batch:  336  /  468     Loss_generator:  0.7249951362609863     Loss_discriminator:  0.690199613571167\n",
      "Epoch:  13     Batch:  337  /  468     Loss_generator:  0.7221510410308838     Loss_discriminator:  0.6672355532646179\n",
      "Epoch:  13     Batch:  338  /  468     Loss_generator:  0.7110313177108765     Loss_discriminator:  0.6802630424499512\n",
      "Epoch:  13     Batch:  339  /  468     Loss_generator:  0.6810014843940735     Loss_discriminator:  0.6782470941543579\n",
      "Epoch:  13     Batch:  340  /  468     Loss_generator:  0.7080134153366089     Loss_discriminator:  0.7003019452095032\n",
      "Epoch:  13     Batch:  341  /  468     Loss_generator:  0.7617989182472229     Loss_discriminator:  0.688451886177063\n",
      "Epoch:  13     Batch:  342  /  468     Loss_generator:  0.7151869535446167     Loss_discriminator:  0.6813265681266785\n",
      "Epoch:  13     Batch:  343  /  468     Loss_generator:  0.7046045660972595     Loss_discriminator:  0.6951004266738892\n",
      "Epoch:  13     Batch:  344  /  468     Loss_generator:  0.6451146006584167     Loss_discriminator:  0.6879558563232422\n",
      "Epoch:  13     Batch:  345  /  468     Loss_generator:  0.6675542593002319     Loss_discriminator:  0.6793166995048523\n",
      "Epoch:  13     Batch:  346  /  468     Loss_generator:  0.7116711139678955     Loss_discriminator:  0.6953693628311157\n",
      "Epoch:  13     Batch:  347  /  468     Loss_generator:  0.7732971906661987     Loss_discriminator:  0.6826636791229248\n",
      "Epoch:  13     Batch:  348  /  468     Loss_generator:  0.7561797499656677     Loss_discriminator:  0.6837422251701355\n",
      "Epoch:  13     Batch:  349  /  468     Loss_generator:  0.7299387454986572     Loss_discriminator:  0.6870530843734741\n",
      "Epoch:  13     Batch:  350  /  468     Loss_generator:  0.6746557354927063     Loss_discriminator:  0.6810251474380493\n",
      "Epoch:  13     Batch:  351  /  468     Loss_generator:  0.6613122820854187     Loss_discriminator:  0.6723517179489136\n",
      "Epoch:  13     Batch:  352  /  468     Loss_generator:  0.6865509748458862     Loss_discriminator:  0.695266842842102\n",
      "Epoch:  13     Batch:  353  /  468     Loss_generator:  0.7110550999641418     Loss_discriminator:  0.6714283227920532\n",
      "Epoch:  13     Batch:  354  /  468     Loss_generator:  0.7303619980812073     Loss_discriminator:  0.6806117296218872\n",
      "Epoch:  13     Batch:  355  /  468     Loss_generator:  0.7262277603149414     Loss_discriminator:  0.6804734468460083\n",
      "Epoch:  13     Batch:  356  /  468     Loss_generator:  0.6886672973632812     Loss_discriminator:  0.689312219619751\n",
      "Epoch:  13     Batch:  357  /  468     Loss_generator:  0.6724913120269775     Loss_discriminator:  0.6952900290489197\n",
      "Epoch:  13     Batch:  358  /  468     Loss_generator:  0.6793962717056274     Loss_discriminator:  0.6846522688865662\n",
      "Epoch:  13     Batch:  359  /  468     Loss_generator:  0.7043655514717102     Loss_discriminator:  0.6850163340568542\n",
      "Epoch:  13     Batch:  360  /  468     Loss_generator:  0.7983766794204712     Loss_discriminator:  0.6843346953392029\n",
      "Epoch:  13     Batch:  361  /  468     Loss_generator:  0.7818588018417358     Loss_discriminator:  0.6941866874694824\n",
      "Epoch:  13     Batch:  362  /  468     Loss_generator:  0.7118848562240601     Loss_discriminator:  0.6902599930763245\n",
      "Epoch:  13     Batch:  363  /  468     Loss_generator:  0.6479900479316711     Loss_discriminator:  0.6888587474822998\n",
      "Epoch:  13     Batch:  364  /  468     Loss_generator:  0.6323237419128418     Loss_discriminator:  0.6666626930236816\n",
      "Epoch:  13     Batch:  365  /  468     Loss_generator:  0.6423927545547485     Loss_discriminator:  0.6769242882728577\n",
      "Epoch:  13     Batch:  366  /  468     Loss_generator:  0.7124227285385132     Loss_discriminator:  0.6926463842391968\n",
      "Epoch:  13     Batch:  367  /  468     Loss_generator:  0.7871637344360352     Loss_discriminator:  0.6957238912582397\n",
      "Epoch:  13     Batch:  368  /  468     Loss_generator:  0.834200382232666     Loss_discriminator:  0.6784694194793701\n",
      "Epoch:  13     Batch:  369  /  468     Loss_generator:  0.7553002834320068     Loss_discriminator:  0.6907019019126892\n",
      "Epoch:  13     Batch:  370  /  468     Loss_generator:  0.6999247074127197     Loss_discriminator:  0.6918395757675171\n",
      "Epoch:  13     Batch:  371  /  468     Loss_generator:  0.6547493934631348     Loss_discriminator:  0.6807233095169067\n",
      "Epoch:  13     Batch:  372  /  468     Loss_generator:  0.6536122560501099     Loss_discriminator:  0.6845214366912842\n",
      "Epoch:  13     Batch:  373  /  468     Loss_generator:  0.6718364953994751     Loss_discriminator:  0.6982706189155579\n",
      "Epoch:  13     Batch:  374  /  468     Loss_generator:  0.723556399345398     Loss_discriminator:  0.6850335597991943\n",
      "Epoch:  13     Batch:  375  /  468     Loss_generator:  0.7810492515563965     Loss_discriminator:  0.6895872950553894\n",
      "Epoch:  13     Batch:  376  /  468     Loss_generator:  0.7772504091262817     Loss_discriminator:  0.679383397102356\n",
      "Epoch:  13     Batch:  377  /  468     Loss_generator:  0.7793382406234741     Loss_discriminator:  0.6970883011817932\n",
      "Epoch:  13     Batch:  378  /  468     Loss_generator:  0.7049598097801208     Loss_discriminator:  0.6864215731620789\n",
      "Epoch:  13     Batch:  379  /  468     Loss_generator:  0.6634057760238647     Loss_discriminator:  0.6984951496124268\n",
      "Epoch:  13     Batch:  380  /  468     Loss_generator:  0.6321848630905151     Loss_discriminator:  0.6901758909225464\n",
      "Epoch:  13     Batch:  381  /  468     Loss_generator:  0.648611843585968     Loss_discriminator:  0.6757494211196899\n",
      "Epoch:  13     Batch:  382  /  468     Loss_generator:  0.7218369841575623     Loss_discriminator:  0.6841793060302734\n",
      "Epoch:  13     Batch:  383  /  468     Loss_generator:  0.736997663974762     Loss_discriminator:  0.6935504674911499\n",
      "Epoch:  13     Batch:  384  /  468     Loss_generator:  0.7263857126235962     Loss_discriminator:  0.6950789093971252\n",
      "Epoch:  13     Batch:  385  /  468     Loss_generator:  0.7031652927398682     Loss_discriminator:  0.6877641677856445\n",
      "Epoch:  13     Batch:  386  /  468     Loss_generator:  0.7150413990020752     Loss_discriminator:  0.6917550563812256\n",
      "Epoch:  13     Batch:  387  /  468     Loss_generator:  0.7269598245620728     Loss_discriminator:  0.6820589303970337\n",
      "Epoch:  13     Batch:  388  /  468     Loss_generator:  0.7213441133499146     Loss_discriminator:  0.6820030212402344\n",
      "Epoch:  13     Batch:  389  /  468     Loss_generator:  0.733881413936615     Loss_discriminator:  0.6882791519165039\n",
      "Epoch:  13     Batch:  390  /  468     Loss_generator:  0.7137678861618042     Loss_discriminator:  0.6813287734985352\n",
      "Epoch:  13     Batch:  391  /  468     Loss_generator:  0.6800842881202698     Loss_discriminator:  0.6941022872924805\n",
      "Epoch:  13     Batch:  392  /  468     Loss_generator:  0.6957391500473022     Loss_discriminator:  0.6879867315292358\n",
      "Epoch:  13     Batch:  393  /  468     Loss_generator:  0.7108758687973022     Loss_discriminator:  0.6821343898773193\n",
      "Epoch:  13     Batch:  394  /  468     Loss_generator:  0.7336757779121399     Loss_discriminator:  0.6877472400665283\n",
      "Epoch:  13     Batch:  395  /  468     Loss_generator:  0.7300089597702026     Loss_discriminator:  0.6660631895065308\n",
      "Epoch:  13     Batch:  396  /  468     Loss_generator:  0.7168853878974915     Loss_discriminator:  0.6894184350967407\n",
      "Epoch:  13     Batch:  397  /  468     Loss_generator:  0.6846270561218262     Loss_discriminator:  0.6762782335281372\n",
      "Epoch:  13     Batch:  398  /  468     Loss_generator:  0.6724233031272888     Loss_discriminator:  0.6639661192893982\n",
      "Epoch:  13     Batch:  399  /  468     Loss_generator:  0.6767668724060059     Loss_discriminator:  0.6887697577476501\n",
      "Epoch:  13     Batch:  400  /  468     Loss_generator:  0.731265127658844     Loss_discriminator:  0.6860412359237671\n",
      "Epoch:  13     Batch:  401  /  468     Loss_generator:  0.7656096816062927     Loss_discriminator:  0.6705039739608765\n",
      "Epoch:  13     Batch:  402  /  468     Loss_generator:  0.7646592855453491     Loss_discriminator:  0.6862568259239197\n",
      "Epoch:  13     Batch:  403  /  468     Loss_generator:  0.6954687833786011     Loss_discriminator:  0.6918199062347412\n",
      "Epoch:  13     Batch:  404  /  468     Loss_generator:  0.6804533004760742     Loss_discriminator:  0.686607837677002\n",
      "Epoch:  13     Batch:  405  /  468     Loss_generator:  0.6711903214454651     Loss_discriminator:  0.6901306509971619\n",
      "Epoch:  13     Batch:  406  /  468     Loss_generator:  0.6776459813117981     Loss_discriminator:  0.6741222739219666\n",
      "Epoch:  13     Batch:  407  /  468     Loss_generator:  0.6969996690750122     Loss_discriminator:  0.6781635880470276\n",
      "Epoch:  13     Batch:  408  /  468     Loss_generator:  0.7275470495223999     Loss_discriminator:  0.6862748265266418\n",
      "Epoch:  13     Batch:  409  /  468     Loss_generator:  0.7374928593635559     Loss_discriminator:  0.6845352649688721\n",
      "Epoch:  13     Batch:  410  /  468     Loss_generator:  0.7330790162086487     Loss_discriminator:  0.6842752695083618\n",
      "Epoch:  13     Batch:  411  /  468     Loss_generator:  0.7083868980407715     Loss_discriminator:  0.690122663974762\n",
      "Epoch:  13     Batch:  412  /  468     Loss_generator:  0.6829732656478882     Loss_discriminator:  0.6838434934616089\n",
      "Epoch:  13     Batch:  413  /  468     Loss_generator:  0.7145810127258301     Loss_discriminator:  0.6851019263267517\n",
      "Epoch:  13     Batch:  414  /  468     Loss_generator:  0.7303788661956787     Loss_discriminator:  0.6940351128578186\n",
      "Epoch:  13     Batch:  415  /  468     Loss_generator:  0.701797604560852     Loss_discriminator:  0.6936628818511963\n",
      "Epoch:  13     Batch:  416  /  468     Loss_generator:  0.7182303667068481     Loss_discriminator:  0.6881559491157532\n",
      "Epoch:  13     Batch:  417  /  468     Loss_generator:  0.730601966381073     Loss_discriminator:  0.6895313262939453\n",
      "Epoch:  13     Batch:  418  /  468     Loss_generator:  0.7304116487503052     Loss_discriminator:  0.6752901077270508\n",
      "Epoch:  13     Batch:  419  /  468     Loss_generator:  0.7122583985328674     Loss_discriminator:  0.6821045875549316\n",
      "Epoch:  13     Batch:  420  /  468     Loss_generator:  0.6858093738555908     Loss_discriminator:  0.6875025033950806\n",
      "Epoch:  13     Batch:  421  /  468     Loss_generator:  0.7026149034500122     Loss_discriminator:  0.6802433729171753\n",
      "Epoch:  13     Batch:  422  /  468     Loss_generator:  0.7039650082588196     Loss_discriminator:  0.687915563583374\n",
      "Epoch:  13     Batch:  423  /  468     Loss_generator:  0.7039740085601807     Loss_discriminator:  0.6858388185501099\n",
      "Epoch:  13     Batch:  424  /  468     Loss_generator:  0.6837093234062195     Loss_discriminator:  0.6894035935401917\n",
      "Epoch:  13     Batch:  425  /  468     Loss_generator:  0.7175984382629395     Loss_discriminator:  0.6887964010238647\n",
      "Epoch:  13     Batch:  426  /  468     Loss_generator:  0.697056233882904     Loss_discriminator:  0.6728071570396423\n",
      "Epoch:  13     Batch:  427  /  468     Loss_generator:  0.6806553602218628     Loss_discriminator:  0.6716442108154297\n",
      "Epoch:  13     Batch:  428  /  468     Loss_generator:  0.708369255065918     Loss_discriminator:  0.6637328863143921\n",
      "Epoch:  13     Batch:  429  /  468     Loss_generator:  0.7251514792442322     Loss_discriminator:  0.688273012638092\n",
      "Epoch:  13     Batch:  430  /  468     Loss_generator:  0.7465261816978455     Loss_discriminator:  0.6863739490509033\n",
      "Epoch:  13     Batch:  431  /  468     Loss_generator:  0.7592247724533081     Loss_discriminator:  0.6820677518844604\n",
      "Epoch:  13     Batch:  432  /  468     Loss_generator:  0.7239137291908264     Loss_discriminator:  0.683546245098114\n",
      "Epoch:  13     Batch:  433  /  468     Loss_generator:  0.679818868637085     Loss_discriminator:  0.6785867810249329\n",
      "Epoch:  13     Batch:  434  /  468     Loss_generator:  0.665006697177887     Loss_discriminator:  0.7027673721313477\n",
      "Epoch:  13     Batch:  435  /  468     Loss_generator:  0.6996480822563171     Loss_discriminator:  0.6875523924827576\n",
      "Epoch:  13     Batch:  436  /  468     Loss_generator:  0.7481983304023743     Loss_discriminator:  0.6792194843292236\n",
      "Epoch:  13     Batch:  437  /  468     Loss_generator:  0.7494303584098816     Loss_discriminator:  0.6968806982040405\n",
      "Epoch:  13     Batch:  438  /  468     Loss_generator:  0.7219575643539429     Loss_discriminator:  0.6851054430007935\n",
      "Epoch:  13     Batch:  439  /  468     Loss_generator:  0.7027217149734497     Loss_discriminator:  0.6902165412902832\n",
      "Epoch:  13     Batch:  440  /  468     Loss_generator:  0.6881885528564453     Loss_discriminator:  0.6930623054504395\n",
      "Epoch:  13     Batch:  441  /  468     Loss_generator:  0.6759258508682251     Loss_discriminator:  0.6862727403640747\n",
      "Epoch:  13     Batch:  442  /  468     Loss_generator:  0.7292064428329468     Loss_discriminator:  0.6770456433296204\n",
      "Epoch:  13     Batch:  443  /  468     Loss_generator:  0.7493927478790283     Loss_discriminator:  0.6963355541229248\n",
      "Epoch:  13     Batch:  444  /  468     Loss_generator:  0.7409529685974121     Loss_discriminator:  0.6834717392921448\n",
      "Epoch:  13     Batch:  445  /  468     Loss_generator:  0.6711192727088928     Loss_discriminator:  0.6863547563552856\n",
      "Epoch:  13     Batch:  446  /  468     Loss_generator:  0.6604067087173462     Loss_discriminator:  0.6840692758560181\n",
      "Epoch:  13     Batch:  447  /  468     Loss_generator:  0.6649237871170044     Loss_discriminator:  0.6915009617805481\n",
      "Epoch:  13     Batch:  448  /  468     Loss_generator:  0.697386622428894     Loss_discriminator:  0.6860253810882568\n",
      "Epoch:  13     Batch:  449  /  468     Loss_generator:  0.7466564774513245     Loss_discriminator:  0.6866928339004517\n",
      "Epoch:  13     Batch:  450  /  468     Loss_generator:  0.765546977519989     Loss_discriminator:  0.693284273147583\n",
      "Epoch:  13     Batch:  451  /  468     Loss_generator:  0.7429333925247192     Loss_discriminator:  0.7046926021575928\n",
      "Epoch:  13     Batch:  452  /  468     Loss_generator:  0.6979405283927917     Loss_discriminator:  0.688651978969574\n",
      "Epoch:  13     Batch:  453  /  468     Loss_generator:  0.6686104536056519     Loss_discriminator:  0.6800300478935242\n",
      "Epoch:  13     Batch:  454  /  468     Loss_generator:  0.6730605363845825     Loss_discriminator:  0.6845730543136597\n",
      "Epoch:  13     Batch:  455  /  468     Loss_generator:  0.7015992403030396     Loss_discriminator:  0.6905546188354492\n",
      "Epoch:  13     Batch:  456  /  468     Loss_generator:  0.7130616307258606     Loss_discriminator:  0.6824995279312134\n",
      "Epoch:  13     Batch:  457  /  468     Loss_generator:  0.7298429012298584     Loss_discriminator:  0.6974867582321167\n",
      "Epoch:  13     Batch:  458  /  468     Loss_generator:  0.7424836158752441     Loss_discriminator:  0.6847527027130127\n",
      "Epoch:  13     Batch:  459  /  468     Loss_generator:  0.7054251432418823     Loss_discriminator:  0.6866572499275208\n",
      "Epoch:  13     Batch:  460  /  468     Loss_generator:  0.6922101378440857     Loss_discriminator:  0.6769861578941345\n",
      "Epoch:  13     Batch:  461  /  468     Loss_generator:  0.7109563946723938     Loss_discriminator:  0.6849533319473267\n",
      "Epoch:  13     Batch:  462  /  468     Loss_generator:  0.6854989528656006     Loss_discriminator:  0.6844010949134827\n",
      "Epoch:  13     Batch:  463  /  468     Loss_generator:  0.7295445799827576     Loss_discriminator:  0.6973016262054443\n",
      "Epoch:  13     Batch:  464  /  468     Loss_generator:  0.6964426040649414     Loss_discriminator:  0.6884344816207886\n",
      "Epoch:  13     Batch:  465  /  468     Loss_generator:  0.7253199815750122     Loss_discriminator:  0.6823806762695312\n",
      "Epoch:  13     Batch:  466  /  468     Loss_generator:  0.6953597068786621     Loss_discriminator:  0.6863265037536621\n",
      "Epoch:  13     Batch:  467  /  468     Loss_generator:  0.712516188621521     Loss_discriminator:  0.6862407922744751\n",
      "Epoch:  14     Batch:  0  /  468     Loss_generator:  0.7222229838371277     Loss_discriminator:  0.6883553266525269\n",
      "Epoch:  14     Batch:  1  /  468     Loss_generator:  0.7086368203163147     Loss_discriminator:  0.6775896549224854\n",
      "Epoch:  14     Batch:  2  /  468     Loss_generator:  0.7039942741394043     Loss_discriminator:  0.6869838237762451\n",
      "Epoch:  14     Batch:  3  /  468     Loss_generator:  0.7324204444885254     Loss_discriminator:  0.6821187734603882\n",
      "Epoch:  14     Batch:  4  /  468     Loss_generator:  0.7647420167922974     Loss_discriminator:  0.6874153017997742\n",
      "Epoch:  14     Batch:  5  /  468     Loss_generator:  0.698819637298584     Loss_discriminator:  0.7127920985221863\n",
      "Epoch:  14     Batch:  6  /  468     Loss_generator:  0.6696040034294128     Loss_discriminator:  0.7009998559951782\n",
      "Epoch:  14     Batch:  7  /  468     Loss_generator:  0.6585981845855713     Loss_discriminator:  0.6884735226631165\n",
      "Epoch:  14     Batch:  8  /  468     Loss_generator:  0.6704146862030029     Loss_discriminator:  0.6908860206604004\n",
      "Epoch:  14     Batch:  9  /  468     Loss_generator:  0.7352086901664734     Loss_discriminator:  0.6924984455108643\n",
      "Epoch:  14     Batch:  10  /  468     Loss_generator:  0.7745723724365234     Loss_discriminator:  0.6867575645446777\n",
      "Epoch:  14     Batch:  11  /  468     Loss_generator:  0.7454978823661804     Loss_discriminator:  0.699020504951477\n",
      "Epoch:  14     Batch:  12  /  468     Loss_generator:  0.6823887825012207     Loss_discriminator:  0.6797854900360107\n",
      "Epoch:  14     Batch:  13  /  468     Loss_generator:  0.6639134883880615     Loss_discriminator:  0.6954074501991272\n",
      "Epoch:  14     Batch:  14  /  468     Loss_generator:  0.6782293319702148     Loss_discriminator:  0.6813151836395264\n",
      "Epoch:  14     Batch:  15  /  468     Loss_generator:  0.7174001336097717     Loss_discriminator:  0.6703245043754578\n",
      "Epoch:  14     Batch:  16  /  468     Loss_generator:  0.7464931607246399     Loss_discriminator:  0.6785659790039062\n",
      "Epoch:  14     Batch:  17  /  468     Loss_generator:  0.7322912216186523     Loss_discriminator:  0.6844223737716675\n",
      "Epoch:  14     Batch:  18  /  468     Loss_generator:  0.7305970191955566     Loss_discriminator:  0.6974442005157471\n",
      "Epoch:  14     Batch:  19  /  468     Loss_generator:  0.709176778793335     Loss_discriminator:  0.6792938709259033\n",
      "Epoch:  14     Batch:  20  /  468     Loss_generator:  0.6978013515472412     Loss_discriminator:  0.6875529885292053\n",
      "Epoch:  14     Batch:  21  /  468     Loss_generator:  0.7051210403442383     Loss_discriminator:  0.6869769096374512\n",
      "Epoch:  14     Batch:  22  /  468     Loss_generator:  0.6904246211051941     Loss_discriminator:  0.6867552995681763\n",
      "Epoch:  14     Batch:  23  /  468     Loss_generator:  0.7039155960083008     Loss_discriminator:  0.6842869520187378\n",
      "Epoch:  14     Batch:  24  /  468     Loss_generator:  0.7506982088088989     Loss_discriminator:  0.6906958818435669\n",
      "Epoch:  14     Batch:  25  /  468     Loss_generator:  0.7563368678092957     Loss_discriminator:  0.6789885759353638\n",
      "Epoch:  14     Batch:  26  /  468     Loss_generator:  0.7045019865036011     Loss_discriminator:  0.6996074914932251\n",
      "Epoch:  14     Batch:  27  /  468     Loss_generator:  0.6649588942527771     Loss_discriminator:  0.6864610314369202\n",
      "Epoch:  14     Batch:  28  /  468     Loss_generator:  0.6541234254837036     Loss_discriminator:  0.689307451248169\n",
      "Epoch:  14     Batch:  29  /  468     Loss_generator:  0.6835120916366577     Loss_discriminator:  0.6940028667449951\n",
      "Epoch:  14     Batch:  30  /  468     Loss_generator:  0.7131402492523193     Loss_discriminator:  0.6828310489654541\n",
      "Epoch:  14     Batch:  31  /  468     Loss_generator:  0.8093549013137817     Loss_discriminator:  0.674323558807373\n",
      "Epoch:  14     Batch:  32  /  468     Loss_generator:  0.816380500793457     Loss_discriminator:  0.6860315799713135\n",
      "Epoch:  14     Batch:  33  /  468     Loss_generator:  0.7493050694465637     Loss_discriminator:  0.6940842270851135\n",
      "Epoch:  14     Batch:  34  /  468     Loss_generator:  0.6925449967384338     Loss_discriminator:  0.6642147302627563\n",
      "Epoch:  14     Batch:  35  /  468     Loss_generator:  0.6667657494544983     Loss_discriminator:  0.6940871477127075\n",
      "Epoch:  14     Batch:  36  /  468     Loss_generator:  0.6634612083435059     Loss_discriminator:  0.6853541135787964\n",
      "Epoch:  14     Batch:  37  /  468     Loss_generator:  0.6956270933151245     Loss_discriminator:  0.6857816576957703\n",
      "Epoch:  14     Batch:  38  /  468     Loss_generator:  0.745510458946228     Loss_discriminator:  0.6947729587554932\n",
      "Epoch:  14     Batch:  39  /  468     Loss_generator:  0.736771821975708     Loss_discriminator:  0.6873643398284912\n",
      "Epoch:  14     Batch:  40  /  468     Loss_generator:  0.72999107837677     Loss_discriminator:  0.6817011833190918\n",
      "Epoch:  14     Batch:  41  /  468     Loss_generator:  0.6930094957351685     Loss_discriminator:  0.6708923578262329\n",
      "Epoch:  14     Batch:  42  /  468     Loss_generator:  0.664254903793335     Loss_discriminator:  0.691383957862854\n",
      "Epoch:  14     Batch:  43  /  468     Loss_generator:  0.6792863011360168     Loss_discriminator:  0.6686567068099976\n",
      "Epoch:  14     Batch:  44  /  468     Loss_generator:  0.7077902555465698     Loss_discriminator:  0.6810464859008789\n",
      "Epoch:  14     Batch:  45  /  468     Loss_generator:  0.7228544354438782     Loss_discriminator:  0.6840007901191711\n",
      "Epoch:  14     Batch:  46  /  468     Loss_generator:  0.7347262501716614     Loss_discriminator:  0.6931134462356567\n",
      "Epoch:  14     Batch:  47  /  468     Loss_generator:  0.7117985486984253     Loss_discriminator:  0.6851217746734619\n",
      "Epoch:  14     Batch:  48  /  468     Loss_generator:  0.6883525252342224     Loss_discriminator:  0.6868059039115906\n",
      "Epoch:  14     Batch:  49  /  468     Loss_generator:  0.6865635514259338     Loss_discriminator:  0.6806618571281433\n",
      "Epoch:  14     Batch:  50  /  468     Loss_generator:  0.7170449495315552     Loss_discriminator:  0.6928353309631348\n",
      "Epoch:  14     Batch:  51  /  468     Loss_generator:  0.7478756308555603     Loss_discriminator:  0.687900960445404\n",
      "Epoch:  14     Batch:  52  /  468     Loss_generator:  0.7565619349479675     Loss_discriminator:  0.6803323030471802\n",
      "Epoch:  14     Batch:  53  /  468     Loss_generator:  0.7721625566482544     Loss_discriminator:  0.6723898649215698\n",
      "Epoch:  14     Batch:  54  /  468     Loss_generator:  0.6811933517456055     Loss_discriminator:  0.6842181086540222\n",
      "Epoch:  14     Batch:  55  /  468     Loss_generator:  0.6573971509933472     Loss_discriminator:  0.6816540956497192\n",
      "Epoch:  14     Batch:  56  /  468     Loss_generator:  0.6776703596115112     Loss_discriminator:  0.6751419305801392\n",
      "Epoch:  14     Batch:  57  /  468     Loss_generator:  0.6915163993835449     Loss_discriminator:  0.6874201893806458\n",
      "Epoch:  14     Batch:  58  /  468     Loss_generator:  0.7374238967895508     Loss_discriminator:  0.689661979675293\n",
      "Epoch:  14     Batch:  59  /  468     Loss_generator:  0.7451987266540527     Loss_discriminator:  0.6851810812950134\n",
      "Epoch:  14     Batch:  60  /  468     Loss_generator:  0.7298979759216309     Loss_discriminator:  0.6896104216575623\n",
      "Epoch:  14     Batch:  61  /  468     Loss_generator:  0.7025439739227295     Loss_discriminator:  0.682294487953186\n",
      "Epoch:  14     Batch:  62  /  468     Loss_generator:  0.7063843011856079     Loss_discriminator:  0.6763564348220825\n",
      "Epoch:  14     Batch:  63  /  468     Loss_generator:  0.695529580116272     Loss_discriminator:  0.6947003602981567\n",
      "Epoch:  14     Batch:  64  /  468     Loss_generator:  0.6975339651107788     Loss_discriminator:  0.6926565766334534\n",
      "Epoch:  14     Batch:  65  /  468     Loss_generator:  0.6925551295280457     Loss_discriminator:  0.6847503185272217\n",
      "Epoch:  14     Batch:  66  /  468     Loss_generator:  0.7021161317825317     Loss_discriminator:  0.683499276638031\n",
      "Epoch:  14     Batch:  67  /  468     Loss_generator:  0.7311347126960754     Loss_discriminator:  0.6818712949752808\n",
      "Epoch:  14     Batch:  68  /  468     Loss_generator:  0.7392989993095398     Loss_discriminator:  0.6825318336486816\n",
      "Epoch:  14     Batch:  69  /  468     Loss_generator:  0.7099733352661133     Loss_discriminator:  0.6831256151199341\n",
      "Epoch:  14     Batch:  70  /  468     Loss_generator:  0.6972765922546387     Loss_discriminator:  0.6948515176773071\n",
      "Epoch:  14     Batch:  71  /  468     Loss_generator:  0.7130282521247864     Loss_discriminator:  0.6863837242126465\n",
      "Epoch:  14     Batch:  72  /  468     Loss_generator:  0.7027443647384644     Loss_discriminator:  0.6793609857559204\n",
      "Epoch:  14     Batch:  73  /  468     Loss_generator:  0.7006362080574036     Loss_discriminator:  0.678371250629425\n",
      "Epoch:  14     Batch:  74  /  468     Loss_generator:  0.6895684599876404     Loss_discriminator:  0.6746963858604431\n",
      "Epoch:  14     Batch:  75  /  468     Loss_generator:  0.6697502136230469     Loss_discriminator:  0.694118320941925\n",
      "Epoch:  14     Batch:  76  /  468     Loss_generator:  0.6617215871810913     Loss_discriminator:  0.6701561212539673\n",
      "Epoch:  14     Batch:  77  /  468     Loss_generator:  0.6736791133880615     Loss_discriminator:  0.6682318449020386\n",
      "Epoch:  14     Batch:  78  /  468     Loss_generator:  0.729397177696228     Loss_discriminator:  0.6823862791061401\n",
      "Epoch:  14     Batch:  79  /  468     Loss_generator:  0.7406907081604004     Loss_discriminator:  0.6900557279586792\n",
      "Epoch:  14     Batch:  80  /  468     Loss_generator:  0.7388507127761841     Loss_discriminator:  0.6789265871047974\n",
      "Epoch:  14     Batch:  81  /  468     Loss_generator:  0.7106897234916687     Loss_discriminator:  0.6854583621025085\n",
      "Epoch:  14     Batch:  82  /  468     Loss_generator:  0.6969293355941772     Loss_discriminator:  0.6962524652481079\n",
      "Epoch:  14     Batch:  83  /  468     Loss_generator:  0.7058974504470825     Loss_discriminator:  0.6882864832878113\n",
      "Epoch:  14     Batch:  84  /  468     Loss_generator:  0.714154839515686     Loss_discriminator:  0.6890975832939148\n",
      "Epoch:  14     Batch:  85  /  468     Loss_generator:  0.7268595695495605     Loss_discriminator:  0.6879788637161255\n",
      "Epoch:  14     Batch:  86  /  468     Loss_generator:  0.7138829231262207     Loss_discriminator:  0.690087616443634\n",
      "Epoch:  14     Batch:  87  /  468     Loss_generator:  0.7081096172332764     Loss_discriminator:  0.6891145706176758\n",
      "Epoch:  14     Batch:  88  /  468     Loss_generator:  0.6751352548599243     Loss_discriminator:  0.6741509437561035\n",
      "Epoch:  14     Batch:  89  /  468     Loss_generator:  0.7083753347396851     Loss_discriminator:  0.6782081127166748\n",
      "Epoch:  14     Batch:  90  /  468     Loss_generator:  0.7459943294525146     Loss_discriminator:  0.6928213834762573\n",
      "Epoch:  14     Batch:  91  /  468     Loss_generator:  0.7473090887069702     Loss_discriminator:  0.6915488839149475\n",
      "Epoch:  14     Batch:  92  /  468     Loss_generator:  0.738768458366394     Loss_discriminator:  0.6804285049438477\n",
      "Epoch:  14     Batch:  93  /  468     Loss_generator:  0.7264478802680969     Loss_discriminator:  0.6829477548599243\n",
      "Epoch:  14     Batch:  94  /  468     Loss_generator:  0.678743302822113     Loss_discriminator:  0.6862326860427856\n",
      "Epoch:  14     Batch:  95  /  468     Loss_generator:  0.6852863430976868     Loss_discriminator:  0.6856100559234619\n",
      "Epoch:  14     Batch:  96  /  468     Loss_generator:  0.7031946778297424     Loss_discriminator:  0.6871083974838257\n",
      "Epoch:  14     Batch:  97  /  468     Loss_generator:  0.7468364238739014     Loss_discriminator:  0.6833736896514893\n",
      "Epoch:  14     Batch:  98  /  468     Loss_generator:  0.7687822580337524     Loss_discriminator:  0.6975169777870178\n",
      "Epoch:  14     Batch:  99  /  468     Loss_generator:  0.7430312037467957     Loss_discriminator:  0.6712460517883301\n",
      "Epoch:  14     Batch:  100  /  468     Loss_generator:  0.723658561706543     Loss_discriminator:  0.6859027147293091\n",
      "Epoch:  14     Batch:  101  /  468     Loss_generator:  0.6851838827133179     Loss_discriminator:  0.6903811693191528\n",
      "Epoch:  14     Batch:  102  /  468     Loss_generator:  0.6587363481521606     Loss_discriminator:  0.6850407719612122\n",
      "Epoch:  14     Batch:  103  /  468     Loss_generator:  0.7036738991737366     Loss_discriminator:  0.6975647211074829\n",
      "Epoch:  14     Batch:  104  /  468     Loss_generator:  0.7747966051101685     Loss_discriminator:  0.6943888664245605\n",
      "Epoch:  14     Batch:  105  /  468     Loss_generator:  0.7614116668701172     Loss_discriminator:  0.6723488569259644\n",
      "Epoch:  14     Batch:  106  /  468     Loss_generator:  0.7257641553878784     Loss_discriminator:  0.691340982913971\n",
      "Epoch:  14     Batch:  107  /  468     Loss_generator:  0.7066749334335327     Loss_discriminator:  0.6940689086914062\n",
      "Epoch:  14     Batch:  108  /  468     Loss_generator:  0.6756325364112854     Loss_discriminator:  0.6826877593994141\n",
      "Epoch:  14     Batch:  109  /  468     Loss_generator:  0.6748432517051697     Loss_discriminator:  0.6708080768585205\n",
      "Epoch:  14     Batch:  110  /  468     Loss_generator:  0.7250182032585144     Loss_discriminator:  0.7017610669136047\n",
      "Epoch:  14     Batch:  111  /  468     Loss_generator:  0.754805862903595     Loss_discriminator:  0.6814051270484924\n",
      "Epoch:  14     Batch:  112  /  468     Loss_generator:  0.7154818177223206     Loss_discriminator:  0.6890410780906677\n",
      "Epoch:  14     Batch:  113  /  468     Loss_generator:  0.7095955014228821     Loss_discriminator:  0.6870629787445068\n",
      "Epoch:  14     Batch:  114  /  468     Loss_generator:  0.6890168786048889     Loss_discriminator:  0.6852652430534363\n",
      "Epoch:  14     Batch:  115  /  468     Loss_generator:  0.6906511783599854     Loss_discriminator:  0.6965616345405579\n",
      "Epoch:  14     Batch:  116  /  468     Loss_generator:  0.7003791332244873     Loss_discriminator:  0.6832178235054016\n",
      "Epoch:  14     Batch:  117  /  468     Loss_generator:  0.7180814743041992     Loss_discriminator:  0.6810287833213806\n",
      "Epoch:  14     Batch:  118  /  468     Loss_generator:  0.6961522102355957     Loss_discriminator:  0.6827688217163086\n",
      "Epoch:  14     Batch:  119  /  468     Loss_generator:  0.7133992910385132     Loss_discriminator:  0.6801728010177612\n",
      "Epoch:  14     Batch:  120  /  468     Loss_generator:  0.7113876342773438     Loss_discriminator:  0.6834118366241455\n",
      "Epoch:  14     Batch:  121  /  468     Loss_generator:  0.7199434638023376     Loss_discriminator:  0.6875412464141846\n",
      "Epoch:  14     Batch:  122  /  468     Loss_generator:  0.7132762670516968     Loss_discriminator:  0.6850327253341675\n",
      "Epoch:  14     Batch:  123  /  468     Loss_generator:  0.7271709442138672     Loss_discriminator:  0.6781082153320312\n",
      "Epoch:  14     Batch:  124  /  468     Loss_generator:  0.7219680547714233     Loss_discriminator:  0.6862227916717529\n",
      "Epoch:  14     Batch:  125  /  468     Loss_generator:  0.7188503742218018     Loss_discriminator:  0.6857378482818604\n",
      "Epoch:  14     Batch:  126  /  468     Loss_generator:  0.7188926935195923     Loss_discriminator:  0.6816487312316895\n",
      "Epoch:  14     Batch:  127  /  468     Loss_generator:  0.7283767461776733     Loss_discriminator:  0.6944606304168701\n",
      "Epoch:  14     Batch:  128  /  468     Loss_generator:  0.7047537565231323     Loss_discriminator:  0.6874886751174927\n",
      "Epoch:  14     Batch:  129  /  468     Loss_generator:  0.7231118083000183     Loss_discriminator:  0.6850424408912659\n",
      "Epoch:  14     Batch:  130  /  468     Loss_generator:  0.6954448223114014     Loss_discriminator:  0.6884939670562744\n",
      "Epoch:  14     Batch:  131  /  468     Loss_generator:  0.7156809568405151     Loss_discriminator:  0.7005481719970703\n",
      "Epoch:  14     Batch:  132  /  468     Loss_generator:  0.7200078368186951     Loss_discriminator:  0.6902284622192383\n",
      "Epoch:  14     Batch:  133  /  468     Loss_generator:  0.6957347989082336     Loss_discriminator:  0.687692403793335\n",
      "Epoch:  14     Batch:  134  /  468     Loss_generator:  0.6979391574859619     Loss_discriminator:  0.6809049844741821\n",
      "Epoch:  14     Batch:  135  /  468     Loss_generator:  0.6692654490470886     Loss_discriminator:  0.6832403540611267\n",
      "Epoch:  14     Batch:  136  /  468     Loss_generator:  0.6905453205108643     Loss_discriminator:  0.6820479035377502\n",
      "Epoch:  14     Batch:  137  /  468     Loss_generator:  0.7044969797134399     Loss_discriminator:  0.6759026050567627\n",
      "Epoch:  14     Batch:  138  /  468     Loss_generator:  0.7249330878257751     Loss_discriminator:  0.688499391078949\n",
      "Epoch:  14     Batch:  139  /  468     Loss_generator:  0.7409489154815674     Loss_discriminator:  0.6926274299621582\n",
      "Epoch:  14     Batch:  140  /  468     Loss_generator:  0.7408292293548584     Loss_discriminator:  0.683789849281311\n",
      "Epoch:  14     Batch:  141  /  468     Loss_generator:  0.7519927024841309     Loss_discriminator:  0.689139723777771\n",
      "Epoch:  14     Batch:  142  /  468     Loss_generator:  0.6974044442176819     Loss_discriminator:  0.6864596605300903\n",
      "Epoch:  14     Batch:  143  /  468     Loss_generator:  0.6966114640235901     Loss_discriminator:  0.670766294002533\n",
      "Epoch:  14     Batch:  144  /  468     Loss_generator:  0.6691721081733704     Loss_discriminator:  0.6792907118797302\n",
      "Epoch:  14     Batch:  145  /  468     Loss_generator:  0.6732525825500488     Loss_discriminator:  0.6896001696586609\n",
      "Epoch:  14     Batch:  146  /  468     Loss_generator:  0.7049456834793091     Loss_discriminator:  0.7028020620346069\n",
      "Epoch:  14     Batch:  147  /  468     Loss_generator:  0.738243043422699     Loss_discriminator:  0.6835139393806458\n",
      "Epoch:  14     Batch:  148  /  468     Loss_generator:  0.7086907625198364     Loss_discriminator:  0.6810579299926758\n",
      "Epoch:  14     Batch:  149  /  468     Loss_generator:  0.725389301776886     Loss_discriminator:  0.6749318242073059\n",
      "Epoch:  14     Batch:  150  /  468     Loss_generator:  0.7007080316543579     Loss_discriminator:  0.6773145198822021\n",
      "Epoch:  14     Batch:  151  /  468     Loss_generator:  0.6943985819816589     Loss_discriminator:  0.6870096921920776\n",
      "Epoch:  14     Batch:  152  /  468     Loss_generator:  0.7265039086341858     Loss_discriminator:  0.6943885087966919\n",
      "Epoch:  14     Batch:  153  /  468     Loss_generator:  0.6985217332839966     Loss_discriminator:  0.6895546913146973\n",
      "Epoch:  14     Batch:  154  /  468     Loss_generator:  0.6884418725967407     Loss_discriminator:  0.6807695627212524\n",
      "Epoch:  14     Batch:  155  /  468     Loss_generator:  0.7111971378326416     Loss_discriminator:  0.699524998664856\n",
      "Epoch:  14     Batch:  156  /  468     Loss_generator:  0.7149941325187683     Loss_discriminator:  0.6874247789382935\n",
      "Epoch:  14     Batch:  157  /  468     Loss_generator:  0.6754082441329956     Loss_discriminator:  0.6839249730110168\n",
      "Epoch:  14     Batch:  158  /  468     Loss_generator:  0.6690928936004639     Loss_discriminator:  0.681799590587616\n",
      "Epoch:  14     Batch:  159  /  468     Loss_generator:  0.7025848627090454     Loss_discriminator:  0.6610255241394043\n",
      "Epoch:  14     Batch:  160  /  468     Loss_generator:  0.7256516814231873     Loss_discriminator:  0.6819000840187073\n",
      "Epoch:  14     Batch:  161  /  468     Loss_generator:  0.7420167922973633     Loss_discriminator:  0.6809026002883911\n",
      "Epoch:  14     Batch:  162  /  468     Loss_generator:  0.7147973775863647     Loss_discriminator:  0.6839480400085449\n",
      "Epoch:  14     Batch:  163  /  468     Loss_generator:  0.7487770915031433     Loss_discriminator:  0.6746193766593933\n",
      "Epoch:  14     Batch:  164  /  468     Loss_generator:  0.7516767978668213     Loss_discriminator:  0.6892496347427368\n",
      "Epoch:  14     Batch:  165  /  468     Loss_generator:  0.7100188136100769     Loss_discriminator:  0.6786375641822815\n",
      "Epoch:  14     Batch:  166  /  468     Loss_generator:  0.685907244682312     Loss_discriminator:  0.6865693926811218\n",
      "Epoch:  14     Batch:  167  /  468     Loss_generator:  0.6560133695602417     Loss_discriminator:  0.6794794201850891\n",
      "Epoch:  14     Batch:  168  /  468     Loss_generator:  0.6888408660888672     Loss_discriminator:  0.6700721979141235\n",
      "Epoch:  14     Batch:  169  /  468     Loss_generator:  0.7032694816589355     Loss_discriminator:  0.6903965473175049\n",
      "Epoch:  14     Batch:  170  /  468     Loss_generator:  0.7296295762062073     Loss_discriminator:  0.6815481781959534\n",
      "Epoch:  14     Batch:  171  /  468     Loss_generator:  0.7452594637870789     Loss_discriminator:  0.675868809223175\n",
      "Epoch:  14     Batch:  172  /  468     Loss_generator:  0.7037584185600281     Loss_discriminator:  0.6834365129470825\n",
      "Epoch:  14     Batch:  173  /  468     Loss_generator:  0.6848291158676147     Loss_discriminator:  0.6937652826309204\n",
      "Epoch:  14     Batch:  174  /  468     Loss_generator:  0.7051790952682495     Loss_discriminator:  0.6753605008125305\n",
      "Epoch:  14     Batch:  175  /  468     Loss_generator:  0.7320964932441711     Loss_discriminator:  0.6808979511260986\n",
      "Epoch:  14     Batch:  176  /  468     Loss_generator:  0.7017171382904053     Loss_discriminator:  0.6643142700195312\n",
      "Epoch:  14     Batch:  177  /  468     Loss_generator:  0.6985540390014648     Loss_discriminator:  0.6831441521644592\n",
      "Epoch:  14     Batch:  178  /  468     Loss_generator:  0.6943377256393433     Loss_discriminator:  0.6779761910438538\n",
      "Epoch:  14     Batch:  179  /  468     Loss_generator:  0.7108316421508789     Loss_discriminator:  0.6852487325668335\n",
      "Epoch:  14     Batch:  180  /  468     Loss_generator:  0.7243454456329346     Loss_discriminator:  0.6923287510871887\n",
      "Epoch:  14     Batch:  181  /  468     Loss_generator:  0.738457441329956     Loss_discriminator:  0.6808533072471619\n",
      "Epoch:  14     Batch:  182  /  468     Loss_generator:  0.7149880528450012     Loss_discriminator:  0.6778398156166077\n",
      "Epoch:  14     Batch:  183  /  468     Loss_generator:  0.7175006866455078     Loss_discriminator:  0.6805596351623535\n",
      "Epoch:  14     Batch:  184  /  468     Loss_generator:  0.7062698602676392     Loss_discriminator:  0.6868231296539307\n",
      "Epoch:  14     Batch:  185  /  468     Loss_generator:  0.6957747936248779     Loss_discriminator:  0.6777895092964172\n",
      "Epoch:  14     Batch:  186  /  468     Loss_generator:  0.7047669291496277     Loss_discriminator:  0.6846702694892883\n",
      "Epoch:  14     Batch:  187  /  468     Loss_generator:  0.7013812065124512     Loss_discriminator:  0.6727979183197021\n",
      "Epoch:  14     Batch:  188  /  468     Loss_generator:  0.7484384179115295     Loss_discriminator:  0.6790368556976318\n",
      "Epoch:  14     Batch:  189  /  468     Loss_generator:  0.7277928590774536     Loss_discriminator:  0.6832887530326843\n",
      "Epoch:  14     Batch:  190  /  468     Loss_generator:  0.7075622081756592     Loss_discriminator:  0.7002089023590088\n",
      "Epoch:  14     Batch:  191  /  468     Loss_generator:  0.6940224170684814     Loss_discriminator:  0.6866116523742676\n",
      "Epoch:  14     Batch:  192  /  468     Loss_generator:  0.7096028923988342     Loss_discriminator:  0.676628053188324\n",
      "Epoch:  14     Batch:  193  /  468     Loss_generator:  0.707717776298523     Loss_discriminator:  0.6804012656211853\n",
      "Epoch:  14     Batch:  194  /  468     Loss_generator:  0.7302846908569336     Loss_discriminator:  0.6954967975616455\n",
      "Epoch:  14     Batch:  195  /  468     Loss_generator:  0.7343766689300537     Loss_discriminator:  0.6896869540214539\n",
      "Epoch:  14     Batch:  196  /  468     Loss_generator:  0.7243925333023071     Loss_discriminator:  0.6850892901420593\n",
      "Epoch:  14     Batch:  197  /  468     Loss_generator:  0.6924951076507568     Loss_discriminator:  0.6794719696044922\n",
      "Epoch:  14     Batch:  198  /  468     Loss_generator:  0.6732652187347412     Loss_discriminator:  0.6817458868026733\n",
      "Epoch:  14     Batch:  199  /  468     Loss_generator:  0.6840333342552185     Loss_discriminator:  0.6809936165809631\n",
      "Epoch:  14     Batch:  200  /  468     Loss_generator:  0.717592179775238     Loss_discriminator:  0.6740356683731079\n",
      "Epoch:  14     Batch:  201  /  468     Loss_generator:  0.7123839855194092     Loss_discriminator:  0.6801673769950867\n",
      "Epoch:  14     Batch:  202  /  468     Loss_generator:  0.7219929099082947     Loss_discriminator:  0.6826073527336121\n",
      "Epoch:  14     Batch:  203  /  468     Loss_generator:  0.7432034015655518     Loss_discriminator:  0.6788243055343628\n",
      "Epoch:  14     Batch:  204  /  468     Loss_generator:  0.6907769441604614     Loss_discriminator:  0.6945517659187317\n",
      "Epoch:  14     Batch:  205  /  468     Loss_generator:  0.6864434480667114     Loss_discriminator:  0.6796007752418518\n",
      "Epoch:  14     Batch:  206  /  468     Loss_generator:  0.6917985081672668     Loss_discriminator:  0.6779530644416809\n",
      "Epoch:  14     Batch:  207  /  468     Loss_generator:  0.7250582575798035     Loss_discriminator:  0.667474627494812\n",
      "Epoch:  14     Batch:  208  /  468     Loss_generator:  0.7355327010154724     Loss_discriminator:  0.6970250606536865\n",
      "Epoch:  14     Batch:  209  /  468     Loss_generator:  0.7155159711837769     Loss_discriminator:  0.6758729219436646\n",
      "Epoch:  14     Batch:  210  /  468     Loss_generator:  0.7248709201812744     Loss_discriminator:  0.6967594027519226\n",
      "Epoch:  14     Batch:  211  /  468     Loss_generator:  0.7130841016769409     Loss_discriminator:  0.6711411476135254\n",
      "Epoch:  14     Batch:  212  /  468     Loss_generator:  0.7230246067047119     Loss_discriminator:  0.6900893449783325\n",
      "Epoch:  14     Batch:  213  /  468     Loss_generator:  0.710760235786438     Loss_discriminator:  0.6884124875068665\n",
      "Epoch:  14     Batch:  214  /  468     Loss_generator:  0.6998908519744873     Loss_discriminator:  0.6920163035392761\n",
      "Epoch:  14     Batch:  215  /  468     Loss_generator:  0.6886814832687378     Loss_discriminator:  0.6784567832946777\n",
      "Epoch:  14     Batch:  216  /  468     Loss_generator:  0.7040921449661255     Loss_discriminator:  0.6904152035713196\n",
      "Epoch:  14     Batch:  217  /  468     Loss_generator:  0.7382290959358215     Loss_discriminator:  0.6759214401245117\n",
      "Epoch:  14     Batch:  218  /  468     Loss_generator:  0.7437258362770081     Loss_discriminator:  0.6821498274803162\n",
      "Epoch:  14     Batch:  219  /  468     Loss_generator:  0.7746279835700989     Loss_discriminator:  0.6918376088142395\n",
      "Epoch:  14     Batch:  220  /  468     Loss_generator:  0.7672635912895203     Loss_discriminator:  0.6823304891586304\n",
      "Epoch:  14     Batch:  221  /  468     Loss_generator:  0.7249764204025269     Loss_discriminator:  0.6784001588821411\n",
      "Epoch:  14     Batch:  222  /  468     Loss_generator:  0.6978532075881958     Loss_discriminator:  0.6765121221542358\n",
      "Epoch:  14     Batch:  223  /  468     Loss_generator:  0.6772069931030273     Loss_discriminator:  0.6945686340332031\n",
      "Epoch:  14     Batch:  224  /  468     Loss_generator:  0.6638721227645874     Loss_discriminator:  0.6800168752670288\n",
      "Epoch:  14     Batch:  225  /  468     Loss_generator:  0.6894935369491577     Loss_discriminator:  0.681132435798645\n",
      "Epoch:  14     Batch:  226  /  468     Loss_generator:  0.7320350408554077     Loss_discriminator:  0.6872909069061279\n",
      "Epoch:  14     Batch:  227  /  468     Loss_generator:  0.723117470741272     Loss_discriminator:  0.6889239549636841\n",
      "Epoch:  14     Batch:  228  /  468     Loss_generator:  0.6970198154449463     Loss_discriminator:  0.6729042530059814\n",
      "Epoch:  14     Batch:  229  /  468     Loss_generator:  0.7056318521499634     Loss_discriminator:  0.6821057796478271\n",
      "Epoch:  14     Batch:  230  /  468     Loss_generator:  0.7355591654777527     Loss_discriminator:  0.6870529651641846\n",
      "Epoch:  14     Batch:  231  /  468     Loss_generator:  0.7629546523094177     Loss_discriminator:  0.6860327124595642\n",
      "Epoch:  14     Batch:  232  /  468     Loss_generator:  0.7329332232475281     Loss_discriminator:  0.6826288104057312\n",
      "Epoch:  14     Batch:  233  /  468     Loss_generator:  0.6941241025924683     Loss_discriminator:  0.6877619028091431\n",
      "Epoch:  14     Batch:  234  /  468     Loss_generator:  0.6806282997131348     Loss_discriminator:  0.6835715174674988\n",
      "Epoch:  14     Batch:  235  /  468     Loss_generator:  0.6688251495361328     Loss_discriminator:  0.6851799488067627\n",
      "Epoch:  14     Batch:  236  /  468     Loss_generator:  0.7063370943069458     Loss_discriminator:  0.6926895380020142\n",
      "Epoch:  14     Batch:  237  /  468     Loss_generator:  0.7312982082366943     Loss_discriminator:  0.6918691396713257\n",
      "Epoch:  14     Batch:  238  /  468     Loss_generator:  0.7243205308914185     Loss_discriminator:  0.6770022511482239\n",
      "Epoch:  14     Batch:  239  /  468     Loss_generator:  0.6933150887489319     Loss_discriminator:  0.6882365345954895\n",
      "Epoch:  14     Batch:  240  /  468     Loss_generator:  0.6718325614929199     Loss_discriminator:  0.6907955408096313\n",
      "Epoch:  14     Batch:  241  /  468     Loss_generator:  0.6750786304473877     Loss_discriminator:  0.6794205904006958\n",
      "Epoch:  14     Batch:  242  /  468     Loss_generator:  0.7335458993911743     Loss_discriminator:  0.7052950859069824\n",
      "Epoch:  14     Batch:  243  /  468     Loss_generator:  0.7385771870613098     Loss_discriminator:  0.6776040196418762\n",
      "Epoch:  14     Batch:  244  /  468     Loss_generator:  0.7478660345077515     Loss_discriminator:  0.6819398403167725\n",
      "Epoch:  14     Batch:  245  /  468     Loss_generator:  0.7261738777160645     Loss_discriminator:  0.697301983833313\n",
      "Epoch:  14     Batch:  246  /  468     Loss_generator:  0.6989430785179138     Loss_discriminator:  0.6801261901855469\n",
      "Epoch:  14     Batch:  247  /  468     Loss_generator:  0.6454493403434753     Loss_discriminator:  0.6841895580291748\n",
      "Epoch:  14     Batch:  248  /  468     Loss_generator:  0.6518145799636841     Loss_discriminator:  0.6940352916717529\n",
      "Epoch:  14     Batch:  249  /  468     Loss_generator:  0.684507429599762     Loss_discriminator:  0.6846632957458496\n",
      "Epoch:  14     Batch:  250  /  468     Loss_generator:  0.7720236778259277     Loss_discriminator:  0.6922737956047058\n",
      "Epoch:  14     Batch:  251  /  468     Loss_generator:  0.7965390086174011     Loss_discriminator:  0.7004443407058716\n",
      "Epoch:  14     Batch:  252  /  468     Loss_generator:  0.7605360150337219     Loss_discriminator:  0.6802339553833008\n",
      "Epoch:  14     Batch:  253  /  468     Loss_generator:  0.708578884601593     Loss_discriminator:  0.6991248726844788\n",
      "Epoch:  14     Batch:  254  /  468     Loss_generator:  0.6974655389785767     Loss_discriminator:  0.6687024831771851\n",
      "Epoch:  14     Batch:  255  /  468     Loss_generator:  0.7182924151420593     Loss_discriminator:  0.6862117648124695\n",
      "Epoch:  14     Batch:  256  /  468     Loss_generator:  0.7214733362197876     Loss_discriminator:  0.672513484954834\n",
      "Epoch:  14     Batch:  257  /  468     Loss_generator:  0.6965053677558899     Loss_discriminator:  0.6908236742019653\n",
      "Epoch:  14     Batch:  258  /  468     Loss_generator:  0.6878076791763306     Loss_discriminator:  0.6966044902801514\n",
      "Epoch:  14     Batch:  259  /  468     Loss_generator:  0.6879047751426697     Loss_discriminator:  0.6902676224708557\n",
      "Epoch:  14     Batch:  260  /  468     Loss_generator:  0.685467004776001     Loss_discriminator:  0.6777101159095764\n",
      "Epoch:  14     Batch:  261  /  468     Loss_generator:  0.7275090217590332     Loss_discriminator:  0.6847871541976929\n",
      "Epoch:  14     Batch:  262  /  468     Loss_generator:  0.762114405632019     Loss_discriminator:  0.6831571459770203\n",
      "Epoch:  14     Batch:  263  /  468     Loss_generator:  0.711175799369812     Loss_discriminator:  0.6833062767982483\n",
      "Epoch:  14     Batch:  264  /  468     Loss_generator:  0.702485203742981     Loss_discriminator:  0.6906335949897766\n",
      "Epoch:  14     Batch:  265  /  468     Loss_generator:  0.6804127097129822     Loss_discriminator:  0.6862162947654724\n",
      "Epoch:  14     Batch:  266  /  468     Loss_generator:  0.719987154006958     Loss_discriminator:  0.6737381219863892\n",
      "Epoch:  14     Batch:  267  /  468     Loss_generator:  0.7748095989227295     Loss_discriminator:  0.6771076321601868\n",
      "Epoch:  14     Batch:  268  /  468     Loss_generator:  0.7674886584281921     Loss_discriminator:  0.6840941905975342\n",
      "Epoch:  14     Batch:  269  /  468     Loss_generator:  0.6922728419303894     Loss_discriminator:  0.6790527105331421\n",
      "Epoch:  14     Batch:  270  /  468     Loss_generator:  0.655695915222168     Loss_discriminator:  0.6916078329086304\n",
      "Epoch:  14     Batch:  271  /  468     Loss_generator:  0.6317242383956909     Loss_discriminator:  0.675844669342041\n",
      "Epoch:  14     Batch:  272  /  468     Loss_generator:  0.6732860803604126     Loss_discriminator:  0.6770951151847839\n",
      "Epoch:  14     Batch:  273  /  468     Loss_generator:  0.7729165554046631     Loss_discriminator:  0.6841707229614258\n",
      "Epoch:  14     Batch:  274  /  468     Loss_generator:  0.7976269125938416     Loss_discriminator:  0.6841646432876587\n",
      "Epoch:  14     Batch:  275  /  468     Loss_generator:  0.7346270680427551     Loss_discriminator:  0.6839920282363892\n",
      "Epoch:  14     Batch:  276  /  468     Loss_generator:  0.6550232172012329     Loss_discriminator:  0.6827200651168823\n",
      "Epoch:  14     Batch:  277  /  468     Loss_generator:  0.6379669904708862     Loss_discriminator:  0.6852355003356934\n",
      "Epoch:  14     Batch:  278  /  468     Loss_generator:  0.6732097864151001     Loss_discriminator:  0.696224570274353\n",
      "Epoch:  14     Batch:  279  /  468     Loss_generator:  0.7853939533233643     Loss_discriminator:  0.694912314414978\n",
      "Epoch:  14     Batch:  280  /  468     Loss_generator:  0.8186187744140625     Loss_discriminator:  0.6859378218650818\n",
      "Epoch:  14     Batch:  281  /  468     Loss_generator:  0.7474080324172974     Loss_discriminator:  0.6888699531555176\n",
      "Epoch:  14     Batch:  282  /  468     Loss_generator:  0.6947574615478516     Loss_discriminator:  0.6736650466918945\n",
      "Epoch:  14     Batch:  283  /  468     Loss_generator:  0.6504979133605957     Loss_discriminator:  0.6764844655990601\n",
      "Epoch:  14     Batch:  284  /  468     Loss_generator:  0.6755306720733643     Loss_discriminator:  0.6942926049232483\n",
      "Epoch:  14     Batch:  285  /  468     Loss_generator:  0.7397164106369019     Loss_discriminator:  0.6863563060760498\n",
      "Epoch:  14     Batch:  286  /  468     Loss_generator:  0.759701132774353     Loss_discriminator:  0.6770216822624207\n",
      "Epoch:  14     Batch:  287  /  468     Loss_generator:  0.7558852434158325     Loss_discriminator:  0.6847684383392334\n",
      "Epoch:  14     Batch:  288  /  468     Loss_generator:  0.7164836525917053     Loss_discriminator:  0.6795079708099365\n",
      "Epoch:  14     Batch:  289  /  468     Loss_generator:  0.6848181486129761     Loss_discriminator:  0.6784265041351318\n",
      "Epoch:  14     Batch:  290  /  468     Loss_generator:  0.6969764828681946     Loss_discriminator:  0.6760841608047485\n",
      "Epoch:  14     Batch:  291  /  468     Loss_generator:  0.7073314189910889     Loss_discriminator:  0.6924481391906738\n",
      "Epoch:  14     Batch:  292  /  468     Loss_generator:  0.7067002654075623     Loss_discriminator:  0.6790525913238525\n",
      "Epoch:  14     Batch:  293  /  468     Loss_generator:  0.6942223906517029     Loss_discriminator:  0.6863812208175659\n",
      "Epoch:  14     Batch:  294  /  468     Loss_generator:  0.6959711313247681     Loss_discriminator:  0.6931558847427368\n",
      "Epoch:  14     Batch:  295  /  468     Loss_generator:  0.7094681262969971     Loss_discriminator:  0.6885756254196167\n",
      "Epoch:  14     Batch:  296  /  468     Loss_generator:  0.6909787654876709     Loss_discriminator:  0.6883124113082886\n",
      "Epoch:  14     Batch:  297  /  468     Loss_generator:  0.7404568195343018     Loss_discriminator:  0.6854772567749023\n",
      "Epoch:  14     Batch:  298  /  468     Loss_generator:  0.7584362626075745     Loss_discriminator:  0.6905328035354614\n",
      "Epoch:  14     Batch:  299  /  468     Loss_generator:  0.7773517966270447     Loss_discriminator:  0.6709626913070679\n",
      "Epoch:  14     Batch:  300  /  468     Loss_generator:  0.7554579973220825     Loss_discriminator:  0.6928565502166748\n",
      "Epoch:  14     Batch:  301  /  468     Loss_generator:  0.6829195022583008     Loss_discriminator:  0.7073789834976196\n",
      "Epoch:  14     Batch:  302  /  468     Loss_generator:  0.6597194671630859     Loss_discriminator:  0.6932040452957153\n",
      "Epoch:  14     Batch:  303  /  468     Loss_generator:  0.6633431315422058     Loss_discriminator:  0.669536828994751\n",
      "Epoch:  14     Batch:  304  /  468     Loss_generator:  0.6945412158966064     Loss_discriminator:  0.685503363609314\n",
      "Epoch:  14     Batch:  305  /  468     Loss_generator:  0.726788341999054     Loss_discriminator:  0.6822307109832764\n",
      "Epoch:  14     Batch:  306  /  468     Loss_generator:  0.7494552731513977     Loss_discriminator:  0.6731579303741455\n",
      "Epoch:  14     Batch:  307  /  468     Loss_generator:  0.7127059698104858     Loss_discriminator:  0.6905713677406311\n",
      "Epoch:  14     Batch:  308  /  468     Loss_generator:  0.684978187084198     Loss_discriminator:  0.7001771926879883\n",
      "Epoch:  14     Batch:  309  /  468     Loss_generator:  0.6877478361129761     Loss_discriminator:  0.6918407678604126\n",
      "Epoch:  14     Batch:  310  /  468     Loss_generator:  0.7270650863647461     Loss_discriminator:  0.7013916969299316\n",
      "Epoch:  14     Batch:  311  /  468     Loss_generator:  0.790066123008728     Loss_discriminator:  0.6920328140258789\n",
      "Epoch:  14     Batch:  312  /  468     Loss_generator:  0.764120876789093     Loss_discriminator:  0.6903101205825806\n",
      "Epoch:  14     Batch:  313  /  468     Loss_generator:  0.7070971727371216     Loss_discriminator:  0.694879412651062\n",
      "Epoch:  14     Batch:  314  /  468     Loss_generator:  0.6648353338241577     Loss_discriminator:  0.6836669445037842\n",
      "Epoch:  14     Batch:  315  /  468     Loss_generator:  0.6739369034767151     Loss_discriminator:  0.6926409602165222\n",
      "Epoch:  14     Batch:  316  /  468     Loss_generator:  0.7084588408470154     Loss_discriminator:  0.6881106495857239\n",
      "Epoch:  14     Batch:  317  /  468     Loss_generator:  0.7310534119606018     Loss_discriminator:  0.6875876188278198\n",
      "Epoch:  14     Batch:  318  /  468     Loss_generator:  0.7271003723144531     Loss_discriminator:  0.6969075798988342\n",
      "Epoch:  14     Batch:  319  /  468     Loss_generator:  0.7066220641136169     Loss_discriminator:  0.6916414499282837\n",
      "Epoch:  14     Batch:  320  /  468     Loss_generator:  0.7093679904937744     Loss_discriminator:  0.6844592094421387\n",
      "Epoch:  14     Batch:  321  /  468     Loss_generator:  0.7207777500152588     Loss_discriminator:  0.6853883862495422\n",
      "Epoch:  14     Batch:  322  /  468     Loss_generator:  0.7023642659187317     Loss_discriminator:  0.6806076169013977\n",
      "Epoch:  14     Batch:  323  /  468     Loss_generator:  0.6963525414466858     Loss_discriminator:  0.6859050989151001\n",
      "Epoch:  14     Batch:  324  /  468     Loss_generator:  0.6986548900604248     Loss_discriminator:  0.6847272515296936\n",
      "Epoch:  14     Batch:  325  /  468     Loss_generator:  0.6951625347137451     Loss_discriminator:  0.6890504956245422\n",
      "Epoch:  14     Batch:  326  /  468     Loss_generator:  0.718511164188385     Loss_discriminator:  0.6885980367660522\n",
      "Epoch:  14     Batch:  327  /  468     Loss_generator:  0.7169575691223145     Loss_discriminator:  0.6909241676330566\n",
      "Epoch:  14     Batch:  328  /  468     Loss_generator:  0.7424228191375732     Loss_discriminator:  0.6667734384536743\n",
      "Epoch:  14     Batch:  329  /  468     Loss_generator:  0.7113354206085205     Loss_discriminator:  0.6934182643890381\n",
      "Epoch:  14     Batch:  330  /  468     Loss_generator:  0.7245434522628784     Loss_discriminator:  0.6799287796020508\n",
      "Epoch:  14     Batch:  331  /  468     Loss_generator:  0.7164491415023804     Loss_discriminator:  0.6840848326683044\n",
      "Epoch:  14     Batch:  332  /  468     Loss_generator:  0.6992828249931335     Loss_discriminator:  0.6928190588951111\n",
      "Epoch:  14     Batch:  333  /  468     Loss_generator:  0.6771308779716492     Loss_discriminator:  0.6922355890274048\n",
      "Epoch:  14     Batch:  334  /  468     Loss_generator:  0.6738861799240112     Loss_discriminator:  0.6881176233291626\n",
      "Epoch:  14     Batch:  335  /  468     Loss_generator:  0.7109886407852173     Loss_discriminator:  0.6903247237205505\n",
      "Epoch:  14     Batch:  336  /  468     Loss_generator:  0.7274988889694214     Loss_discriminator:  0.6924036145210266\n",
      "Epoch:  14     Batch:  337  /  468     Loss_generator:  0.7137815952301025     Loss_discriminator:  0.6727305054664612\n",
      "Epoch:  14     Batch:  338  /  468     Loss_generator:  0.7296847701072693     Loss_discriminator:  0.6958106756210327\n",
      "Epoch:  14     Batch:  339  /  468     Loss_generator:  0.7110850811004639     Loss_discriminator:  0.6775751113891602\n",
      "Epoch:  14     Batch:  340  /  468     Loss_generator:  0.7285666465759277     Loss_discriminator:  0.6850173473358154\n",
      "Epoch:  14     Batch:  341  /  468     Loss_generator:  0.7347923517227173     Loss_discriminator:  0.6986874341964722\n",
      "Epoch:  14     Batch:  342  /  468     Loss_generator:  0.7488098740577698     Loss_discriminator:  0.6960437297821045\n",
      "Epoch:  14     Batch:  343  /  468     Loss_generator:  0.7170910239219666     Loss_discriminator:  0.6821296215057373\n",
      "Epoch:  14     Batch:  344  /  468     Loss_generator:  0.6896913647651672     Loss_discriminator:  0.6959127187728882\n",
      "Epoch:  14     Batch:  345  /  468     Loss_generator:  0.6756069660186768     Loss_discriminator:  0.6902525424957275\n",
      "Epoch:  14     Batch:  346  /  468     Loss_generator:  0.6942687034606934     Loss_discriminator:  0.6702591776847839\n",
      "Epoch:  14     Batch:  347  /  468     Loss_generator:  0.6965786218643188     Loss_discriminator:  0.6850799322128296\n",
      "Epoch:  14     Batch:  348  /  468     Loss_generator:  0.7189429402351379     Loss_discriminator:  0.6915449500083923\n",
      "Epoch:  14     Batch:  349  /  468     Loss_generator:  0.732815146446228     Loss_discriminator:  0.6809568405151367\n",
      "Epoch:  14     Batch:  350  /  468     Loss_generator:  0.7109473943710327     Loss_discriminator:  0.6690921783447266\n",
      "Epoch:  14     Batch:  351  /  468     Loss_generator:  0.7042301893234253     Loss_discriminator:  0.6779195666313171\n",
      "Epoch:  14     Batch:  352  /  468     Loss_generator:  0.7165924310684204     Loss_discriminator:  0.6867297887802124\n",
      "Epoch:  14     Batch:  353  /  468     Loss_generator:  0.7091931104660034     Loss_discriminator:  0.6811630725860596\n",
      "Epoch:  14     Batch:  354  /  468     Loss_generator:  0.7067816257476807     Loss_discriminator:  0.6759223937988281\n",
      "Epoch:  14     Batch:  355  /  468     Loss_generator:  0.7191810607910156     Loss_discriminator:  0.6856330633163452\n",
      "Epoch:  14     Batch:  356  /  468     Loss_generator:  0.7186177968978882     Loss_discriminator:  0.6885175108909607\n",
      "Epoch:  14     Batch:  357  /  468     Loss_generator:  0.6895053386688232     Loss_discriminator:  0.6807876229286194\n",
      "Epoch:  14     Batch:  358  /  468     Loss_generator:  0.6977117657661438     Loss_discriminator:  0.6789594888687134\n",
      "Epoch:  14     Batch:  359  /  468     Loss_generator:  0.6890853047370911     Loss_discriminator:  0.685757040977478\n",
      "Epoch:  14     Batch:  360  /  468     Loss_generator:  0.7100892663002014     Loss_discriminator:  0.7012895345687866\n",
      "Epoch:  14     Batch:  361  /  468     Loss_generator:  0.7251067161560059     Loss_discriminator:  0.6759511232376099\n",
      "Epoch:  14     Batch:  362  /  468     Loss_generator:  0.7138246893882751     Loss_discriminator:  0.6807444095611572\n",
      "Epoch:  14     Batch:  363  /  468     Loss_generator:  0.6996832489967346     Loss_discriminator:  0.6899899244308472\n",
      "Epoch:  14     Batch:  364  /  468     Loss_generator:  0.6760035157203674     Loss_discriminator:  0.6806156635284424\n",
      "Epoch:  14     Batch:  365  /  468     Loss_generator:  0.6765069365501404     Loss_discriminator:  0.6893310546875\n",
      "Epoch:  14     Batch:  366  /  468     Loss_generator:  0.7141518592834473     Loss_discriminator:  0.7012088298797607\n",
      "Epoch:  14     Batch:  367  /  468     Loss_generator:  0.6983712911605835     Loss_discriminator:  0.6847313642501831\n",
      "Epoch:  14     Batch:  368  /  468     Loss_generator:  0.7259473204612732     Loss_discriminator:  0.6861189007759094\n",
      "Epoch:  14     Batch:  369  /  468     Loss_generator:  0.7252211570739746     Loss_discriminator:  0.6961559057235718\n",
      "Epoch:  14     Batch:  370  /  468     Loss_generator:  0.7562025785446167     Loss_discriminator:  0.696233332157135\n",
      "Epoch:  14     Batch:  371  /  468     Loss_generator:  0.7655341625213623     Loss_discriminator:  0.6837579011917114\n",
      "Epoch:  14     Batch:  372  /  468     Loss_generator:  0.7183315753936768     Loss_discriminator:  0.6897887587547302\n",
      "Epoch:  14     Batch:  373  /  468     Loss_generator:  0.7151480913162231     Loss_discriminator:  0.6937909126281738\n",
      "Epoch:  14     Batch:  374  /  468     Loss_generator:  0.6760087013244629     Loss_discriminator:  0.6846995949745178\n",
      "Epoch:  14     Batch:  375  /  468     Loss_generator:  0.6966633796691895     Loss_discriminator:  0.7078335285186768\n",
      "Epoch:  14     Batch:  376  /  468     Loss_generator:  0.6981712579727173     Loss_discriminator:  0.6883978843688965\n",
      "Epoch:  14     Batch:  377  /  468     Loss_generator:  0.6965746879577637     Loss_discriminator:  0.6936786770820618\n",
      "Epoch:  14     Batch:  378  /  468     Loss_generator:  0.7079399228096008     Loss_discriminator:  0.667521595954895\n",
      "Epoch:  14     Batch:  379  /  468     Loss_generator:  0.6925177574157715     Loss_discriminator:  0.6841593384742737\n",
      "Epoch:  14     Batch:  380  /  468     Loss_generator:  0.7135255932807922     Loss_discriminator:  0.706214189529419\n",
      "Epoch:  14     Batch:  381  /  468     Loss_generator:  0.7341442108154297     Loss_discriminator:  0.6862947344779968\n",
      "Epoch:  14     Batch:  382  /  468     Loss_generator:  0.7547158598899841     Loss_discriminator:  0.6874961256980896\n",
      "Epoch:  14     Batch:  383  /  468     Loss_generator:  0.744199275970459     Loss_discriminator:  0.677845299243927\n",
      "Epoch:  14     Batch:  384  /  468     Loss_generator:  0.7282341122627258     Loss_discriminator:  0.6923109292984009\n",
      "Epoch:  14     Batch:  385  /  468     Loss_generator:  0.6835582256317139     Loss_discriminator:  0.6978241801261902\n",
      "Epoch:  14     Batch:  386  /  468     Loss_generator:  0.6605217456817627     Loss_discriminator:  0.6802577376365662\n",
      "Epoch:  14     Batch:  387  /  468     Loss_generator:  0.6535680890083313     Loss_discriminator:  0.6830852031707764\n",
      "Epoch:  14     Batch:  388  /  468     Loss_generator:  0.7111952900886536     Loss_discriminator:  0.6952323317527771\n",
      "Epoch:  14     Batch:  389  /  468     Loss_generator:  0.757835328578949     Loss_discriminator:  0.6876756548881531\n",
      "Epoch:  14     Batch:  390  /  468     Loss_generator:  0.7498835325241089     Loss_discriminator:  0.6765431761741638\n",
      "Epoch:  14     Batch:  391  /  468     Loss_generator:  0.7106120586395264     Loss_discriminator:  0.678520679473877\n",
      "Epoch:  14     Batch:  392  /  468     Loss_generator:  0.6914311051368713     Loss_discriminator:  0.6866441965103149\n",
      "Epoch:  14     Batch:  393  /  468     Loss_generator:  0.6610785126686096     Loss_discriminator:  0.6871716976165771\n",
      "Epoch:  14     Batch:  394  /  468     Loss_generator:  0.6496239900588989     Loss_discriminator:  0.6886188983917236\n",
      "Epoch:  14     Batch:  395  /  468     Loss_generator:  0.6726065874099731     Loss_discriminator:  0.699209988117218\n",
      "Epoch:  14     Batch:  396  /  468     Loss_generator:  0.7147760987281799     Loss_discriminator:  0.689437747001648\n",
      "Epoch:  14     Batch:  397  /  468     Loss_generator:  0.7741875052452087     Loss_discriminator:  0.705460786819458\n",
      "Epoch:  14     Batch:  398  /  468     Loss_generator:  0.8108296394348145     Loss_discriminator:  0.6810425519943237\n",
      "Epoch:  14     Batch:  399  /  468     Loss_generator:  0.7869926691055298     Loss_discriminator:  0.6915995478630066\n",
      "Epoch:  14     Batch:  400  /  468     Loss_generator:  0.7179610729217529     Loss_discriminator:  0.6910781860351562\n",
      "Epoch:  14     Batch:  401  /  468     Loss_generator:  0.6649660468101501     Loss_discriminator:  0.6761475205421448\n",
      "Epoch:  14     Batch:  402  /  468     Loss_generator:  0.6355533599853516     Loss_discriminator:  0.6947672963142395\n",
      "Epoch:  14     Batch:  403  /  468     Loss_generator:  0.6660990715026855     Loss_discriminator:  0.6812840700149536\n",
      "Epoch:  14     Batch:  404  /  468     Loss_generator:  0.6829652786254883     Loss_discriminator:  0.6858433485031128\n",
      "Epoch:  14     Batch:  405  /  468     Loss_generator:  0.7337965965270996     Loss_discriminator:  0.6771466732025146\n",
      "Epoch:  14     Batch:  406  /  468     Loss_generator:  0.7429262399673462     Loss_discriminator:  0.685295045375824\n",
      "Epoch:  14     Batch:  407  /  468     Loss_generator:  0.7224598526954651     Loss_discriminator:  0.6854987144470215\n",
      "Epoch:  14     Batch:  408  /  468     Loss_generator:  0.6802821159362793     Loss_discriminator:  0.6876839399337769\n",
      "Epoch:  14     Batch:  409  /  468     Loss_generator:  0.682441234588623     Loss_discriminator:  0.6904779672622681\n",
      "Epoch:  14     Batch:  410  /  468     Loss_generator:  0.7207373976707458     Loss_discriminator:  0.6930319666862488\n",
      "Epoch:  14     Batch:  411  /  468     Loss_generator:  0.7352998852729797     Loss_discriminator:  0.6902814507484436\n",
      "Epoch:  14     Batch:  412  /  468     Loss_generator:  0.7206172347068787     Loss_discriminator:  0.6924648284912109\n",
      "Epoch:  14     Batch:  413  /  468     Loss_generator:  0.7006258964538574     Loss_discriminator:  0.6779528856277466\n",
      "Epoch:  14     Batch:  414  /  468     Loss_generator:  0.7242997884750366     Loss_discriminator:  0.6815400123596191\n",
      "Epoch:  14     Batch:  415  /  468     Loss_generator:  0.7481275796890259     Loss_discriminator:  0.6833851337432861\n",
      "Epoch:  14     Batch:  416  /  468     Loss_generator:  0.7485998272895813     Loss_discriminator:  0.6795109510421753\n",
      "Epoch:  14     Batch:  417  /  468     Loss_generator:  0.7175126075744629     Loss_discriminator:  0.6805922389030457\n",
      "Epoch:  14     Batch:  418  /  468     Loss_generator:  0.6776182651519775     Loss_discriminator:  0.701540470123291\n",
      "Epoch:  14     Batch:  419  /  468     Loss_generator:  0.6598379611968994     Loss_discriminator:  0.6774056553840637\n",
      "Epoch:  14     Batch:  420  /  468     Loss_generator:  0.667467474937439     Loss_discriminator:  0.6934829950332642\n",
      "Epoch:  14     Batch:  421  /  468     Loss_generator:  0.6996636390686035     Loss_discriminator:  0.6939999461174011\n",
      "Epoch:  14     Batch:  422  /  468     Loss_generator:  0.7672828435897827     Loss_discriminator:  0.6844578981399536\n",
      "Epoch:  14     Batch:  423  /  468     Loss_generator:  0.7534117698669434     Loss_discriminator:  0.6847227811813354\n",
      "Epoch:  14     Batch:  424  /  468     Loss_generator:  0.7307676672935486     Loss_discriminator:  0.6953158378601074\n",
      "Epoch:  14     Batch:  425  /  468     Loss_generator:  0.6910430788993835     Loss_discriminator:  0.687358021736145\n",
      "Epoch:  14     Batch:  426  /  468     Loss_generator:  0.6603854894638062     Loss_discriminator:  0.6923419237136841\n",
      "Epoch:  14     Batch:  427  /  468     Loss_generator:  0.7110010385513306     Loss_discriminator:  0.6863574385643005\n",
      "Epoch:  14     Batch:  428  /  468     Loss_generator:  0.7593064308166504     Loss_discriminator:  0.6783322691917419\n",
      "Epoch:  14     Batch:  429  /  468     Loss_generator:  0.7578099370002747     Loss_discriminator:  0.6940915584564209\n",
      "Epoch:  14     Batch:  430  /  468     Loss_generator:  0.7202771902084351     Loss_discriminator:  0.6745706796646118\n",
      "Epoch:  14     Batch:  431  /  468     Loss_generator:  0.6954284310340881     Loss_discriminator:  0.6815961599349976\n",
      "Epoch:  14     Batch:  432  /  468     Loss_generator:  0.6612986922264099     Loss_discriminator:  0.6906583905220032\n",
      "Epoch:  14     Batch:  433  /  468     Loss_generator:  0.6718893051147461     Loss_discriminator:  0.6906155347824097\n",
      "Epoch:  14     Batch:  434  /  468     Loss_generator:  0.7137372493743896     Loss_discriminator:  0.6901972889900208\n",
      "Epoch:  14     Batch:  435  /  468     Loss_generator:  0.7295067310333252     Loss_discriminator:  0.6910555958747864\n",
      "Epoch:  14     Batch:  436  /  468     Loss_generator:  0.728986382484436     Loss_discriminator:  0.6896690130233765\n",
      "Epoch:  14     Batch:  437  /  468     Loss_generator:  0.7015862464904785     Loss_discriminator:  0.7013144493103027\n",
      "Epoch:  14     Batch:  438  /  468     Loss_generator:  0.7221453189849854     Loss_discriminator:  0.6836864948272705\n",
      "Epoch:  14     Batch:  439  /  468     Loss_generator:  0.7124491930007935     Loss_discriminator:  0.6934755444526672\n",
      "Epoch:  14     Batch:  440  /  468     Loss_generator:  0.6818011403083801     Loss_discriminator:  0.6770381927490234\n",
      "Epoch:  14     Batch:  441  /  468     Loss_generator:  0.7263118028640747     Loss_discriminator:  0.681770920753479\n",
      "Epoch:  14     Batch:  442  /  468     Loss_generator:  0.7572683095932007     Loss_discriminator:  0.674826979637146\n",
      "Epoch:  14     Batch:  443  /  468     Loss_generator:  0.7427911162376404     Loss_discriminator:  0.6890082955360413\n",
      "Epoch:  14     Batch:  444  /  468     Loss_generator:  0.7020349502563477     Loss_discriminator:  0.6881144046783447\n",
      "Epoch:  14     Batch:  445  /  468     Loss_generator:  0.7025758028030396     Loss_discriminator:  0.6993692517280579\n",
      "Epoch:  14     Batch:  446  /  468     Loss_generator:  0.740498423576355     Loss_discriminator:  0.6946821212768555\n",
      "Epoch:  14     Batch:  447  /  468     Loss_generator:  0.7296772003173828     Loss_discriminator:  0.689217746257782\n",
      "Epoch:  14     Batch:  448  /  468     Loss_generator:  0.720823347568512     Loss_discriminator:  0.6834663152694702\n",
      "Epoch:  14     Batch:  449  /  468     Loss_generator:  0.6799347996711731     Loss_discriminator:  0.6928699016571045\n",
      "Epoch:  14     Batch:  450  /  468     Loss_generator:  0.66994309425354     Loss_discriminator:  0.6785743236541748\n",
      "Epoch:  14     Batch:  451  /  468     Loss_generator:  0.6785434484481812     Loss_discriminator:  0.6786460876464844\n",
      "Epoch:  14     Batch:  452  /  468     Loss_generator:  0.7194919586181641     Loss_discriminator:  0.6780978441238403\n",
      "Epoch:  14     Batch:  453  /  468     Loss_generator:  0.7501891851425171     Loss_discriminator:  0.685673713684082\n",
      "Epoch:  14     Batch:  454  /  468     Loss_generator:  0.7200700044631958     Loss_discriminator:  0.6907698512077332\n",
      "Epoch:  14     Batch:  455  /  468     Loss_generator:  0.7202891111373901     Loss_discriminator:  0.7000452280044556\n",
      "Epoch:  14     Batch:  456  /  468     Loss_generator:  0.712263822555542     Loss_discriminator:  0.6911135315895081\n",
      "Epoch:  14     Batch:  457  /  468     Loss_generator:  0.7055151462554932     Loss_discriminator:  0.6828572750091553\n",
      "Epoch:  14     Batch:  458  /  468     Loss_generator:  0.7248373031616211     Loss_discriminator:  0.6916011571884155\n",
      "Epoch:  14     Batch:  459  /  468     Loss_generator:  0.7307459115982056     Loss_discriminator:  0.684256374835968\n",
      "Epoch:  14     Batch:  460  /  468     Loss_generator:  0.7082579135894775     Loss_discriminator:  0.684368371963501\n",
      "Epoch:  14     Batch:  461  /  468     Loss_generator:  0.687362551689148     Loss_discriminator:  0.6960137486457825\n",
      "Epoch:  14     Batch:  462  /  468     Loss_generator:  0.668337345123291     Loss_discriminator:  0.6888642311096191\n",
      "Epoch:  14     Batch:  463  /  468     Loss_generator:  0.6755442023277283     Loss_discriminator:  0.6863803863525391\n",
      "Epoch:  14     Batch:  464  /  468     Loss_generator:  0.6859735250473022     Loss_discriminator:  0.6775065064430237\n",
      "Epoch:  14     Batch:  465  /  468     Loss_generator:  0.7371687293052673     Loss_discriminator:  0.6910948753356934\n",
      "Epoch:  14     Batch:  466  /  468     Loss_generator:  0.7318623661994934     Loss_discriminator:  0.6870332956314087\n",
      "Epoch:  14     Batch:  467  /  468     Loss_generator:  0.7312899827957153     Loss_discriminator:  0.6858752369880676\n",
      "Epoch:  15     Batch:  0  /  468     Loss_generator:  0.7187075614929199     Loss_discriminator:  0.6850767135620117\n",
      "Epoch:  15     Batch:  1  /  468     Loss_generator:  0.7319809198379517     Loss_discriminator:  0.6858083009719849\n",
      "Epoch:  15     Batch:  2  /  468     Loss_generator:  0.7390917539596558     Loss_discriminator:  0.6883535385131836\n",
      "Epoch:  15     Batch:  3  /  468     Loss_generator:  0.7299906015396118     Loss_discriminator:  0.6924638152122498\n",
      "Epoch:  15     Batch:  4  /  468     Loss_generator:  0.712804913520813     Loss_discriminator:  0.6816507577896118\n",
      "Epoch:  15     Batch:  5  /  468     Loss_generator:  0.6727358102798462     Loss_discriminator:  0.6893801689147949\n",
      "Epoch:  15     Batch:  6  /  468     Loss_generator:  0.6704570055007935     Loss_discriminator:  0.6756596565246582\n",
      "Epoch:  15     Batch:  7  /  468     Loss_generator:  0.656808078289032     Loss_discriminator:  0.6858280301094055\n",
      "Epoch:  15     Batch:  8  /  468     Loss_generator:  0.660753071308136     Loss_discriminator:  0.6850882172584534\n",
      "Epoch:  15     Batch:  9  /  468     Loss_generator:  0.6953058242797852     Loss_discriminator:  0.6803854703903198\n",
      "Epoch:  15     Batch:  10  /  468     Loss_generator:  0.7409619688987732     Loss_discriminator:  0.6940576434135437\n",
      "Epoch:  15     Batch:  11  /  468     Loss_generator:  0.7677832841873169     Loss_discriminator:  0.6796312928199768\n",
      "Epoch:  15     Batch:  12  /  468     Loss_generator:  0.7164795994758606     Loss_discriminator:  0.6935232281684875\n",
      "Epoch:  15     Batch:  13  /  468     Loss_generator:  0.7206756472587585     Loss_discriminator:  0.6609762907028198\n",
      "Epoch:  15     Batch:  14  /  468     Loss_generator:  0.7328778505325317     Loss_discriminator:  0.6849696040153503\n",
      "Epoch:  15     Batch:  15  /  468     Loss_generator:  0.734677791595459     Loss_discriminator:  0.6777359843254089\n",
      "Epoch:  15     Batch:  16  /  468     Loss_generator:  0.7248858213424683     Loss_discriminator:  0.6863095760345459\n",
      "Epoch:  15     Batch:  17  /  468     Loss_generator:  0.6870179772377014     Loss_discriminator:  0.6934980750083923\n",
      "Epoch:  15     Batch:  18  /  468     Loss_generator:  0.6561892628669739     Loss_discriminator:  0.6881210207939148\n",
      "Epoch:  15     Batch:  19  /  468     Loss_generator:  0.6534016132354736     Loss_discriminator:  0.6879127621650696\n",
      "Epoch:  15     Batch:  20  /  468     Loss_generator:  0.7066155076026917     Loss_discriminator:  0.6910156011581421\n",
      "Epoch:  15     Batch:  21  /  468     Loss_generator:  0.7716697454452515     Loss_discriminator:  0.6829047799110413\n",
      "Epoch:  15     Batch:  22  /  468     Loss_generator:  0.780075192451477     Loss_discriminator:  0.6861991286277771\n",
      "Epoch:  15     Batch:  23  /  468     Loss_generator:  0.7451276779174805     Loss_discriminator:  0.6806894540786743\n",
      "Epoch:  15     Batch:  24  /  468     Loss_generator:  0.7108465433120728     Loss_discriminator:  0.6785630583763123\n",
      "Epoch:  15     Batch:  25  /  468     Loss_generator:  0.6722893714904785     Loss_discriminator:  0.6846911907196045\n",
      "Epoch:  15     Batch:  26  /  468     Loss_generator:  0.6686316728591919     Loss_discriminator:  0.6830928325653076\n",
      "Epoch:  15     Batch:  27  /  468     Loss_generator:  0.6867743730545044     Loss_discriminator:  0.6916725635528564\n",
      "Epoch:  15     Batch:  28  /  468     Loss_generator:  0.7278779149055481     Loss_discriminator:  0.675127387046814\n",
      "Epoch:  15     Batch:  29  /  468     Loss_generator:  0.7145631313323975     Loss_discriminator:  0.6838112473487854\n",
      "Epoch:  15     Batch:  30  /  468     Loss_generator:  0.6854494214057922     Loss_discriminator:  0.6832862496376038\n",
      "Epoch:  15     Batch:  31  /  468     Loss_generator:  0.7045691013336182     Loss_discriminator:  0.685513973236084\n",
      "Epoch:  15     Batch:  32  /  468     Loss_generator:  0.7134695649147034     Loss_discriminator:  0.6750800609588623\n",
      "Epoch:  15     Batch:  33  /  468     Loss_generator:  0.7389633655548096     Loss_discriminator:  0.6852179765701294\n",
      "Epoch:  15     Batch:  34  /  468     Loss_generator:  0.740138053894043     Loss_discriminator:  0.6899645328521729\n",
      "Epoch:  15     Batch:  35  /  468     Loss_generator:  0.7266950011253357     Loss_discriminator:  0.6819372773170471\n",
      "Epoch:  15     Batch:  36  /  468     Loss_generator:  0.7067153453826904     Loss_discriminator:  0.6875157356262207\n",
      "Epoch:  15     Batch:  37  /  468     Loss_generator:  0.7070341110229492     Loss_discriminator:  0.6768326759338379\n",
      "Epoch:  15     Batch:  38  /  468     Loss_generator:  0.7203686237335205     Loss_discriminator:  0.6871784925460815\n",
      "Epoch:  15     Batch:  39  /  468     Loss_generator:  0.7133151292800903     Loss_discriminator:  0.6796833276748657\n",
      "Epoch:  15     Batch:  40  /  468     Loss_generator:  0.6950476169586182     Loss_discriminator:  0.6883736848831177\n",
      "Epoch:  15     Batch:  41  /  468     Loss_generator:  0.6628821492195129     Loss_discriminator:  0.6836982369422913\n",
      "Epoch:  15     Batch:  42  /  468     Loss_generator:  0.6885143518447876     Loss_discriminator:  0.6891353726387024\n",
      "Epoch:  15     Batch:  43  /  468     Loss_generator:  0.7256171703338623     Loss_discriminator:  0.678162693977356\n",
      "Epoch:  15     Batch:  44  /  468     Loss_generator:  0.7716004848480225     Loss_discriminator:  0.6807177066802979\n",
      "Epoch:  15     Batch:  45  /  468     Loss_generator:  0.7318169474601746     Loss_discriminator:  0.6686450242996216\n",
      "Epoch:  15     Batch:  46  /  468     Loss_generator:  0.6886847019195557     Loss_discriminator:  0.6905468106269836\n",
      "Epoch:  15     Batch:  47  /  468     Loss_generator:  0.680402398109436     Loss_discriminator:  0.674676239490509\n",
      "Epoch:  15     Batch:  48  /  468     Loss_generator:  0.6715807914733887     Loss_discriminator:  0.6765929460525513\n",
      "Epoch:  15     Batch:  49  /  468     Loss_generator:  0.7018591165542603     Loss_discriminator:  0.6915479898452759\n",
      "Epoch:  15     Batch:  50  /  468     Loss_generator:  0.7129940986633301     Loss_discriminator:  0.693161129951477\n",
      "Epoch:  15     Batch:  51  /  468     Loss_generator:  0.7126951217651367     Loss_discriminator:  0.674334704875946\n",
      "Epoch:  15     Batch:  52  /  468     Loss_generator:  0.7350690364837646     Loss_discriminator:  0.690129280090332\n",
      "Epoch:  15     Batch:  53  /  468     Loss_generator:  0.7477402687072754     Loss_discriminator:  0.6728403568267822\n",
      "Epoch:  15     Batch:  54  /  468     Loss_generator:  0.7254557013511658     Loss_discriminator:  0.6992475390434265\n",
      "Epoch:  15     Batch:  55  /  468     Loss_generator:  0.6774625182151794     Loss_discriminator:  0.6857346296310425\n",
      "Epoch:  15     Batch:  56  /  468     Loss_generator:  0.6636411547660828     Loss_discriminator:  0.683449387550354\n",
      "Epoch:  15     Batch:  57  /  468     Loss_generator:  0.6610094308853149     Loss_discriminator:  0.6950638294219971\n",
      "Epoch:  15     Batch:  58  /  468     Loss_generator:  0.7354459762573242     Loss_discriminator:  0.6878067255020142\n",
      "Epoch:  15     Batch:  59  /  468     Loss_generator:  0.7378211617469788     Loss_discriminator:  0.679202675819397\n",
      "Epoch:  15     Batch:  60  /  468     Loss_generator:  0.7532044053077698     Loss_discriminator:  0.6928961873054504\n",
      "Epoch:  15     Batch:  61  /  468     Loss_generator:  0.7235753536224365     Loss_discriminator:  0.6957575082778931\n",
      "Epoch:  15     Batch:  62  /  468     Loss_generator:  0.6663368344306946     Loss_discriminator:  0.6756146550178528\n",
      "Epoch:  15     Batch:  63  /  468     Loss_generator:  0.6583048105239868     Loss_discriminator:  0.6714819073677063\n",
      "Epoch:  15     Batch:  64  /  468     Loss_generator:  0.6452595591545105     Loss_discriminator:  0.6704986095428467\n",
      "Epoch:  15     Batch:  65  /  468     Loss_generator:  0.6992700099945068     Loss_discriminator:  0.6869934797286987\n",
      "Epoch:  15     Batch:  66  /  468     Loss_generator:  0.768409013748169     Loss_discriminator:  0.6885591149330139\n",
      "Epoch:  15     Batch:  67  /  468     Loss_generator:  0.8409414887428284     Loss_discriminator:  0.6832576990127563\n",
      "Epoch:  15     Batch:  68  /  468     Loss_generator:  0.7950569987297058     Loss_discriminator:  0.6799010634422302\n",
      "Epoch:  15     Batch:  69  /  468     Loss_generator:  0.7217693328857422     Loss_discriminator:  0.6807941794395447\n",
      "Epoch:  15     Batch:  70  /  468     Loss_generator:  0.6684613227844238     Loss_discriminator:  0.6697381734848022\n",
      "Epoch:  15     Batch:  71  /  468     Loss_generator:  0.6697427034378052     Loss_discriminator:  0.6825268864631653\n",
      "Epoch:  15     Batch:  72  /  468     Loss_generator:  0.6643471717834473     Loss_discriminator:  0.6766340732574463\n",
      "Epoch:  15     Batch:  73  /  468     Loss_generator:  0.7083061933517456     Loss_discriminator:  0.6839701533317566\n",
      "Epoch:  15     Batch:  74  /  468     Loss_generator:  0.7412628531455994     Loss_discriminator:  0.6940409541130066\n",
      "Epoch:  15     Batch:  75  /  468     Loss_generator:  0.7698007822036743     Loss_discriminator:  0.6781518459320068\n",
      "Epoch:  15     Batch:  76  /  468     Loss_generator:  0.7120526432991028     Loss_discriminator:  0.681075930595398\n",
      "Epoch:  15     Batch:  77  /  468     Loss_generator:  0.697312593460083     Loss_discriminator:  0.6808721423149109\n",
      "Epoch:  15     Batch:  78  /  468     Loss_generator:  0.6969367265701294     Loss_discriminator:  0.6911559104919434\n",
      "Epoch:  15     Batch:  79  /  468     Loss_generator:  0.7188218235969543     Loss_discriminator:  0.6867828369140625\n",
      "Epoch:  15     Batch:  80  /  468     Loss_generator:  0.7433194518089294     Loss_discriminator:  0.6861441731452942\n",
      "Epoch:  15     Batch:  81  /  468     Loss_generator:  0.7148126363754272     Loss_discriminator:  0.6887595653533936\n",
      "Epoch:  15     Batch:  82  /  468     Loss_generator:  0.7082960605621338     Loss_discriminator:  0.6968021392822266\n",
      "Epoch:  15     Batch:  83  /  468     Loss_generator:  0.6829695701599121     Loss_discriminator:  0.6884928345680237\n",
      "Epoch:  15     Batch:  84  /  468     Loss_generator:  0.6898778676986694     Loss_discriminator:  0.685160219669342\n",
      "Epoch:  15     Batch:  85  /  468     Loss_generator:  0.6980120539665222     Loss_discriminator:  0.6889386177062988\n",
      "Epoch:  15     Batch:  86  /  468     Loss_generator:  0.7370322942733765     Loss_discriminator:  0.6813474297523499\n",
      "Epoch:  15     Batch:  87  /  468     Loss_generator:  0.7765641212463379     Loss_discriminator:  0.684441089630127\n",
      "Epoch:  15     Batch:  88  /  468     Loss_generator:  0.7771462798118591     Loss_discriminator:  0.6874129176139832\n",
      "Epoch:  15     Batch:  89  /  468     Loss_generator:  0.7232615947723389     Loss_discriminator:  0.680350124835968\n",
      "Epoch:  15     Batch:  90  /  468     Loss_generator:  0.6794590950012207     Loss_discriminator:  0.6831527948379517\n",
      "Epoch:  15     Batch:  91  /  468     Loss_generator:  0.6512319445610046     Loss_discriminator:  0.6893030405044556\n",
      "Epoch:  15     Batch:  92  /  468     Loss_generator:  0.692469596862793     Loss_discriminator:  0.6866630911827087\n",
      "Epoch:  15     Batch:  93  /  468     Loss_generator:  0.7129850387573242     Loss_discriminator:  0.6919315457344055\n",
      "Epoch:  15     Batch:  94  /  468     Loss_generator:  0.7552986145019531     Loss_discriminator:  0.6872044801712036\n",
      "Epoch:  15     Batch:  95  /  468     Loss_generator:  0.7330008745193481     Loss_discriminator:  0.7024683952331543\n",
      "Epoch:  15     Batch:  96  /  468     Loss_generator:  0.6901397705078125     Loss_discriminator:  0.6873090863227844\n",
      "Epoch:  15     Batch:  97  /  468     Loss_generator:  0.6692638397216797     Loss_discriminator:  0.6897075772285461\n",
      "Epoch:  15     Batch:  98  /  468     Loss_generator:  0.6960547566413879     Loss_discriminator:  0.6944593191146851\n",
      "Epoch:  15     Batch:  99  /  468     Loss_generator:  0.720633864402771     Loss_discriminator:  0.6881322860717773\n",
      "Epoch:  15     Batch:  100  /  468     Loss_generator:  0.7394096851348877     Loss_discriminator:  0.6799606084823608\n",
      "Epoch:  15     Batch:  101  /  468     Loss_generator:  0.7411705255508423     Loss_discriminator:  0.688310980796814\n",
      "Epoch:  15     Batch:  102  /  468     Loss_generator:  0.7147910594940186     Loss_discriminator:  0.6887813210487366\n",
      "Epoch:  15     Batch:  103  /  468     Loss_generator:  0.7041460275650024     Loss_discriminator:  0.6646848917007446\n",
      "Epoch:  15     Batch:  104  /  468     Loss_generator:  0.6829493045806885     Loss_discriminator:  0.6994386911392212\n",
      "Epoch:  15     Batch:  105  /  468     Loss_generator:  0.6944987773895264     Loss_discriminator:  0.6950017213821411\n",
      "Epoch:  15     Batch:  106  /  468     Loss_generator:  0.7339563965797424     Loss_discriminator:  0.6860107183456421\n",
      "Epoch:  15     Batch:  107  /  468     Loss_generator:  0.7477091550827026     Loss_discriminator:  0.6813883781433105\n",
      "Epoch:  15     Batch:  108  /  468     Loss_generator:  0.7102751731872559     Loss_discriminator:  0.6817643642425537\n",
      "Epoch:  15     Batch:  109  /  468     Loss_generator:  0.6604954600334167     Loss_discriminator:  0.6873892545700073\n",
      "Epoch:  15     Batch:  110  /  468     Loss_generator:  0.6519504189491272     Loss_discriminator:  0.6795722246170044\n",
      "Epoch:  15     Batch:  111  /  468     Loss_generator:  0.6939764618873596     Loss_discriminator:  0.700690746307373\n",
      "Epoch:  15     Batch:  112  /  468     Loss_generator:  0.7421932220458984     Loss_discriminator:  0.6793345808982849\n",
      "Epoch:  15     Batch:  113  /  468     Loss_generator:  0.7745659947395325     Loss_discriminator:  0.6772216558456421\n",
      "Epoch:  15     Batch:  114  /  468     Loss_generator:  0.7604978084564209     Loss_discriminator:  0.6911078691482544\n",
      "Epoch:  15     Batch:  115  /  468     Loss_generator:  0.7248802185058594     Loss_discriminator:  0.6921803951263428\n",
      "Epoch:  15     Batch:  116  /  468     Loss_generator:  0.6682440042495728     Loss_discriminator:  0.6873438358306885\n",
      "Epoch:  15     Batch:  117  /  468     Loss_generator:  0.6514559388160706     Loss_discriminator:  0.6691498756408691\n",
      "Epoch:  15     Batch:  118  /  468     Loss_generator:  0.6761074066162109     Loss_discriminator:  0.6857191920280457\n",
      "Epoch:  15     Batch:  119  /  468     Loss_generator:  0.7429953813552856     Loss_discriminator:  0.6916223168373108\n",
      "Epoch:  15     Batch:  120  /  468     Loss_generator:  0.7938735485076904     Loss_discriminator:  0.6965593099594116\n",
      "Epoch:  15     Batch:  121  /  468     Loss_generator:  0.7728776931762695     Loss_discriminator:  0.6740004420280457\n",
      "Epoch:  15     Batch:  122  /  468     Loss_generator:  0.690841019153595     Loss_discriminator:  0.699885368347168\n",
      "Epoch:  15     Batch:  123  /  468     Loss_generator:  0.6663118004798889     Loss_discriminator:  0.6864901781082153\n",
      "Epoch:  15     Batch:  124  /  468     Loss_generator:  0.6592849493026733     Loss_discriminator:  0.6803248524665833\n",
      "Epoch:  15     Batch:  125  /  468     Loss_generator:  0.697172999382019     Loss_discriminator:  0.6809546947479248\n",
      "Epoch:  15     Batch:  126  /  468     Loss_generator:  0.7378003597259521     Loss_discriminator:  0.6855636835098267\n",
      "Epoch:  15     Batch:  127  /  468     Loss_generator:  0.7770814299583435     Loss_discriminator:  0.6829169988632202\n",
      "Epoch:  15     Batch:  128  /  468     Loss_generator:  0.7227069735527039     Loss_discriminator:  0.6807501316070557\n",
      "Epoch:  15     Batch:  129  /  468     Loss_generator:  0.7298828363418579     Loss_discriminator:  0.6788685917854309\n",
      "Epoch:  15     Batch:  130  /  468     Loss_generator:  0.6928104162216187     Loss_discriminator:  0.6671285629272461\n",
      "Epoch:  15     Batch:  131  /  468     Loss_generator:  0.6778352856636047     Loss_discriminator:  0.6815891265869141\n",
      "Epoch:  15     Batch:  132  /  468     Loss_generator:  0.6664440035820007     Loss_discriminator:  0.6915634870529175\n",
      "Epoch:  15     Batch:  133  /  468     Loss_generator:  0.6811539530754089     Loss_discriminator:  0.6797915697097778\n",
      "Epoch:  15     Batch:  134  /  468     Loss_generator:  0.7280769348144531     Loss_discriminator:  0.6811577081680298\n",
      "Epoch:  15     Batch:  135  /  468     Loss_generator:  0.7642034292221069     Loss_discriminator:  0.6788219213485718\n",
      "Epoch:  15     Batch:  136  /  468     Loss_generator:  0.7183383703231812     Loss_discriminator:  0.6740909814834595\n",
      "Epoch:  15     Batch:  137  /  468     Loss_generator:  0.7126524448394775     Loss_discriminator:  0.6829339265823364\n",
      "Epoch:  15     Batch:  138  /  468     Loss_generator:  0.7271735668182373     Loss_discriminator:  0.6960352063179016\n",
      "Epoch:  15     Batch:  139  /  468     Loss_generator:  0.7304791808128357     Loss_discriminator:  0.6848741769790649\n",
      "Epoch:  15     Batch:  140  /  468     Loss_generator:  0.7276048064231873     Loss_discriminator:  0.6807388663291931\n",
      "Epoch:  15     Batch:  141  /  468     Loss_generator:  0.7283391952514648     Loss_discriminator:  0.6717981696128845\n",
      "Epoch:  15     Batch:  142  /  468     Loss_generator:  0.7323256731033325     Loss_discriminator:  0.6785733699798584\n",
      "Epoch:  15     Batch:  143  /  468     Loss_generator:  0.6869542598724365     Loss_discriminator:  0.6771048307418823\n",
      "Epoch:  15     Batch:  144  /  468     Loss_generator:  0.6903442144393921     Loss_discriminator:  0.6871783137321472\n",
      "Epoch:  15     Batch:  145  /  468     Loss_generator:  0.7028776407241821     Loss_discriminator:  0.681406557559967\n",
      "Epoch:  15     Batch:  146  /  468     Loss_generator:  0.7478961944580078     Loss_discriminator:  0.694679856300354\n",
      "Epoch:  15     Batch:  147  /  468     Loss_generator:  0.7687642574310303     Loss_discriminator:  0.6793376207351685\n",
      "Epoch:  15     Batch:  148  /  468     Loss_generator:  0.7238665223121643     Loss_discriminator:  0.6709212064743042\n",
      "Epoch:  15     Batch:  149  /  468     Loss_generator:  0.6908241510391235     Loss_discriminator:  0.6832149028778076\n",
      "Epoch:  15     Batch:  150  /  468     Loss_generator:  0.6570675373077393     Loss_discriminator:  0.6855858564376831\n",
      "Epoch:  15     Batch:  151  /  468     Loss_generator:  0.6526637077331543     Loss_discriminator:  0.6812272667884827\n",
      "Epoch:  15     Batch:  152  /  468     Loss_generator:  0.6987903118133545     Loss_discriminator:  0.688184380531311\n",
      "Epoch:  15     Batch:  153  /  468     Loss_generator:  0.7505499720573425     Loss_discriminator:  0.6854546666145325\n",
      "Epoch:  15     Batch:  154  /  468     Loss_generator:  0.8143243789672852     Loss_discriminator:  0.6670863628387451\n",
      "Epoch:  15     Batch:  155  /  468     Loss_generator:  0.7820098400115967     Loss_discriminator:  0.676133394241333\n",
      "Epoch:  15     Batch:  156  /  468     Loss_generator:  0.6890498399734497     Loss_discriminator:  0.6915094256401062\n",
      "Epoch:  15     Batch:  157  /  468     Loss_generator:  0.6537567377090454     Loss_discriminator:  0.6809995770454407\n",
      "Epoch:  15     Batch:  158  /  468     Loss_generator:  0.6317393779754639     Loss_discriminator:  0.6766265034675598\n",
      "Epoch:  15     Batch:  159  /  468     Loss_generator:  0.6959723830223083     Loss_discriminator:  0.6908097863197327\n",
      "Epoch:  15     Batch:  160  /  468     Loss_generator:  0.7662041783332825     Loss_discriminator:  0.6806914806365967\n",
      "Epoch:  15     Batch:  161  /  468     Loss_generator:  0.7913291454315186     Loss_discriminator:  0.6763675212860107\n",
      "Epoch:  15     Batch:  162  /  468     Loss_generator:  0.7762467265129089     Loss_discriminator:  0.692069411277771\n",
      "Epoch:  15     Batch:  163  /  468     Loss_generator:  0.7270365953445435     Loss_discriminator:  0.6783294677734375\n",
      "Epoch:  15     Batch:  164  /  468     Loss_generator:  0.6792616844177246     Loss_discriminator:  0.6676762700080872\n",
      "Epoch:  15     Batch:  165  /  468     Loss_generator:  0.650436520576477     Loss_discriminator:  0.6884319186210632\n",
      "Epoch:  15     Batch:  166  /  468     Loss_generator:  0.6703711748123169     Loss_discriminator:  0.6759578585624695\n",
      "Epoch:  15     Batch:  167  /  468     Loss_generator:  0.7156893014907837     Loss_discriminator:  0.6794861555099487\n",
      "Epoch:  15     Batch:  168  /  468     Loss_generator:  0.7187488675117493     Loss_discriminator:  0.6847729682922363\n",
      "Epoch:  15     Batch:  169  /  468     Loss_generator:  0.7207613587379456     Loss_discriminator:  0.6818745732307434\n",
      "Epoch:  15     Batch:  170  /  468     Loss_generator:  0.7174948453903198     Loss_discriminator:  0.6709108948707581\n",
      "Epoch:  15     Batch:  171  /  468     Loss_generator:  0.7345149517059326     Loss_discriminator:  0.6811219453811646\n",
      "Epoch:  15     Batch:  172  /  468     Loss_generator:  0.7125877141952515     Loss_discriminator:  0.6824776530265808\n",
      "Epoch:  15     Batch:  173  /  468     Loss_generator:  0.6929570436477661     Loss_discriminator:  0.6814429759979248\n",
      "Epoch:  15     Batch:  174  /  468     Loss_generator:  0.6891410946846008     Loss_discriminator:  0.6943355798721313\n",
      "Epoch:  15     Batch:  175  /  468     Loss_generator:  0.7194333076477051     Loss_discriminator:  0.6820423603057861\n",
      "Epoch:  15     Batch:  176  /  468     Loss_generator:  0.7396539449691772     Loss_discriminator:  0.6879985332489014\n",
      "Epoch:  15     Batch:  177  /  468     Loss_generator:  0.7257609367370605     Loss_discriminator:  0.687861442565918\n",
      "Epoch:  15     Batch:  178  /  468     Loss_generator:  0.73618483543396     Loss_discriminator:  0.6739705801010132\n",
      "Epoch:  15     Batch:  179  /  468     Loss_generator:  0.7033048272132874     Loss_discriminator:  0.6846609115600586\n",
      "Epoch:  15     Batch:  180  /  468     Loss_generator:  0.6985760927200317     Loss_discriminator:  0.692866325378418\n",
      "Epoch:  15     Batch:  181  /  468     Loss_generator:  0.6870402097702026     Loss_discriminator:  0.6921833753585815\n",
      "Epoch:  15     Batch:  182  /  468     Loss_generator:  0.6826767921447754     Loss_discriminator:  0.6916127800941467\n",
      "Epoch:  15     Batch:  183  /  468     Loss_generator:  0.6826009750366211     Loss_discriminator:  0.6750722527503967\n",
      "Epoch:  15     Batch:  184  /  468     Loss_generator:  0.6920733451843262     Loss_discriminator:  0.6820889711380005\n",
      "Epoch:  15     Batch:  185  /  468     Loss_generator:  0.6945691108703613     Loss_discriminator:  0.681333065032959\n",
      "Epoch:  15     Batch:  186  /  468     Loss_generator:  0.73211669921875     Loss_discriminator:  0.6874473094940186\n",
      "Epoch:  15     Batch:  187  /  468     Loss_generator:  0.7514898777008057     Loss_discriminator:  0.6802117228507996\n",
      "Epoch:  15     Batch:  188  /  468     Loss_generator:  0.7455507516860962     Loss_discriminator:  0.6813346147537231\n",
      "Epoch:  15     Batch:  189  /  468     Loss_generator:  0.6910771131515503     Loss_discriminator:  0.6789997220039368\n",
      "Epoch:  15     Batch:  190  /  468     Loss_generator:  0.6656404137611389     Loss_discriminator:  0.6850645542144775\n",
      "Epoch:  15     Batch:  191  /  468     Loss_generator:  0.6780851483345032     Loss_discriminator:  0.6906009912490845\n",
      "Epoch:  15     Batch:  192  /  468     Loss_generator:  0.7143511772155762     Loss_discriminator:  0.68080735206604\n",
      "Epoch:  15     Batch:  193  /  468     Loss_generator:  0.7506623268127441     Loss_discriminator:  0.6934122443199158\n",
      "Epoch:  15     Batch:  194  /  468     Loss_generator:  0.7703481912612915     Loss_discriminator:  0.6701961755752563\n",
      "Epoch:  15     Batch:  195  /  468     Loss_generator:  0.7318980693817139     Loss_discriminator:  0.6910474896430969\n",
      "Epoch:  15     Batch:  196  /  468     Loss_generator:  0.6963604688644409     Loss_discriminator:  0.6692044734954834\n",
      "Epoch:  15     Batch:  197  /  468     Loss_generator:  0.6899762749671936     Loss_discriminator:  0.6853123307228088\n",
      "Epoch:  15     Batch:  198  /  468     Loss_generator:  0.7389219999313354     Loss_discriminator:  0.6938441395759583\n",
      "Epoch:  15     Batch:  199  /  468     Loss_generator:  0.7560316324234009     Loss_discriminator:  0.6805851459503174\n",
      "Epoch:  15     Batch:  200  /  468     Loss_generator:  0.7777428030967712     Loss_discriminator:  0.6855031847953796\n",
      "Epoch:  15     Batch:  201  /  468     Loss_generator:  0.7145875096321106     Loss_discriminator:  0.7026726007461548\n",
      "Epoch:  15     Batch:  202  /  468     Loss_generator:  0.6674500703811646     Loss_discriminator:  0.6840780973434448\n",
      "Epoch:  15     Batch:  203  /  468     Loss_generator:  0.6786609888076782     Loss_discriminator:  0.6956570744514465\n",
      "Epoch:  15     Batch:  204  /  468     Loss_generator:  0.6843727827072144     Loss_discriminator:  0.6699628829956055\n",
      "Epoch:  15     Batch:  205  /  468     Loss_generator:  0.7150654196739197     Loss_discriminator:  0.6765295267105103\n",
      "Epoch:  15     Batch:  206  /  468     Loss_generator:  0.7222020626068115     Loss_discriminator:  0.6939931511878967\n",
      "Epoch:  15     Batch:  207  /  468     Loss_generator:  0.7192448973655701     Loss_discriminator:  0.6769891977310181\n",
      "Epoch:  15     Batch:  208  /  468     Loss_generator:  0.6973881125450134     Loss_discriminator:  0.6853148937225342\n",
      "Epoch:  15     Batch:  209  /  468     Loss_generator:  0.7245407104492188     Loss_discriminator:  0.6926816701889038\n",
      "Epoch:  15     Batch:  210  /  468     Loss_generator:  0.7629003524780273     Loss_discriminator:  0.6755569577217102\n",
      "Epoch:  15     Batch:  211  /  468     Loss_generator:  0.7410420179367065     Loss_discriminator:  0.6794877648353577\n",
      "Epoch:  15     Batch:  212  /  468     Loss_generator:  0.702932596206665     Loss_discriminator:  0.6770463585853577\n",
      "Epoch:  15     Batch:  213  /  468     Loss_generator:  0.6619612574577332     Loss_discriminator:  0.6779173612594604\n",
      "Epoch:  15     Batch:  214  /  468     Loss_generator:  0.6701062321662903     Loss_discriminator:  0.6942500472068787\n",
      "Epoch:  15     Batch:  215  /  468     Loss_generator:  0.6989856362342834     Loss_discriminator:  0.6724320650100708\n",
      "Epoch:  15     Batch:  216  /  468     Loss_generator:  0.7874610424041748     Loss_discriminator:  0.6800363659858704\n",
      "Epoch:  15     Batch:  217  /  468     Loss_generator:  0.7738528251647949     Loss_discriminator:  0.6745569109916687\n",
      "Epoch:  15     Batch:  218  /  468     Loss_generator:  0.7322208881378174     Loss_discriminator:  0.672585129737854\n",
      "Epoch:  15     Batch:  219  /  468     Loss_generator:  0.6562615036964417     Loss_discriminator:  0.6858385801315308\n",
      "Epoch:  15     Batch:  220  /  468     Loss_generator:  0.6400882601737976     Loss_discriminator:  0.6804517507553101\n",
      "Epoch:  15     Batch:  221  /  468     Loss_generator:  0.662153959274292     Loss_discriminator:  0.6889106035232544\n",
      "Epoch:  15     Batch:  222  /  468     Loss_generator:  0.7145168781280518     Loss_discriminator:  0.6820809245109558\n",
      "Epoch:  15     Batch:  223  /  468     Loss_generator:  0.7958750128746033     Loss_discriminator:  0.6963883638381958\n",
      "Epoch:  15     Batch:  224  /  468     Loss_generator:  0.806370735168457     Loss_discriminator:  0.6882264614105225\n",
      "Epoch:  15     Batch:  225  /  468     Loss_generator:  0.7253919839859009     Loss_discriminator:  0.6777265071868896\n",
      "Epoch:  15     Batch:  226  /  468     Loss_generator:  0.6691234707832336     Loss_discriminator:  0.7107923030853271\n",
      "Epoch:  15     Batch:  227  /  468     Loss_generator:  0.6669338345527649     Loss_discriminator:  0.6843101978302002\n",
      "Epoch:  15     Batch:  228  /  468     Loss_generator:  0.6761409044265747     Loss_discriminator:  0.6708232164382935\n",
      "Epoch:  15     Batch:  229  /  468     Loss_generator:  0.7289671301841736     Loss_discriminator:  0.6878772377967834\n",
      "Epoch:  15     Batch:  230  /  468     Loss_generator:  0.7585795521736145     Loss_discriminator:  0.6764726042747498\n",
      "Epoch:  15     Batch:  231  /  468     Loss_generator:  0.7276482582092285     Loss_discriminator:  0.6828380823135376\n",
      "Epoch:  15     Batch:  232  /  468     Loss_generator:  0.6973328590393066     Loss_discriminator:  0.6746916770935059\n",
      "Epoch:  15     Batch:  233  /  468     Loss_generator:  0.6881852149963379     Loss_discriminator:  0.6963986158370972\n",
      "Epoch:  15     Batch:  234  /  468     Loss_generator:  0.7092858552932739     Loss_discriminator:  0.7010165452957153\n",
      "Epoch:  15     Batch:  235  /  468     Loss_generator:  0.7445180416107178     Loss_discriminator:  0.683435320854187\n",
      "Epoch:  15     Batch:  236  /  468     Loss_generator:  0.7646361589431763     Loss_discriminator:  0.6841554045677185\n",
      "Epoch:  15     Batch:  237  /  468     Loss_generator:  0.7363795042037964     Loss_discriminator:  0.6801382899284363\n",
      "Epoch:  15     Batch:  238  /  468     Loss_generator:  0.6944564580917358     Loss_discriminator:  0.6948726773262024\n",
      "Epoch:  15     Batch:  239  /  468     Loss_generator:  0.6711325645446777     Loss_discriminator:  0.7031176090240479\n",
      "Epoch:  15     Batch:  240  /  468     Loss_generator:  0.6863664984703064     Loss_discriminator:  0.666676938533783\n",
      "Epoch:  15     Batch:  241  /  468     Loss_generator:  0.704684853553772     Loss_discriminator:  0.7022287845611572\n",
      "Epoch:  15     Batch:  242  /  468     Loss_generator:  0.7249199151992798     Loss_discriminator:  0.6945129036903381\n",
      "Epoch:  15     Batch:  243  /  468     Loss_generator:  0.7611190676689148     Loss_discriminator:  0.6819237470626831\n",
      "Epoch:  15     Batch:  244  /  468     Loss_generator:  0.7586933970451355     Loss_discriminator:  0.6832465529441833\n",
      "Epoch:  15     Batch:  245  /  468     Loss_generator:  0.7282695174217224     Loss_discriminator:  0.6754341721534729\n",
      "Epoch:  15     Batch:  246  /  468     Loss_generator:  0.7018028497695923     Loss_discriminator:  0.676520586013794\n",
      "Epoch:  15     Batch:  247  /  468     Loss_generator:  0.681719183921814     Loss_discriminator:  0.6885017156600952\n",
      "Epoch:  15     Batch:  248  /  468     Loss_generator:  0.6975505352020264     Loss_discriminator:  0.6930456161499023\n",
      "Epoch:  15     Batch:  249  /  468     Loss_generator:  0.6831274032592773     Loss_discriminator:  0.682765781879425\n",
      "Epoch:  15     Batch:  250  /  468     Loss_generator:  0.7239933013916016     Loss_discriminator:  0.6865378022193909\n",
      "Epoch:  15     Batch:  251  /  468     Loss_generator:  0.757091224193573     Loss_discriminator:  0.6917716860771179\n",
      "Epoch:  15     Batch:  252  /  468     Loss_generator:  0.792375922203064     Loss_discriminator:  0.6973692178726196\n",
      "Epoch:  15     Batch:  253  /  468     Loss_generator:  0.7401706576347351     Loss_discriminator:  0.6881779432296753\n",
      "Epoch:  15     Batch:  254  /  468     Loss_generator:  0.6891219615936279     Loss_discriminator:  0.6847560405731201\n",
      "Epoch:  15     Batch:  255  /  468     Loss_generator:  0.6469689011573792     Loss_discriminator:  0.6984298825263977\n",
      "Epoch:  15     Batch:  256  /  468     Loss_generator:  0.677791953086853     Loss_discriminator:  0.6896167993545532\n",
      "Epoch:  15     Batch:  257  /  468     Loss_generator:  0.7095388770103455     Loss_discriminator:  0.6897609233856201\n",
      "Epoch:  15     Batch:  258  /  468     Loss_generator:  0.7261461019515991     Loss_discriminator:  0.6810305118560791\n",
      "Epoch:  15     Batch:  259  /  468     Loss_generator:  0.7305328845977783     Loss_discriminator:  0.6765124797821045\n",
      "Epoch:  15     Batch:  260  /  468     Loss_generator:  0.6922057867050171     Loss_discriminator:  0.6674332022666931\n",
      "Epoch:  15     Batch:  261  /  468     Loss_generator:  0.6800574064254761     Loss_discriminator:  0.6978104114532471\n",
      "Epoch:  15     Batch:  262  /  468     Loss_generator:  0.7168707847595215     Loss_discriminator:  0.6937772035598755\n",
      "Epoch:  15     Batch:  263  /  468     Loss_generator:  0.7526912689208984     Loss_discriminator:  0.6825228929519653\n",
      "Epoch:  15     Batch:  264  /  468     Loss_generator:  0.7646154165267944     Loss_discriminator:  0.6703363656997681\n",
      "Epoch:  15     Batch:  265  /  468     Loss_generator:  0.7414244413375854     Loss_discriminator:  0.6853212118148804\n",
      "Epoch:  15     Batch:  266  /  468     Loss_generator:  0.6722229719161987     Loss_discriminator:  0.6900652647018433\n",
      "Epoch:  15     Batch:  267  /  468     Loss_generator:  0.6672293543815613     Loss_discriminator:  0.6891178488731384\n",
      "Epoch:  15     Batch:  268  /  468     Loss_generator:  0.70809406042099     Loss_discriminator:  0.6817543506622314\n",
      "Epoch:  15     Batch:  269  /  468     Loss_generator:  0.7126384377479553     Loss_discriminator:  0.6783604621887207\n",
      "Epoch:  15     Batch:  270  /  468     Loss_generator:  0.727500855922699     Loss_discriminator:  0.6875134706497192\n",
      "Epoch:  15     Batch:  271  /  468     Loss_generator:  0.7097996473312378     Loss_discriminator:  0.6824461221694946\n",
      "Epoch:  15     Batch:  272  /  468     Loss_generator:  0.7025626301765442     Loss_discriminator:  0.6836469173431396\n",
      "Epoch:  15     Batch:  273  /  468     Loss_generator:  0.686576247215271     Loss_discriminator:  0.6948882937431335\n",
      "Epoch:  15     Batch:  274  /  468     Loss_generator:  0.6906250715255737     Loss_discriminator:  0.7110095024108887\n",
      "Epoch:  15     Batch:  275  /  468     Loss_generator:  0.7138240933418274     Loss_discriminator:  0.6745812892913818\n",
      "Epoch:  15     Batch:  276  /  468     Loss_generator:  0.7470707893371582     Loss_discriminator:  0.681227445602417\n",
      "Epoch:  15     Batch:  277  /  468     Loss_generator:  0.7519704103469849     Loss_discriminator:  0.6961257457733154\n",
      "Epoch:  15     Batch:  278  /  468     Loss_generator:  0.7503015398979187     Loss_discriminator:  0.6904362440109253\n",
      "Epoch:  15     Batch:  279  /  468     Loss_generator:  0.7275176048278809     Loss_discriminator:  0.6832864284515381\n",
      "Epoch:  15     Batch:  280  /  468     Loss_generator:  0.7015863060951233     Loss_discriminator:  0.6956672668457031\n",
      "Epoch:  15     Batch:  281  /  468     Loss_generator:  0.6844059824943542     Loss_discriminator:  0.6745325326919556\n",
      "Epoch:  15     Batch:  282  /  468     Loss_generator:  0.6526275873184204     Loss_discriminator:  0.6766475439071655\n",
      "Epoch:  15     Batch:  283  /  468     Loss_generator:  0.6922422647476196     Loss_discriminator:  0.687923789024353\n",
      "Epoch:  15     Batch:  284  /  468     Loss_generator:  0.7450209856033325     Loss_discriminator:  0.6717272996902466\n",
      "Epoch:  15     Batch:  285  /  468     Loss_generator:  0.8046953678131104     Loss_discriminator:  0.6898179650306702\n",
      "Epoch:  15     Batch:  286  /  468     Loss_generator:  0.7437304854393005     Loss_discriminator:  0.6888079643249512\n",
      "Epoch:  15     Batch:  287  /  468     Loss_generator:  0.6779927611351013     Loss_discriminator:  0.6887407898902893\n",
      "Epoch:  15     Batch:  288  /  468     Loss_generator:  0.6321011781692505     Loss_discriminator:  0.6712971925735474\n",
      "Epoch:  15     Batch:  289  /  468     Loss_generator:  0.6586241722106934     Loss_discriminator:  0.7001433372497559\n",
      "Epoch:  15     Batch:  290  /  468     Loss_generator:  0.7210891842842102     Loss_discriminator:  0.6929057836532593\n",
      "Epoch:  15     Batch:  291  /  468     Loss_generator:  0.7807179093360901     Loss_discriminator:  0.6674463152885437\n",
      "Epoch:  15     Batch:  292  /  468     Loss_generator:  0.7586165070533752     Loss_discriminator:  0.6931106448173523\n",
      "Epoch:  15     Batch:  293  /  468     Loss_generator:  0.6914855241775513     Loss_discriminator:  0.6945019960403442\n",
      "Epoch:  15     Batch:  294  /  468     Loss_generator:  0.6782853603363037     Loss_discriminator:  0.6899913549423218\n",
      "Epoch:  15     Batch:  295  /  468     Loss_generator:  0.7152595520019531     Loss_discriminator:  0.6771698594093323\n",
      "Epoch:  15     Batch:  296  /  468     Loss_generator:  0.7298797965049744     Loss_discriminator:  0.6904070377349854\n",
      "Epoch:  15     Batch:  297  /  468     Loss_generator:  0.7486022114753723     Loss_discriminator:  0.6880120038986206\n",
      "Epoch:  15     Batch:  298  /  468     Loss_generator:  0.7297689318656921     Loss_discriminator:  0.6955313682556152\n",
      "Epoch:  15     Batch:  299  /  468     Loss_generator:  0.701169490814209     Loss_discriminator:  0.6858198642730713\n",
      "Epoch:  15     Batch:  300  /  468     Loss_generator:  0.6743687987327576     Loss_discriminator:  0.6786772608757019\n",
      "Epoch:  15     Batch:  301  /  468     Loss_generator:  0.7043952941894531     Loss_discriminator:  0.6818395853042603\n",
      "Epoch:  15     Batch:  302  /  468     Loss_generator:  0.7226778268814087     Loss_discriminator:  0.6829333305358887\n",
      "Epoch:  15     Batch:  303  /  468     Loss_generator:  0.7203556299209595     Loss_discriminator:  0.6776543855667114\n",
      "Epoch:  15     Batch:  304  /  468     Loss_generator:  0.704840898513794     Loss_discriminator:  0.667534351348877\n",
      "Epoch:  15     Batch:  305  /  468     Loss_generator:  0.6883169412612915     Loss_discriminator:  0.6835337281227112\n",
      "Epoch:  15     Batch:  306  /  468     Loss_generator:  0.7144991159439087     Loss_discriminator:  0.6832871437072754\n",
      "Epoch:  15     Batch:  307  /  468     Loss_generator:  0.7066153883934021     Loss_discriminator:  0.6885324120521545\n",
      "Epoch:  15     Batch:  308  /  468     Loss_generator:  0.7105773687362671     Loss_discriminator:  0.691091001033783\n",
      "Epoch:  15     Batch:  309  /  468     Loss_generator:  0.7148925065994263     Loss_discriminator:  0.6847493648529053\n",
      "Epoch:  15     Batch:  310  /  468     Loss_generator:  0.7274290919303894     Loss_discriminator:  0.6795088648796082\n",
      "Epoch:  15     Batch:  311  /  468     Loss_generator:  0.7093240022659302     Loss_discriminator:  0.6733694076538086\n",
      "Epoch:  15     Batch:  312  /  468     Loss_generator:  0.6957918405532837     Loss_discriminator:  0.685545802116394\n",
      "Epoch:  15     Batch:  313  /  468     Loss_generator:  0.6997695565223694     Loss_discriminator:  0.6846440434455872\n",
      "Epoch:  15     Batch:  314  /  468     Loss_generator:  0.7265907526016235     Loss_discriminator:  0.6880985498428345\n",
      "Epoch:  15     Batch:  315  /  468     Loss_generator:  0.7437354922294617     Loss_discriminator:  0.6934735774993896\n",
      "Epoch:  15     Batch:  316  /  468     Loss_generator:  0.7153968811035156     Loss_discriminator:  0.6714541912078857\n",
      "Epoch:  15     Batch:  317  /  468     Loss_generator:  0.7003778219223022     Loss_discriminator:  0.688015878200531\n",
      "Epoch:  15     Batch:  318  /  468     Loss_generator:  0.7114219069480896     Loss_discriminator:  0.6874793767929077\n",
      "Epoch:  15     Batch:  319  /  468     Loss_generator:  0.6898505091667175     Loss_discriminator:  0.6903824806213379\n",
      "Epoch:  15     Batch:  320  /  468     Loss_generator:  0.6975526809692383     Loss_discriminator:  0.6875656843185425\n",
      "Epoch:  15     Batch:  321  /  468     Loss_generator:  0.7202590703964233     Loss_discriminator:  0.6868991255760193\n",
      "Epoch:  15     Batch:  322  /  468     Loss_generator:  0.7391062378883362     Loss_discriminator:  0.6939418315887451\n",
      "Epoch:  15     Batch:  323  /  468     Loss_generator:  0.731882631778717     Loss_discriminator:  0.6759970188140869\n",
      "Epoch:  15     Batch:  324  /  468     Loss_generator:  0.7636840343475342     Loss_discriminator:  0.6908824443817139\n",
      "Epoch:  15     Batch:  325  /  468     Loss_generator:  0.7288658022880554     Loss_discriminator:  0.7050082087516785\n",
      "Epoch:  15     Batch:  326  /  468     Loss_generator:  0.6841455698013306     Loss_discriminator:  0.6876558065414429\n",
      "Epoch:  15     Batch:  327  /  468     Loss_generator:  0.6694067716598511     Loss_discriminator:  0.689288854598999\n",
      "Epoch:  15     Batch:  328  /  468     Loss_generator:  0.6911829113960266     Loss_discriminator:  0.6941832900047302\n",
      "Epoch:  15     Batch:  329  /  468     Loss_generator:  0.6921462416648865     Loss_discriminator:  0.6843630075454712\n",
      "Epoch:  15     Batch:  330  /  468     Loss_generator:  0.7063854932785034     Loss_discriminator:  0.6737557649612427\n",
      "Epoch:  15     Batch:  331  /  468     Loss_generator:  0.7125399708747864     Loss_discriminator:  0.683268129825592\n",
      "Epoch:  15     Batch:  332  /  468     Loss_generator:  0.6792352199554443     Loss_discriminator:  0.6817293763160706\n",
      "Epoch:  15     Batch:  333  /  468     Loss_generator:  0.6930513978004456     Loss_discriminator:  0.6843717098236084\n",
      "Epoch:  15     Batch:  334  /  468     Loss_generator:  0.7118469476699829     Loss_discriminator:  0.6837983131408691\n",
      "Epoch:  15     Batch:  335  /  468     Loss_generator:  0.7007444500923157     Loss_discriminator:  0.6923357248306274\n",
      "Epoch:  15     Batch:  336  /  468     Loss_generator:  0.7036184668540955     Loss_discriminator:  0.6808143854141235\n",
      "Epoch:  15     Batch:  337  /  468     Loss_generator:  0.7055753469467163     Loss_discriminator:  0.6775875091552734\n",
      "Epoch:  15     Batch:  338  /  468     Loss_generator:  0.7105556726455688     Loss_discriminator:  0.6809965372085571\n",
      "Epoch:  15     Batch:  339  /  468     Loss_generator:  0.7093705534934998     Loss_discriminator:  0.6904819011688232\n",
      "Epoch:  15     Batch:  340  /  468     Loss_generator:  0.7240371704101562     Loss_discriminator:  0.6831414699554443\n",
      "Epoch:  15     Batch:  341  /  468     Loss_generator:  0.7038257122039795     Loss_discriminator:  0.6778115630149841\n",
      "Epoch:  15     Batch:  342  /  468     Loss_generator:  0.6961674690246582     Loss_discriminator:  0.6914109587669373\n",
      "Epoch:  15     Batch:  343  /  468     Loss_generator:  0.6979907751083374     Loss_discriminator:  0.669685423374176\n",
      "Epoch:  15     Batch:  344  /  468     Loss_generator:  0.7415052652359009     Loss_discriminator:  0.6835334300994873\n",
      "Epoch:  15     Batch:  345  /  468     Loss_generator:  0.728387713432312     Loss_discriminator:  0.6798207759857178\n",
      "Epoch:  15     Batch:  346  /  468     Loss_generator:  0.6941145658493042     Loss_discriminator:  0.6835875511169434\n",
      "Epoch:  15     Batch:  347  /  468     Loss_generator:  0.7069895267486572     Loss_discriminator:  0.6714872121810913\n",
      "Epoch:  15     Batch:  348  /  468     Loss_generator:  0.7099485397338867     Loss_discriminator:  0.6760267019271851\n",
      "Epoch:  15     Batch:  349  /  468     Loss_generator:  0.7174239158630371     Loss_discriminator:  0.6865977644920349\n",
      "Epoch:  15     Batch:  350  /  468     Loss_generator:  0.7406072020530701     Loss_discriminator:  0.681043803691864\n",
      "Epoch:  15     Batch:  351  /  468     Loss_generator:  0.7225314378738403     Loss_discriminator:  0.687190055847168\n",
      "Epoch:  15     Batch:  352  /  468     Loss_generator:  0.7274570465087891     Loss_discriminator:  0.6811090707778931\n",
      "Epoch:  15     Batch:  353  /  468     Loss_generator:  0.7293559312820435     Loss_discriminator:  0.6922632455825806\n",
      "Epoch:  15     Batch:  354  /  468     Loss_generator:  0.7208157777786255     Loss_discriminator:  0.6850505471229553\n",
      "Epoch:  15     Batch:  355  /  468     Loss_generator:  0.6986134052276611     Loss_discriminator:  0.6780694723129272\n",
      "Epoch:  15     Batch:  356  /  468     Loss_generator:  0.7050241827964783     Loss_discriminator:  0.6834030747413635\n",
      "Epoch:  15     Batch:  357  /  468     Loss_generator:  0.6994372606277466     Loss_discriminator:  0.6828018426895142\n",
      "Epoch:  15     Batch:  358  /  468     Loss_generator:  0.7089444994926453     Loss_discriminator:  0.6847843527793884\n",
      "Epoch:  15     Batch:  359  /  468     Loss_generator:  0.713860034942627     Loss_discriminator:  0.6971571445465088\n",
      "Epoch:  15     Batch:  360  /  468     Loss_generator:  0.7327941656112671     Loss_discriminator:  0.670464813709259\n",
      "Epoch:  15     Batch:  361  /  468     Loss_generator:  0.7153122425079346     Loss_discriminator:  0.6882808208465576\n",
      "Epoch:  15     Batch:  362  /  468     Loss_generator:  0.6619817018508911     Loss_discriminator:  0.6860485076904297\n",
      "Epoch:  15     Batch:  363  /  468     Loss_generator:  0.676838219165802     Loss_discriminator:  0.6996737718582153\n",
      "Epoch:  15     Batch:  364  /  468     Loss_generator:  0.7022868394851685     Loss_discriminator:  0.6750720739364624\n",
      "Epoch:  15     Batch:  365  /  468     Loss_generator:  0.7380270957946777     Loss_discriminator:  0.6867948174476624\n",
      "Epoch:  15     Batch:  366  /  468     Loss_generator:  0.7829957008361816     Loss_discriminator:  0.6834540963172913\n",
      "Epoch:  15     Batch:  367  /  468     Loss_generator:  0.7219282388687134     Loss_discriminator:  0.6830697059631348\n",
      "Epoch:  15     Batch:  368  /  468     Loss_generator:  0.6746299862861633     Loss_discriminator:  0.6887514591217041\n",
      "Epoch:  15     Batch:  369  /  468     Loss_generator:  0.6567195653915405     Loss_discriminator:  0.6781142950057983\n",
      "Epoch:  15     Batch:  370  /  468     Loss_generator:  0.6842352151870728     Loss_discriminator:  0.6838787794113159\n",
      "Epoch:  15     Batch:  371  /  468     Loss_generator:  0.7462711334228516     Loss_discriminator:  0.6889485120773315\n",
      "Epoch:  15     Batch:  372  /  468     Loss_generator:  0.7254945039749146     Loss_discriminator:  0.7033730149269104\n",
      "Epoch:  15     Batch:  373  /  468     Loss_generator:  0.760668158531189     Loss_discriminator:  0.6890365481376648\n",
      "Epoch:  15     Batch:  374  /  468     Loss_generator:  0.7426416873931885     Loss_discriminator:  0.6886494159698486\n",
      "Epoch:  15     Batch:  375  /  468     Loss_generator:  0.6993198990821838     Loss_discriminator:  0.6820298433303833\n",
      "Epoch:  15     Batch:  376  /  468     Loss_generator:  0.6840612292289734     Loss_discriminator:  0.6804625988006592\n",
      "Epoch:  15     Batch:  377  /  468     Loss_generator:  0.7084687352180481     Loss_discriminator:  0.6890734434127808\n",
      "Epoch:  15     Batch:  378  /  468     Loss_generator:  0.6796942949295044     Loss_discriminator:  0.6948608160018921\n",
      "Epoch:  15     Batch:  379  /  468     Loss_generator:  0.6752161979675293     Loss_discriminator:  0.6965827941894531\n",
      "Epoch:  15     Batch:  380  /  468     Loss_generator:  0.717456579208374     Loss_discriminator:  0.6795126795768738\n",
      "Epoch:  15     Batch:  381  /  468     Loss_generator:  0.7550956606864929     Loss_discriminator:  0.6903603076934814\n",
      "Epoch:  15     Batch:  382  /  468     Loss_generator:  0.7358039617538452     Loss_discriminator:  0.6961016654968262\n",
      "Epoch:  15     Batch:  383  /  468     Loss_generator:  0.7204795479774475     Loss_discriminator:  0.6888750791549683\n",
      "Epoch:  15     Batch:  384  /  468     Loss_generator:  0.7116442322731018     Loss_discriminator:  0.6968629360198975\n",
      "Epoch:  15     Batch:  385  /  468     Loss_generator:  0.7358376979827881     Loss_discriminator:  0.6764496564865112\n",
      "Epoch:  15     Batch:  386  /  468     Loss_generator:  0.7014353275299072     Loss_discriminator:  0.6809152364730835\n",
      "Epoch:  15     Batch:  387  /  468     Loss_generator:  0.685901403427124     Loss_discriminator:  0.6845327019691467\n",
      "Epoch:  15     Batch:  388  /  468     Loss_generator:  0.6995991468429565     Loss_discriminator:  0.6944565773010254\n",
      "Epoch:  15     Batch:  389  /  468     Loss_generator:  0.6713506579399109     Loss_discriminator:  0.6856635808944702\n",
      "Epoch:  15     Batch:  390  /  468     Loss_generator:  0.6935547590255737     Loss_discriminator:  0.6933661699295044\n",
      "Epoch:  15     Batch:  391  /  468     Loss_generator:  0.7379862666130066     Loss_discriminator:  0.7044609785079956\n",
      "Epoch:  15     Batch:  392  /  468     Loss_generator:  0.7012386918067932     Loss_discriminator:  0.686596155166626\n",
      "Epoch:  15     Batch:  393  /  468     Loss_generator:  0.6927341222763062     Loss_discriminator:  0.6799110174179077\n",
      "Epoch:  15     Batch:  394  /  468     Loss_generator:  0.7102511525154114     Loss_discriminator:  0.6982063055038452\n",
      "Epoch:  15     Batch:  395  /  468     Loss_generator:  0.7189650535583496     Loss_discriminator:  0.6839299201965332\n",
      "Epoch:  15     Batch:  396  /  468     Loss_generator:  0.7516429424285889     Loss_discriminator:  0.6633241176605225\n",
      "Epoch:  15     Batch:  397  /  468     Loss_generator:  0.7793293595314026     Loss_discriminator:  0.6786298155784607\n",
      "Epoch:  15     Batch:  398  /  468     Loss_generator:  0.7148833274841309     Loss_discriminator:  0.6939287781715393\n",
      "Epoch:  15     Batch:  399  /  468     Loss_generator:  0.6963132619857788     Loss_discriminator:  0.6882951259613037\n",
      "Epoch:  15     Batch:  400  /  468     Loss_generator:  0.6802239418029785     Loss_discriminator:  0.6884835958480835\n",
      "Epoch:  15     Batch:  401  /  468     Loss_generator:  0.7000906467437744     Loss_discriminator:  0.6847183108329773\n",
      "Epoch:  15     Batch:  402  /  468     Loss_generator:  0.7154122591018677     Loss_discriminator:  0.6749022006988525\n",
      "Epoch:  15     Batch:  403  /  468     Loss_generator:  0.7082253694534302     Loss_discriminator:  0.6928154230117798\n",
      "Epoch:  15     Batch:  404  /  468     Loss_generator:  0.6950833797454834     Loss_discriminator:  0.6991367340087891\n",
      "Epoch:  15     Batch:  405  /  468     Loss_generator:  0.6876847743988037     Loss_discriminator:  0.6686533093452454\n",
      "Epoch:  15     Batch:  406  /  468     Loss_generator:  0.6691892147064209     Loss_discriminator:  0.6926488876342773\n",
      "Epoch:  15     Batch:  407  /  468     Loss_generator:  0.6991817355155945     Loss_discriminator:  0.7025405168533325\n",
      "Epoch:  15     Batch:  408  /  468     Loss_generator:  0.7791158556938171     Loss_discriminator:  0.6879006624221802\n",
      "Epoch:  15     Batch:  409  /  468     Loss_generator:  0.8162037134170532     Loss_discriminator:  0.6774792671203613\n",
      "Epoch:  15     Batch:  410  /  468     Loss_generator:  0.7447336316108704     Loss_discriminator:  0.6932718753814697\n",
      "Epoch:  15     Batch:  411  /  468     Loss_generator:  0.6950919032096863     Loss_discriminator:  0.7046799659729004\n",
      "Epoch:  15     Batch:  412  /  468     Loss_generator:  0.6499848961830139     Loss_discriminator:  0.6738960146903992\n",
      "Epoch:  15     Batch:  413  /  468     Loss_generator:  0.6800073981285095     Loss_discriminator:  0.6818751692771912\n",
      "Epoch:  15     Batch:  414  /  468     Loss_generator:  0.7011200189590454     Loss_discriminator:  0.6703627109527588\n",
      "Epoch:  15     Batch:  415  /  468     Loss_generator:  0.7140954732894897     Loss_discriminator:  0.6840746998786926\n",
      "Epoch:  15     Batch:  416  /  468     Loss_generator:  0.7320546507835388     Loss_discriminator:  0.6710088849067688\n",
      "Epoch:  15     Batch:  417  /  468     Loss_generator:  0.725748598575592     Loss_discriminator:  0.6791415214538574\n",
      "Epoch:  15     Batch:  418  /  468     Loss_generator:  0.6896106004714966     Loss_discriminator:  0.6750521063804626\n",
      "Epoch:  15     Batch:  419  /  468     Loss_generator:  0.6957600116729736     Loss_discriminator:  0.6757382750511169\n",
      "Epoch:  15     Batch:  420  /  468     Loss_generator:  0.758590817451477     Loss_discriminator:  0.679429292678833\n",
      "Epoch:  15     Batch:  421  /  468     Loss_generator:  0.7591902613639832     Loss_discriminator:  0.685849130153656\n",
      "Epoch:  15     Batch:  422  /  468     Loss_generator:  0.7196512818336487     Loss_discriminator:  0.691821277141571\n",
      "Epoch:  15     Batch:  423  /  468     Loss_generator:  0.6868152618408203     Loss_discriminator:  0.6671490669250488\n",
      "Epoch:  15     Batch:  424  /  468     Loss_generator:  0.6940452456474304     Loss_discriminator:  0.6637668609619141\n",
      "Epoch:  15     Batch:  425  /  468     Loss_generator:  0.6843423247337341     Loss_discriminator:  0.6905122399330139\n",
      "Epoch:  15     Batch:  426  /  468     Loss_generator:  0.7102181315422058     Loss_discriminator:  0.687768816947937\n",
      "Epoch:  15     Batch:  427  /  468     Loss_generator:  0.7197592258453369     Loss_discriminator:  0.6800833344459534\n",
      "Epoch:  15     Batch:  428  /  468     Loss_generator:  0.7149618268013     Loss_discriminator:  0.6855740547180176\n",
      "Epoch:  15     Batch:  429  /  468     Loss_generator:  0.727012038230896     Loss_discriminator:  0.6794887781143188\n",
      "Epoch:  15     Batch:  430  /  468     Loss_generator:  0.7049948573112488     Loss_discriminator:  0.6707901358604431\n",
      "Epoch:  15     Batch:  431  /  468     Loss_generator:  0.6956688165664673     Loss_discriminator:  0.6854286193847656\n",
      "Epoch:  15     Batch:  432  /  468     Loss_generator:  0.7059657573699951     Loss_discriminator:  0.6850430965423584\n",
      "Epoch:  15     Batch:  433  /  468     Loss_generator:  0.7105055451393127     Loss_discriminator:  0.6861482858657837\n",
      "Epoch:  15     Batch:  434  /  468     Loss_generator:  0.7396515607833862     Loss_discriminator:  0.7106791138648987\n",
      "Epoch:  15     Batch:  435  /  468     Loss_generator:  0.7243646383285522     Loss_discriminator:  0.67818284034729\n",
      "Epoch:  15     Batch:  436  /  468     Loss_generator:  0.696159839630127     Loss_discriminator:  0.6810290217399597\n",
      "Epoch:  15     Batch:  437  /  468     Loss_generator:  0.6960458755493164     Loss_discriminator:  0.6765616536140442\n",
      "Epoch:  15     Batch:  438  /  468     Loss_generator:  0.6999437808990479     Loss_discriminator:  0.7002283334732056\n",
      "Epoch:  15     Batch:  439  /  468     Loss_generator:  0.7169141173362732     Loss_discriminator:  0.7017306089401245\n",
      "Epoch:  15     Batch:  440  /  468     Loss_generator:  0.7461797595024109     Loss_discriminator:  0.7031331062316895\n",
      "Epoch:  15     Batch:  441  /  468     Loss_generator:  0.7730343341827393     Loss_discriminator:  0.6795058250427246\n",
      "Epoch:  15     Batch:  442  /  468     Loss_generator:  0.7257763147354126     Loss_discriminator:  0.6721886992454529\n",
      "Epoch:  15     Batch:  443  /  468     Loss_generator:  0.6907679438591003     Loss_discriminator:  0.6842482089996338\n",
      "Epoch:  15     Batch:  444  /  468     Loss_generator:  0.6788886189460754     Loss_discriminator:  0.6895241737365723\n",
      "Epoch:  15     Batch:  445  /  468     Loss_generator:  0.689562201499939     Loss_discriminator:  0.6694917678833008\n",
      "Epoch:  15     Batch:  446  /  468     Loss_generator:  0.6852937936782837     Loss_discriminator:  0.6892229318618774\n",
      "Epoch:  15     Batch:  447  /  468     Loss_generator:  0.7079647779464722     Loss_discriminator:  0.6882306933403015\n",
      "Epoch:  15     Batch:  448  /  468     Loss_generator:  0.7456623315811157     Loss_discriminator:  0.6852834224700928\n",
      "Epoch:  15     Batch:  449  /  468     Loss_generator:  0.7688374519348145     Loss_discriminator:  0.6816981434822083\n",
      "Epoch:  15     Batch:  450  /  468     Loss_generator:  0.7171732187271118     Loss_discriminator:  0.6851843595504761\n",
      "Epoch:  15     Batch:  451  /  468     Loss_generator:  0.657401442527771     Loss_discriminator:  0.6806970238685608\n",
      "Epoch:  15     Batch:  452  /  468     Loss_generator:  0.6580976843833923     Loss_discriminator:  0.687645673751831\n",
      "Epoch:  15     Batch:  453  /  468     Loss_generator:  0.6869828701019287     Loss_discriminator:  0.693719744682312\n",
      "Epoch:  15     Batch:  454  /  468     Loss_generator:  0.7270811796188354     Loss_discriminator:  0.6825995445251465\n",
      "Epoch:  15     Batch:  455  /  468     Loss_generator:  0.7830104827880859     Loss_discriminator:  0.6948757171630859\n",
      "Epoch:  15     Batch:  456  /  468     Loss_generator:  0.7543838024139404     Loss_discriminator:  0.6937832832336426\n",
      "Epoch:  15     Batch:  457  /  468     Loss_generator:  0.7095546722412109     Loss_discriminator:  0.6868836879730225\n",
      "Epoch:  15     Batch:  458  /  468     Loss_generator:  0.6869884729385376     Loss_discriminator:  0.6817079186439514\n",
      "Epoch:  15     Batch:  459  /  468     Loss_generator:  0.700481653213501     Loss_discriminator:  0.6776372194290161\n",
      "Epoch:  15     Batch:  460  /  468     Loss_generator:  0.6965185403823853     Loss_discriminator:  0.6809478998184204\n",
      "Epoch:  15     Batch:  461  /  468     Loss_generator:  0.6976723670959473     Loss_discriminator:  0.686488687992096\n",
      "Epoch:  15     Batch:  462  /  468     Loss_generator:  0.7083578705787659     Loss_discriminator:  0.6841757297515869\n",
      "Epoch:  15     Batch:  463  /  468     Loss_generator:  0.7263655662536621     Loss_discriminator:  0.6764147281646729\n",
      "Epoch:  15     Batch:  464  /  468     Loss_generator:  0.71967613697052     Loss_discriminator:  0.6851385831832886\n",
      "Epoch:  15     Batch:  465  /  468     Loss_generator:  0.7125943899154663     Loss_discriminator:  0.6885865926742554\n",
      "Epoch:  15     Batch:  466  /  468     Loss_generator:  0.7305095195770264     Loss_discriminator:  0.6837577819824219\n",
      "Epoch:  15     Batch:  467  /  468     Loss_generator:  0.7139813899993896     Loss_discriminator:  0.6927787065505981\n",
      "Epoch:  16     Batch:  0  /  468     Loss_generator:  0.7117088437080383     Loss_discriminator:  0.6917866468429565\n",
      "Epoch:  16     Batch:  1  /  468     Loss_generator:  0.7096012234687805     Loss_discriminator:  0.6803750991821289\n",
      "Epoch:  16     Batch:  2  /  468     Loss_generator:  0.7481024265289307     Loss_discriminator:  0.6882267594337463\n",
      "Epoch:  16     Batch:  3  /  468     Loss_generator:  0.7257332801818848     Loss_discriminator:  0.6912810802459717\n",
      "Epoch:  16     Batch:  4  /  468     Loss_generator:  0.6934375762939453     Loss_discriminator:  0.6758831143379211\n",
      "Epoch:  16     Batch:  5  /  468     Loss_generator:  0.6783051490783691     Loss_discriminator:  0.6839756369590759\n",
      "Epoch:  16     Batch:  6  /  468     Loss_generator:  0.6824797987937927     Loss_discriminator:  0.6827019453048706\n",
      "Epoch:  16     Batch:  7  /  468     Loss_generator:  0.7094824314117432     Loss_discriminator:  0.6837949752807617\n",
      "Epoch:  16     Batch:  8  /  468     Loss_generator:  0.7291538715362549     Loss_discriminator:  0.6883116960525513\n",
      "Epoch:  16     Batch:  9  /  468     Loss_generator:  0.7752106189727783     Loss_discriminator:  0.6836676597595215\n",
      "Epoch:  16     Batch:  10  /  468     Loss_generator:  0.7356753945350647     Loss_discriminator:  0.6755184531211853\n",
      "Epoch:  16     Batch:  11  /  468     Loss_generator:  0.6838516592979431     Loss_discriminator:  0.6965333819389343\n",
      "Epoch:  16     Batch:  12  /  468     Loss_generator:  0.7161272764205933     Loss_discriminator:  0.6766571998596191\n",
      "Epoch:  16     Batch:  13  /  468     Loss_generator:  0.7023208141326904     Loss_discriminator:  0.6713179349899292\n",
      "Epoch:  16     Batch:  14  /  468     Loss_generator:  0.725576639175415     Loss_discriminator:  0.6877422332763672\n",
      "Epoch:  16     Batch:  15  /  468     Loss_generator:  0.7477933168411255     Loss_discriminator:  0.6716059446334839\n",
      "Epoch:  16     Batch:  16  /  468     Loss_generator:  0.7162466049194336     Loss_discriminator:  0.6868835687637329\n",
      "Epoch:  16     Batch:  17  /  468     Loss_generator:  0.6613075733184814     Loss_discriminator:  0.6732363700866699\n",
      "Epoch:  16     Batch:  18  /  468     Loss_generator:  0.6562736630439758     Loss_discriminator:  0.6906400322914124\n",
      "Epoch:  16     Batch:  19  /  468     Loss_generator:  0.7010015845298767     Loss_discriminator:  0.6899034976959229\n",
      "Epoch:  16     Batch:  20  /  468     Loss_generator:  0.7143634557723999     Loss_discriminator:  0.6780455112457275\n",
      "Epoch:  16     Batch:  21  /  468     Loss_generator:  0.7320319414138794     Loss_discriminator:  0.679297685623169\n",
      "Epoch:  16     Batch:  22  /  468     Loss_generator:  0.7335181832313538     Loss_discriminator:  0.6890972852706909\n",
      "Epoch:  16     Batch:  23  /  468     Loss_generator:  0.7132889032363892     Loss_discriminator:  0.6757999658584595\n",
      "Epoch:  16     Batch:  24  /  468     Loss_generator:  0.6822543740272522     Loss_discriminator:  0.6792950630187988\n",
      "Epoch:  16     Batch:  25  /  468     Loss_generator:  0.683100700378418     Loss_discriminator:  0.6946057081222534\n",
      "Epoch:  16     Batch:  26  /  468     Loss_generator:  0.7233073711395264     Loss_discriminator:  0.6895743608474731\n",
      "Epoch:  16     Batch:  27  /  468     Loss_generator:  0.7457818984985352     Loss_discriminator:  0.685573935508728\n",
      "Epoch:  16     Batch:  28  /  468     Loss_generator:  0.7595685720443726     Loss_discriminator:  0.6883888244628906\n",
      "Epoch:  16     Batch:  29  /  468     Loss_generator:  0.7424277067184448     Loss_discriminator:  0.6866477131843567\n",
      "Epoch:  16     Batch:  30  /  468     Loss_generator:  0.6871124505996704     Loss_discriminator:  0.6833623051643372\n",
      "Epoch:  16     Batch:  31  /  468     Loss_generator:  0.6604738831520081     Loss_discriminator:  0.6673901677131653\n",
      "Epoch:  16     Batch:  32  /  468     Loss_generator:  0.6557344198226929     Loss_discriminator:  0.7008780837059021\n",
      "Epoch:  16     Batch:  33  /  468     Loss_generator:  0.7025936841964722     Loss_discriminator:  0.6910296082496643\n",
      "Epoch:  16     Batch:  34  /  468     Loss_generator:  0.7244431972503662     Loss_discriminator:  0.6977059841156006\n",
      "Epoch:  16     Batch:  35  /  468     Loss_generator:  0.7753130793571472     Loss_discriminator:  0.6855810880661011\n",
      "Epoch:  16     Batch:  36  /  468     Loss_generator:  0.7745070457458496     Loss_discriminator:  0.681329071521759\n",
      "Epoch:  16     Batch:  37  /  468     Loss_generator:  0.7134349346160889     Loss_discriminator:  0.6740002632141113\n",
      "Epoch:  16     Batch:  38  /  468     Loss_generator:  0.6638298630714417     Loss_discriminator:  0.6831281781196594\n",
      "Epoch:  16     Batch:  39  /  468     Loss_generator:  0.662095308303833     Loss_discriminator:  0.6829919219017029\n",
      "Epoch:  16     Batch:  40  /  468     Loss_generator:  0.6872028112411499     Loss_discriminator:  0.6951152086257935\n",
      "Epoch:  16     Batch:  41  /  468     Loss_generator:  0.7395896911621094     Loss_discriminator:  0.6796489357948303\n",
      "Epoch:  16     Batch:  42  /  468     Loss_generator:  0.7764807939529419     Loss_discriminator:  0.6772565245628357\n",
      "Epoch:  16     Batch:  43  /  468     Loss_generator:  0.7465993165969849     Loss_discriminator:  0.6679965257644653\n",
      "Epoch:  16     Batch:  44  /  468     Loss_generator:  0.7190616130828857     Loss_discriminator:  0.6834244132041931\n",
      "Epoch:  16     Batch:  45  /  468     Loss_generator:  0.6688867807388306     Loss_discriminator:  0.6884071230888367\n",
      "Epoch:  16     Batch:  46  /  468     Loss_generator:  0.6613701581954956     Loss_discriminator:  0.6690059900283813\n",
      "Epoch:  16     Batch:  47  /  468     Loss_generator:  0.6802493333816528     Loss_discriminator:  0.6832900047302246\n",
      "Epoch:  16     Batch:  48  /  468     Loss_generator:  0.794918417930603     Loss_discriminator:  0.686432421207428\n",
      "Epoch:  16     Batch:  49  /  468     Loss_generator:  0.8143918514251709     Loss_discriminator:  0.6955321431159973\n",
      "Epoch:  16     Batch:  50  /  468     Loss_generator:  0.7604936957359314     Loss_discriminator:  0.6868851184844971\n",
      "Epoch:  16     Batch:  51  /  468     Loss_generator:  0.6687192916870117     Loss_discriminator:  0.6908352375030518\n",
      "Epoch:  16     Batch:  52  /  468     Loss_generator:  0.6501173973083496     Loss_discriminator:  0.6917521953582764\n",
      "Epoch:  16     Batch:  53  /  468     Loss_generator:  0.6726062297821045     Loss_discriminator:  0.6950304508209229\n",
      "Epoch:  16     Batch:  54  /  468     Loss_generator:  0.723931610584259     Loss_discriminator:  0.6938076019287109\n",
      "Epoch:  16     Batch:  55  /  468     Loss_generator:  0.7678976058959961     Loss_discriminator:  0.6826905012130737\n",
      "Epoch:  16     Batch:  56  /  468     Loss_generator:  0.7659010887145996     Loss_discriminator:  0.6815476417541504\n",
      "Epoch:  16     Batch:  57  /  468     Loss_generator:  0.7192803621292114     Loss_discriminator:  0.6964895129203796\n",
      "Epoch:  16     Batch:  58  /  468     Loss_generator:  0.6819979548454285     Loss_discriminator:  0.680700421333313\n",
      "Epoch:  16     Batch:  59  /  468     Loss_generator:  0.7058961391448975     Loss_discriminator:  0.6901815533638\n",
      "Epoch:  16     Batch:  60  /  468     Loss_generator:  0.7403016090393066     Loss_discriminator:  0.6857935786247253\n",
      "Epoch:  16     Batch:  61  /  468     Loss_generator:  0.7578843235969543     Loss_discriminator:  0.6856824159622192\n",
      "Epoch:  16     Batch:  62  /  468     Loss_generator:  0.7277104258537292     Loss_discriminator:  0.6787835359573364\n",
      "Epoch:  16     Batch:  63  /  468     Loss_generator:  0.6686312556266785     Loss_discriminator:  0.6770727634429932\n",
      "Epoch:  16     Batch:  64  /  468     Loss_generator:  0.63730788230896     Loss_discriminator:  0.6870744228363037\n",
      "Epoch:  16     Batch:  65  /  468     Loss_generator:  0.6605198383331299     Loss_discriminator:  0.6815573573112488\n",
      "Epoch:  16     Batch:  66  /  468     Loss_generator:  0.7600715160369873     Loss_discriminator:  0.6723251342773438\n",
      "Epoch:  16     Batch:  67  /  468     Loss_generator:  0.8316680788993835     Loss_discriminator:  0.6669775247573853\n",
      "Epoch:  16     Batch:  68  /  468     Loss_generator:  0.815279483795166     Loss_discriminator:  0.6831980347633362\n",
      "Epoch:  16     Batch:  69  /  468     Loss_generator:  0.7747575044631958     Loss_discriminator:  0.6851962804794312\n",
      "Epoch:  16     Batch:  70  /  468     Loss_generator:  0.6748644709587097     Loss_discriminator:  0.6837630271911621\n",
      "Epoch:  16     Batch:  71  /  468     Loss_generator:  0.6501016616821289     Loss_discriminator:  0.6709083318710327\n",
      "Epoch:  16     Batch:  72  /  468     Loss_generator:  0.6628360152244568     Loss_discriminator:  0.690364420413971\n",
      "Epoch:  16     Batch:  73  /  468     Loss_generator:  0.6941123604774475     Loss_discriminator:  0.6942641735076904\n",
      "Epoch:  16     Batch:  74  /  468     Loss_generator:  0.7248972058296204     Loss_discriminator:  0.6845042109489441\n",
      "Epoch:  16     Batch:  75  /  468     Loss_generator:  0.7158925533294678     Loss_discriminator:  0.6935738325119019\n",
      "Epoch:  16     Batch:  76  /  468     Loss_generator:  0.678360104560852     Loss_discriminator:  0.6819484233856201\n",
      "Epoch:  16     Batch:  77  /  468     Loss_generator:  0.7111881971359253     Loss_discriminator:  0.6830044984817505\n",
      "Epoch:  16     Batch:  78  /  468     Loss_generator:  0.6959466338157654     Loss_discriminator:  0.6976057291030884\n",
      "Epoch:  16     Batch:  79  /  468     Loss_generator:  0.7290287613868713     Loss_discriminator:  0.7053887248039246\n",
      "Epoch:  16     Batch:  80  /  468     Loss_generator:  0.7428981065750122     Loss_discriminator:  0.6773654222488403\n",
      "Epoch:  16     Batch:  81  /  468     Loss_generator:  0.7208131551742554     Loss_discriminator:  0.679796040058136\n",
      "Epoch:  16     Batch:  82  /  468     Loss_generator:  0.7067990303039551     Loss_discriminator:  0.6730327606201172\n",
      "Epoch:  16     Batch:  83  /  468     Loss_generator:  0.6905752420425415     Loss_discriminator:  0.6808393001556396\n",
      "Epoch:  16     Batch:  84  /  468     Loss_generator:  0.6884751915931702     Loss_discriminator:  0.6731082797050476\n",
      "Epoch:  16     Batch:  85  /  468     Loss_generator:  0.677356481552124     Loss_discriminator:  0.6786531209945679\n",
      "Epoch:  16     Batch:  86  /  468     Loss_generator:  0.6756539344787598     Loss_discriminator:  0.6859883666038513\n",
      "Epoch:  16     Batch:  87  /  468     Loss_generator:  0.7440232038497925     Loss_discriminator:  0.6860209703445435\n",
      "Epoch:  16     Batch:  88  /  468     Loss_generator:  0.7678130865097046     Loss_discriminator:  0.6880156993865967\n",
      "Epoch:  16     Batch:  89  /  468     Loss_generator:  0.734216570854187     Loss_discriminator:  0.6947475075721741\n",
      "Epoch:  16     Batch:  90  /  468     Loss_generator:  0.6991475224494934     Loss_discriminator:  0.6736143231391907\n",
      "Epoch:  16     Batch:  91  /  468     Loss_generator:  0.657106876373291     Loss_discriminator:  0.6854966878890991\n",
      "Epoch:  16     Batch:  92  /  468     Loss_generator:  0.655116617679596     Loss_discriminator:  0.6838028430938721\n",
      "Epoch:  16     Batch:  93  /  468     Loss_generator:  0.6652036905288696     Loss_discriminator:  0.6887136697769165\n",
      "Epoch:  16     Batch:  94  /  468     Loss_generator:  0.7098391652107239     Loss_discriminator:  0.6789028644561768\n",
      "Epoch:  16     Batch:  95  /  468     Loss_generator:  0.7606750726699829     Loss_discriminator:  0.6921427845954895\n",
      "Epoch:  16     Batch:  96  /  468     Loss_generator:  0.7794047594070435     Loss_discriminator:  0.685732901096344\n",
      "Epoch:  16     Batch:  97  /  468     Loss_generator:  0.7250798344612122     Loss_discriminator:  0.6777651309967041\n",
      "Epoch:  16     Batch:  98  /  468     Loss_generator:  0.7067039012908936     Loss_discriminator:  0.6924436688423157\n",
      "Epoch:  16     Batch:  99  /  468     Loss_generator:  0.7025884389877319     Loss_discriminator:  0.6998299956321716\n",
      "Epoch:  16     Batch:  100  /  468     Loss_generator:  0.7173404693603516     Loss_discriminator:  0.6930297613143921\n",
      "Epoch:  16     Batch:  101  /  468     Loss_generator:  0.72407066822052     Loss_discriminator:  0.6904393434524536\n",
      "Epoch:  16     Batch:  102  /  468     Loss_generator:  0.7331503629684448     Loss_discriminator:  0.6810736656188965\n",
      "Epoch:  16     Batch:  103  /  468     Loss_generator:  0.7093299627304077     Loss_discriminator:  0.6818603277206421\n",
      "Epoch:  16     Batch:  104  /  468     Loss_generator:  0.6694443821907043     Loss_discriminator:  0.6907364726066589\n",
      "Epoch:  16     Batch:  105  /  468     Loss_generator:  0.6567719578742981     Loss_discriminator:  0.6834969520568848\n",
      "Epoch:  16     Batch:  106  /  468     Loss_generator:  0.6872411370277405     Loss_discriminator:  0.704500675201416\n",
      "Epoch:  16     Batch:  107  /  468     Loss_generator:  0.7323372960090637     Loss_discriminator:  0.6809057593345642\n",
      "Epoch:  16     Batch:  108  /  468     Loss_generator:  0.7750276327133179     Loss_discriminator:  0.6900604963302612\n",
      "Epoch:  16     Batch:  109  /  468     Loss_generator:  0.8085577487945557     Loss_discriminator:  0.6868305206298828\n",
      "Epoch:  16     Batch:  110  /  468     Loss_generator:  0.7559282779693604     Loss_discriminator:  0.6838632822036743\n",
      "Epoch:  16     Batch:  111  /  468     Loss_generator:  0.6636643409729004     Loss_discriminator:  0.6885409355163574\n",
      "Epoch:  16     Batch:  112  /  468     Loss_generator:  0.6593579053878784     Loss_discriminator:  0.6772960424423218\n",
      "Epoch:  16     Batch:  113  /  468     Loss_generator:  0.6600241661071777     Loss_discriminator:  0.6779120564460754\n",
      "Epoch:  16     Batch:  114  /  468     Loss_generator:  0.6765291690826416     Loss_discriminator:  0.6962145566940308\n",
      "Epoch:  16     Batch:  115  /  468     Loss_generator:  0.7269641160964966     Loss_discriminator:  0.6870298981666565\n",
      "Epoch:  16     Batch:  116  /  468     Loss_generator:  0.7724159359931946     Loss_discriminator:  0.6826162934303284\n",
      "Epoch:  16     Batch:  117  /  468     Loss_generator:  0.7268924713134766     Loss_discriminator:  0.6879558563232422\n",
      "Epoch:  16     Batch:  118  /  468     Loss_generator:  0.695154070854187     Loss_discriminator:  0.6866849660873413\n",
      "Epoch:  16     Batch:  119  /  468     Loss_generator:  0.6683438420295715     Loss_discriminator:  0.6937689781188965\n",
      "Epoch:  16     Batch:  120  /  468     Loss_generator:  0.6741721630096436     Loss_discriminator:  0.6644426584243774\n",
      "Epoch:  16     Batch:  121  /  468     Loss_generator:  0.6991504430770874     Loss_discriminator:  0.6814390420913696\n",
      "Epoch:  16     Batch:  122  /  468     Loss_generator:  0.76042640209198     Loss_discriminator:  0.6828423738479614\n",
      "Epoch:  16     Batch:  123  /  468     Loss_generator:  0.79963219165802     Loss_discriminator:  0.683168888092041\n",
      "Epoch:  16     Batch:  124  /  468     Loss_generator:  0.7900840640068054     Loss_discriminator:  0.6902340650558472\n",
      "Epoch:  16     Batch:  125  /  468     Loss_generator:  0.7181326150894165     Loss_discriminator:  0.6764822006225586\n",
      "Epoch:  16     Batch:  126  /  468     Loss_generator:  0.6506080031394958     Loss_discriminator:  0.6776017546653748\n",
      "Epoch:  16     Batch:  127  /  468     Loss_generator:  0.632428765296936     Loss_discriminator:  0.6916104555130005\n",
      "Epoch:  16     Batch:  128  /  468     Loss_generator:  0.6770641803741455     Loss_discriminator:  0.6915924549102783\n",
      "Epoch:  16     Batch:  129  /  468     Loss_generator:  0.750070333480835     Loss_discriminator:  0.7017026543617249\n",
      "Epoch:  16     Batch:  130  /  468     Loss_generator:  0.7754658460617065     Loss_discriminator:  0.6776491403579712\n",
      "Epoch:  16     Batch:  131  /  468     Loss_generator:  0.7438872456550598     Loss_discriminator:  0.6766507625579834\n",
      "Epoch:  16     Batch:  132  /  468     Loss_generator:  0.7272350192070007     Loss_discriminator:  0.6957353353500366\n",
      "Epoch:  16     Batch:  133  /  468     Loss_generator:  0.691167950630188     Loss_discriminator:  0.6871318817138672\n",
      "Epoch:  16     Batch:  134  /  468     Loss_generator:  0.668304443359375     Loss_discriminator:  0.6821631789207458\n",
      "Epoch:  16     Batch:  135  /  468     Loss_generator:  0.6839675903320312     Loss_discriminator:  0.6834286451339722\n",
      "Epoch:  16     Batch:  136  /  468     Loss_generator:  0.7196459174156189     Loss_discriminator:  0.6704667210578918\n",
      "Epoch:  16     Batch:  137  /  468     Loss_generator:  0.7752984762191772     Loss_discriminator:  0.6839741468429565\n",
      "Epoch:  16     Batch:  138  /  468     Loss_generator:  0.7764307260513306     Loss_discriminator:  0.7034095525741577\n",
      "Epoch:  16     Batch:  139  /  468     Loss_generator:  0.7372057437896729     Loss_discriminator:  0.6822094321250916\n",
      "Epoch:  16     Batch:  140  /  468     Loss_generator:  0.6606994271278381     Loss_discriminator:  0.6911860108375549\n",
      "Epoch:  16     Batch:  141  /  468     Loss_generator:  0.6570498943328857     Loss_discriminator:  0.6696507930755615\n",
      "Epoch:  16     Batch:  142  /  468     Loss_generator:  0.6341105103492737     Loss_discriminator:  0.6832887530326843\n",
      "Epoch:  16     Batch:  143  /  468     Loss_generator:  0.6758860349655151     Loss_discriminator:  0.6854953765869141\n",
      "Epoch:  16     Batch:  144  /  468     Loss_generator:  0.7522761821746826     Loss_discriminator:  0.6820205450057983\n",
      "Epoch:  16     Batch:  145  /  468     Loss_generator:  0.8047522306442261     Loss_discriminator:  0.6916840076446533\n",
      "Epoch:  16     Batch:  146  /  468     Loss_generator:  0.7632415294647217     Loss_discriminator:  0.6863265037536621\n",
      "Epoch:  16     Batch:  147  /  468     Loss_generator:  0.6897944211959839     Loss_discriminator:  0.6695245504379272\n",
      "Epoch:  16     Batch:  148  /  468     Loss_generator:  0.6915470361709595     Loss_discriminator:  0.6798754930496216\n",
      "Epoch:  16     Batch:  149  /  468     Loss_generator:  0.6876675486564636     Loss_discriminator:  0.6859645843505859\n",
      "Epoch:  16     Batch:  150  /  468     Loss_generator:  0.7264788746833801     Loss_discriminator:  0.6730756759643555\n",
      "Epoch:  16     Batch:  151  /  468     Loss_generator:  0.7190488576889038     Loss_discriminator:  0.6811859607696533\n",
      "Epoch:  16     Batch:  152  /  468     Loss_generator:  0.6854254603385925     Loss_discriminator:  0.6886451244354248\n",
      "Epoch:  16     Batch:  153  /  468     Loss_generator:  0.6819534301757812     Loss_discriminator:  0.6776031851768494\n",
      "Epoch:  16     Batch:  154  /  468     Loss_generator:  0.7168815732002258     Loss_discriminator:  0.676493763923645\n",
      "Epoch:  16     Batch:  155  /  468     Loss_generator:  0.6984924674034119     Loss_discriminator:  0.680289626121521\n",
      "Epoch:  16     Batch:  156  /  468     Loss_generator:  0.6958413124084473     Loss_discriminator:  0.6741060018539429\n",
      "Epoch:  16     Batch:  157  /  468     Loss_generator:  0.6705098152160645     Loss_discriminator:  0.6872520446777344\n",
      "Epoch:  16     Batch:  158  /  468     Loss_generator:  0.6824201345443726     Loss_discriminator:  0.6959608197212219\n",
      "Epoch:  16     Batch:  159  /  468     Loss_generator:  0.7451793551445007     Loss_discriminator:  0.6933506727218628\n",
      "Epoch:  16     Batch:  160  /  468     Loss_generator:  0.7420580983161926     Loss_discriminator:  0.6795010566711426\n",
      "Epoch:  16     Batch:  161  /  468     Loss_generator:  0.7187053561210632     Loss_discriminator:  0.6826272010803223\n",
      "Epoch:  16     Batch:  162  /  468     Loss_generator:  0.7209700345993042     Loss_discriminator:  0.6901390552520752\n",
      "Epoch:  16     Batch:  163  /  468     Loss_generator:  0.7413777112960815     Loss_discriminator:  0.6724951267242432\n",
      "Epoch:  16     Batch:  164  /  468     Loss_generator:  0.6916089057922363     Loss_discriminator:  0.683186411857605\n",
      "Epoch:  16     Batch:  165  /  468     Loss_generator:  0.6953241229057312     Loss_discriminator:  0.6824735403060913\n",
      "Epoch:  16     Batch:  166  /  468     Loss_generator:  0.7075120806694031     Loss_discriminator:  0.6838130950927734\n",
      "Epoch:  16     Batch:  167  /  468     Loss_generator:  0.7322109341621399     Loss_discriminator:  0.6724543571472168\n",
      "Epoch:  16     Batch:  168  /  468     Loss_generator:  0.7018030285835266     Loss_discriminator:  0.6879910826683044\n",
      "Epoch:  16     Batch:  169  /  468     Loss_generator:  0.7202394604682922     Loss_discriminator:  0.6724379062652588\n",
      "Epoch:  16     Batch:  170  /  468     Loss_generator:  0.7051628232002258     Loss_discriminator:  0.6811412572860718\n",
      "Epoch:  16     Batch:  171  /  468     Loss_generator:  0.7276783585548401     Loss_discriminator:  0.6791850328445435\n",
      "Epoch:  16     Batch:  172  /  468     Loss_generator:  0.717875599861145     Loss_discriminator:  0.6838480830192566\n",
      "Epoch:  16     Batch:  173  /  468     Loss_generator:  0.7574262619018555     Loss_discriminator:  0.6804342865943909\n",
      "Epoch:  16     Batch:  174  /  468     Loss_generator:  0.7746310830116272     Loss_discriminator:  0.675766110420227\n",
      "Epoch:  16     Batch:  175  /  468     Loss_generator:  0.7321114540100098     Loss_discriminator:  0.6921793818473816\n",
      "Epoch:  16     Batch:  176  /  468     Loss_generator:  0.6650352478027344     Loss_discriminator:  0.6797069907188416\n",
      "Epoch:  16     Batch:  177  /  468     Loss_generator:  0.6617245078086853     Loss_discriminator:  0.6882361173629761\n",
      "Epoch:  16     Batch:  178  /  468     Loss_generator:  0.727270245552063     Loss_discriminator:  0.6838003396987915\n",
      "Epoch:  16     Batch:  179  /  468     Loss_generator:  0.7562840580940247     Loss_discriminator:  0.6924733519554138\n",
      "Epoch:  16     Batch:  180  /  468     Loss_generator:  0.758751630783081     Loss_discriminator:  0.6888634562492371\n",
      "Epoch:  16     Batch:  181  /  468     Loss_generator:  0.7148880362510681     Loss_discriminator:  0.6750439405441284\n",
      "Epoch:  16     Batch:  182  /  468     Loss_generator:  0.7045061588287354     Loss_discriminator:  0.6931008696556091\n",
      "Epoch:  16     Batch:  183  /  468     Loss_generator:  0.6956076622009277     Loss_discriminator:  0.6855928897857666\n",
      "Epoch:  16     Batch:  184  /  468     Loss_generator:  0.6735016107559204     Loss_discriminator:  0.7012728452682495\n",
      "Epoch:  16     Batch:  185  /  468     Loss_generator:  0.6857166886329651     Loss_discriminator:  0.684850811958313\n",
      "Epoch:  16     Batch:  186  /  468     Loss_generator:  0.6947208642959595     Loss_discriminator:  0.6845518350601196\n",
      "Epoch:  16     Batch:  187  /  468     Loss_generator:  0.717444121837616     Loss_discriminator:  0.681455671787262\n",
      "Epoch:  16     Batch:  188  /  468     Loss_generator:  0.7123366594314575     Loss_discriminator:  0.6832699775695801\n",
      "Epoch:  16     Batch:  189  /  468     Loss_generator:  0.7471325397491455     Loss_discriminator:  0.6941087245941162\n",
      "Epoch:  16     Batch:  190  /  468     Loss_generator:  0.7348026037216187     Loss_discriminator:  0.677714467048645\n",
      "Epoch:  16     Batch:  191  /  468     Loss_generator:  0.7084323763847351     Loss_discriminator:  0.6776589751243591\n",
      "Epoch:  16     Batch:  192  /  468     Loss_generator:  0.6768262386322021     Loss_discriminator:  0.6685909032821655\n",
      "Epoch:  16     Batch:  193  /  468     Loss_generator:  0.6854703426361084     Loss_discriminator:  0.6903797388076782\n",
      "Epoch:  16     Batch:  194  /  468     Loss_generator:  0.7140224575996399     Loss_discriminator:  0.6926999092102051\n",
      "Epoch:  16     Batch:  195  /  468     Loss_generator:  0.7274739742279053     Loss_discriminator:  0.6894948482513428\n",
      "Epoch:  16     Batch:  196  /  468     Loss_generator:  0.7342258095741272     Loss_discriminator:  0.6839338541030884\n",
      "Epoch:  16     Batch:  197  /  468     Loss_generator:  0.7182533144950867     Loss_discriminator:  0.6978652477264404\n",
      "Epoch:  16     Batch:  198  /  468     Loss_generator:  0.7172406911849976     Loss_discriminator:  0.6807469129562378\n",
      "Epoch:  16     Batch:  199  /  468     Loss_generator:  0.7150018811225891     Loss_discriminator:  0.6860778331756592\n",
      "Epoch:  16     Batch:  200  /  468     Loss_generator:  0.7202014923095703     Loss_discriminator:  0.6730409860610962\n",
      "Epoch:  16     Batch:  201  /  468     Loss_generator:  0.6939758658409119     Loss_discriminator:  0.6918147802352905\n",
      "Epoch:  16     Batch:  202  /  468     Loss_generator:  0.6765446066856384     Loss_discriminator:  0.672773003578186\n",
      "Epoch:  16     Batch:  203  /  468     Loss_generator:  0.6795011758804321     Loss_discriminator:  0.6723853349685669\n",
      "Epoch:  16     Batch:  204  /  468     Loss_generator:  0.7233289480209351     Loss_discriminator:  0.695420503616333\n",
      "Epoch:  16     Batch:  205  /  468     Loss_generator:  0.773021399974823     Loss_discriminator:  0.6864032745361328\n",
      "Epoch:  16     Batch:  206  /  468     Loss_generator:  0.7925251722335815     Loss_discriminator:  0.6994845867156982\n",
      "Epoch:  16     Batch:  207  /  468     Loss_generator:  0.704588770866394     Loss_discriminator:  0.6807588338851929\n",
      "Epoch:  16     Batch:  208  /  468     Loss_generator:  0.6686773300170898     Loss_discriminator:  0.684003472328186\n",
      "Epoch:  16     Batch:  209  /  468     Loss_generator:  0.6635891199111938     Loss_discriminator:  0.6969103217124939\n",
      "Epoch:  16     Batch:  210  /  468     Loss_generator:  0.7175955176353455     Loss_discriminator:  0.6815335750579834\n",
      "Epoch:  16     Batch:  211  /  468     Loss_generator:  0.7660382986068726     Loss_discriminator:  0.6758600473403931\n",
      "Epoch:  16     Batch:  212  /  468     Loss_generator:  0.72390216588974     Loss_discriminator:  0.6814864873886108\n",
      "Epoch:  16     Batch:  213  /  468     Loss_generator:  0.7002259492874146     Loss_discriminator:  0.682736337184906\n",
      "Epoch:  16     Batch:  214  /  468     Loss_generator:  0.6984398365020752     Loss_discriminator:  0.6748600006103516\n",
      "Epoch:  16     Batch:  215  /  468     Loss_generator:  0.7006295323371887     Loss_discriminator:  0.6859081983566284\n",
      "Epoch:  16     Batch:  216  /  468     Loss_generator:  0.7241487503051758     Loss_discriminator:  0.6832186579704285\n",
      "Epoch:  16     Batch:  217  /  468     Loss_generator:  0.7244231104850769     Loss_discriminator:  0.6947494745254517\n",
      "Epoch:  16     Batch:  218  /  468     Loss_generator:  0.7403386235237122     Loss_discriminator:  0.6752254962921143\n",
      "Epoch:  16     Batch:  219  /  468     Loss_generator:  0.7060176730155945     Loss_discriminator:  0.6951286792755127\n",
      "Epoch:  16     Batch:  220  /  468     Loss_generator:  0.6898801922798157     Loss_discriminator:  0.6771277785301208\n",
      "Epoch:  16     Batch:  221  /  468     Loss_generator:  0.6841964721679688     Loss_discriminator:  0.6809500455856323\n",
      "Epoch:  16     Batch:  222  /  468     Loss_generator:  0.7176568508148193     Loss_discriminator:  0.6891462206840515\n",
      "Epoch:  16     Batch:  223  /  468     Loss_generator:  0.7328916192054749     Loss_discriminator:  0.6871821880340576\n",
      "Epoch:  16     Batch:  224  /  468     Loss_generator:  0.7628088593482971     Loss_discriminator:  0.6935803294181824\n",
      "Epoch:  16     Batch:  225  /  468     Loss_generator:  0.7422933578491211     Loss_discriminator:  0.6811255216598511\n",
      "Epoch:  16     Batch:  226  /  468     Loss_generator:  0.7122730016708374     Loss_discriminator:  0.6925971508026123\n",
      "Epoch:  16     Batch:  227  /  468     Loss_generator:  0.6772792339324951     Loss_discriminator:  0.6881499290466309\n",
      "Epoch:  16     Batch:  228  /  468     Loss_generator:  0.6685530543327332     Loss_discriminator:  0.6850883960723877\n",
      "Epoch:  16     Batch:  229  /  468     Loss_generator:  0.6860882043838501     Loss_discriminator:  0.6858366131782532\n",
      "Epoch:  16     Batch:  230  /  468     Loss_generator:  0.696793258190155     Loss_discriminator:  0.6873645782470703\n",
      "Epoch:  16     Batch:  231  /  468     Loss_generator:  0.7354030013084412     Loss_discriminator:  0.6833552122116089\n",
      "Epoch:  16     Batch:  232  /  468     Loss_generator:  0.7504984140396118     Loss_discriminator:  0.7057421803474426\n",
      "Epoch:  16     Batch:  233  /  468     Loss_generator:  0.7565628290176392     Loss_discriminator:  0.6877115964889526\n",
      "Epoch:  16     Batch:  234  /  468     Loss_generator:  0.7213740944862366     Loss_discriminator:  0.6653071641921997\n",
      "Epoch:  16     Batch:  235  /  468     Loss_generator:  0.6848414540290833     Loss_discriminator:  0.6934797167778015\n",
      "Epoch:  16     Batch:  236  /  468     Loss_generator:  0.6830382347106934     Loss_discriminator:  0.6860114336013794\n",
      "Epoch:  16     Batch:  237  /  468     Loss_generator:  0.6880772113800049     Loss_discriminator:  0.6698036789894104\n",
      "Epoch:  16     Batch:  238  /  468     Loss_generator:  0.7314853072166443     Loss_discriminator:  0.6741278171539307\n",
      "Epoch:  16     Batch:  239  /  468     Loss_generator:  0.7368046641349792     Loss_discriminator:  0.6990581750869751\n",
      "Epoch:  16     Batch:  240  /  468     Loss_generator:  0.715002179145813     Loss_discriminator:  0.6863715052604675\n",
      "Epoch:  16     Batch:  241  /  468     Loss_generator:  0.7152688503265381     Loss_discriminator:  0.685163140296936\n",
      "Epoch:  16     Batch:  242  /  468     Loss_generator:  0.7051318883895874     Loss_discriminator:  0.686699390411377\n",
      "Epoch:  16     Batch:  243  /  468     Loss_generator:  0.7323417663574219     Loss_discriminator:  0.6818419098854065\n",
      "Epoch:  16     Batch:  244  /  468     Loss_generator:  0.7250046133995056     Loss_discriminator:  0.692542552947998\n",
      "Epoch:  16     Batch:  245  /  468     Loss_generator:  0.7184500694274902     Loss_discriminator:  0.6917505264282227\n",
      "Epoch:  16     Batch:  246  /  468     Loss_generator:  0.6777400970458984     Loss_discriminator:  0.6901228427886963\n",
      "Epoch:  16     Batch:  247  /  468     Loss_generator:  0.6859290599822998     Loss_discriminator:  0.6784883141517639\n",
      "Epoch:  16     Batch:  248  /  468     Loss_generator:  0.7386375665664673     Loss_discriminator:  0.693387508392334\n",
      "Epoch:  16     Batch:  249  /  468     Loss_generator:  0.7628084421157837     Loss_discriminator:  0.6965718269348145\n",
      "Epoch:  16     Batch:  250  /  468     Loss_generator:  0.7318786978721619     Loss_discriminator:  0.6897493004798889\n",
      "Epoch:  16     Batch:  251  /  468     Loss_generator:  0.6940524578094482     Loss_discriminator:  0.6910693049430847\n",
      "Epoch:  16     Batch:  252  /  468     Loss_generator:  0.6948336362838745     Loss_discriminator:  0.6746416687965393\n",
      "Epoch:  16     Batch:  253  /  468     Loss_generator:  0.701493501663208     Loss_discriminator:  0.6790454387664795\n",
      "Epoch:  16     Batch:  254  /  468     Loss_generator:  0.728466272354126     Loss_discriminator:  0.6899862885475159\n",
      "Epoch:  16     Batch:  255  /  468     Loss_generator:  0.7347797751426697     Loss_discriminator:  0.6842854619026184\n",
      "Epoch:  16     Batch:  256  /  468     Loss_generator:  0.717983067035675     Loss_discriminator:  0.6867790222167969\n",
      "Epoch:  16     Batch:  257  /  468     Loss_generator:  0.6850106120109558     Loss_discriminator:  0.6842317581176758\n",
      "Epoch:  16     Batch:  258  /  468     Loss_generator:  0.670443058013916     Loss_discriminator:  0.6940909624099731\n",
      "Epoch:  16     Batch:  259  /  468     Loss_generator:  0.6809322834014893     Loss_discriminator:  0.6816380620002747\n",
      "Epoch:  16     Batch:  260  /  468     Loss_generator:  0.7298575043678284     Loss_discriminator:  0.6997044086456299\n",
      "Epoch:  16     Batch:  261  /  468     Loss_generator:  0.7571067810058594     Loss_discriminator:  0.6727150082588196\n",
      "Epoch:  16     Batch:  262  /  468     Loss_generator:  0.7957082986831665     Loss_discriminator:  0.696457028388977\n",
      "Epoch:  16     Batch:  263  /  468     Loss_generator:  0.7620061635971069     Loss_discriminator:  0.6775799989700317\n",
      "Epoch:  16     Batch:  264  /  468     Loss_generator:  0.702373743057251     Loss_discriminator:  0.6909703016281128\n",
      "Epoch:  16     Batch:  265  /  468     Loss_generator:  0.6844874024391174     Loss_discriminator:  0.7026212215423584\n",
      "Epoch:  16     Batch:  266  /  468     Loss_generator:  0.6766417622566223     Loss_discriminator:  0.6762347221374512\n",
      "Epoch:  16     Batch:  267  /  468     Loss_generator:  0.700981080532074     Loss_discriminator:  0.6813656091690063\n",
      "Epoch:  16     Batch:  268  /  468     Loss_generator:  0.6980928778648376     Loss_discriminator:  0.6842302083969116\n",
      "Epoch:  16     Batch:  269  /  468     Loss_generator:  0.7082472443580627     Loss_discriminator:  0.6977989673614502\n",
      "Epoch:  16     Batch:  270  /  468     Loss_generator:  0.7119276523590088     Loss_discriminator:  0.6907824873924255\n",
      "Epoch:  16     Batch:  271  /  468     Loss_generator:  0.7242200374603271     Loss_discriminator:  0.6829401254653931\n",
      "Epoch:  16     Batch:  272  /  468     Loss_generator:  0.7546047568321228     Loss_discriminator:  0.6703739166259766\n",
      "Epoch:  16     Batch:  273  /  468     Loss_generator:  0.7773934006690979     Loss_discriminator:  0.6844177842140198\n",
      "Epoch:  16     Batch:  274  /  468     Loss_generator:  0.7690490484237671     Loss_discriminator:  0.6877529621124268\n",
      "Epoch:  16     Batch:  275  /  468     Loss_generator:  0.6985067129135132     Loss_discriminator:  0.6834230422973633\n",
      "Epoch:  16     Batch:  276  /  468     Loss_generator:  0.6678177118301392     Loss_discriminator:  0.690030574798584\n",
      "Epoch:  16     Batch:  277  /  468     Loss_generator:  0.6640114784240723     Loss_discriminator:  0.6866134405136108\n",
      "Epoch:  16     Batch:  278  /  468     Loss_generator:  0.730294406414032     Loss_discriminator:  0.6956205368041992\n",
      "Epoch:  16     Batch:  279  /  468     Loss_generator:  0.7452183961868286     Loss_discriminator:  0.6886764168739319\n",
      "Epoch:  16     Batch:  280  /  468     Loss_generator:  0.7675250768661499     Loss_discriminator:  0.684614360332489\n",
      "Epoch:  16     Batch:  281  /  468     Loss_generator:  0.7276373505592346     Loss_discriminator:  0.688143253326416\n",
      "Epoch:  16     Batch:  282  /  468     Loss_generator:  0.6906687021255493     Loss_discriminator:  0.6847118139266968\n",
      "Epoch:  16     Batch:  283  /  468     Loss_generator:  0.6782400608062744     Loss_discriminator:  0.682794451713562\n",
      "Epoch:  16     Batch:  284  /  468     Loss_generator:  0.6881883144378662     Loss_discriminator:  0.7027629613876343\n",
      "Epoch:  16     Batch:  285  /  468     Loss_generator:  0.7075438499450684     Loss_discriminator:  0.6855006217956543\n",
      "Epoch:  16     Batch:  286  /  468     Loss_generator:  0.7338172197341919     Loss_discriminator:  0.6686910390853882\n",
      "Epoch:  16     Batch:  287  /  468     Loss_generator:  0.732958197593689     Loss_discriminator:  0.6763081550598145\n",
      "Epoch:  16     Batch:  288  /  468     Loss_generator:  0.7532711029052734     Loss_discriminator:  0.6866188049316406\n",
      "Epoch:  16     Batch:  289  /  468     Loss_generator:  0.7245455980300903     Loss_discriminator:  0.6769792437553406\n",
      "Epoch:  16     Batch:  290  /  468     Loss_generator:  0.6937086582183838     Loss_discriminator:  0.6916134357452393\n",
      "Epoch:  16     Batch:  291  /  468     Loss_generator:  0.6910585165023804     Loss_discriminator:  0.6836456060409546\n",
      "Epoch:  16     Batch:  292  /  468     Loss_generator:  0.7001565098762512     Loss_discriminator:  0.6945319771766663\n",
      "Epoch:  16     Batch:  293  /  468     Loss_generator:  0.7411121129989624     Loss_discriminator:  0.672701895236969\n",
      "Epoch:  16     Batch:  294  /  468     Loss_generator:  0.7178636789321899     Loss_discriminator:  0.6981304883956909\n",
      "Epoch:  16     Batch:  295  /  468     Loss_generator:  0.7195475697517395     Loss_discriminator:  0.6788938045501709\n",
      "Epoch:  16     Batch:  296  /  468     Loss_generator:  0.7233944535255432     Loss_discriminator:  0.6868463754653931\n",
      "Epoch:  16     Batch:  297  /  468     Loss_generator:  0.7186335921287537     Loss_discriminator:  0.681543231010437\n",
      "Epoch:  16     Batch:  298  /  468     Loss_generator:  0.6957679986953735     Loss_discriminator:  0.678711473941803\n",
      "Epoch:  16     Batch:  299  /  468     Loss_generator:  0.7032179832458496     Loss_discriminator:  0.6990095973014832\n",
      "Epoch:  16     Batch:  300  /  468     Loss_generator:  0.712533175945282     Loss_discriminator:  0.6801230907440186\n",
      "Epoch:  16     Batch:  301  /  468     Loss_generator:  0.6943480372428894     Loss_discriminator:  0.6728848218917847\n",
      "Epoch:  16     Batch:  302  /  468     Loss_generator:  0.6965624690055847     Loss_discriminator:  0.6884945631027222\n",
      "Epoch:  16     Batch:  303  /  468     Loss_generator:  0.7142729163169861     Loss_discriminator:  0.6847907900810242\n",
      "Epoch:  16     Batch:  304  /  468     Loss_generator:  0.7259284853935242     Loss_discriminator:  0.6917597055435181\n",
      "Epoch:  16     Batch:  305  /  468     Loss_generator:  0.7068486213684082     Loss_discriminator:  0.6966229677200317\n",
      "Epoch:  16     Batch:  306  /  468     Loss_generator:  0.7221739292144775     Loss_discriminator:  0.7040213346481323\n",
      "Epoch:  16     Batch:  307  /  468     Loss_generator:  0.7167156338691711     Loss_discriminator:  0.6812594532966614\n",
      "Epoch:  16     Batch:  308  /  468     Loss_generator:  0.7235617637634277     Loss_discriminator:  0.6853734254837036\n",
      "Epoch:  16     Batch:  309  /  468     Loss_generator:  0.6935492157936096     Loss_discriminator:  0.6819522380828857\n",
      "Epoch:  16     Batch:  310  /  468     Loss_generator:  0.6957931518554688     Loss_discriminator:  0.688750147819519\n",
      "Epoch:  16     Batch:  311  /  468     Loss_generator:  0.7165074348449707     Loss_discriminator:  0.7022191882133484\n",
      "Epoch:  16     Batch:  312  /  468     Loss_generator:  0.7074300050735474     Loss_discriminator:  0.6900292634963989\n",
      "Epoch:  16     Batch:  313  /  468     Loss_generator:  0.7075957655906677     Loss_discriminator:  0.6905745267868042\n",
      "Epoch:  16     Batch:  314  /  468     Loss_generator:  0.7223963737487793     Loss_discriminator:  0.6911521553993225\n",
      "Epoch:  16     Batch:  315  /  468     Loss_generator:  0.6883920431137085     Loss_discriminator:  0.6850178241729736\n",
      "Epoch:  16     Batch:  316  /  468     Loss_generator:  0.7060940861701965     Loss_discriminator:  0.6769294738769531\n",
      "Epoch:  16     Batch:  317  /  468     Loss_generator:  0.7108813524246216     Loss_discriminator:  0.6985141038894653\n",
      "Epoch:  16     Batch:  318  /  468     Loss_generator:  0.6986981630325317     Loss_discriminator:  0.6825317144393921\n",
      "Epoch:  16     Batch:  319  /  468     Loss_generator:  0.725518524646759     Loss_discriminator:  0.6751818656921387\n",
      "Epoch:  16     Batch:  320  /  468     Loss_generator:  0.7149866819381714     Loss_discriminator:  0.6704729795455933\n",
      "Epoch:  16     Batch:  321  /  468     Loss_generator:  0.740496039390564     Loss_discriminator:  0.7031006813049316\n",
      "Epoch:  16     Batch:  322  /  468     Loss_generator:  0.7405968904495239     Loss_discriminator:  0.6719367504119873\n",
      "Epoch:  16     Batch:  323  /  468     Loss_generator:  0.7516343593597412     Loss_discriminator:  0.6811927556991577\n",
      "Epoch:  16     Batch:  324  /  468     Loss_generator:  0.7027882933616638     Loss_discriminator:  0.6905611157417297\n",
      "Epoch:  16     Batch:  325  /  468     Loss_generator:  0.7010705471038818     Loss_discriminator:  0.6815564632415771\n",
      "Epoch:  16     Batch:  326  /  468     Loss_generator:  0.70326167345047     Loss_discriminator:  0.6762650012969971\n",
      "Epoch:  16     Batch:  327  /  468     Loss_generator:  0.722379207611084     Loss_discriminator:  0.695855975151062\n",
      "Epoch:  16     Batch:  328  /  468     Loss_generator:  0.7256412506103516     Loss_discriminator:  0.6928033232688904\n",
      "Epoch:  16     Batch:  329  /  468     Loss_generator:  0.7020573019981384     Loss_discriminator:  0.6820957064628601\n",
      "Epoch:  16     Batch:  330  /  468     Loss_generator:  0.6741033792495728     Loss_discriminator:  0.6881457567214966\n",
      "Epoch:  16     Batch:  331  /  468     Loss_generator:  0.6748552322387695     Loss_discriminator:  0.681691586971283\n",
      "Epoch:  16     Batch:  332  /  468     Loss_generator:  0.7264679074287415     Loss_discriminator:  0.6874939799308777\n",
      "Epoch:  16     Batch:  333  /  468     Loss_generator:  0.7635725736618042     Loss_discriminator:  0.6824570894241333\n",
      "Epoch:  16     Batch:  334  /  468     Loss_generator:  0.7440539002418518     Loss_discriminator:  0.6754783391952515\n",
      "Epoch:  16     Batch:  335  /  468     Loss_generator:  0.7115938663482666     Loss_discriminator:  0.6875843405723572\n",
      "Epoch:  16     Batch:  336  /  468     Loss_generator:  0.6681735515594482     Loss_discriminator:  0.6927412152290344\n",
      "Epoch:  16     Batch:  337  /  468     Loss_generator:  0.6771906614303589     Loss_discriminator:  0.6855212450027466\n",
      "Epoch:  16     Batch:  338  /  468     Loss_generator:  0.7665481567382812     Loss_discriminator:  0.6757249236106873\n",
      "Epoch:  16     Batch:  339  /  468     Loss_generator:  0.7514210939407349     Loss_discriminator:  0.6782922744750977\n",
      "Epoch:  16     Batch:  340  /  468     Loss_generator:  0.7170753479003906     Loss_discriminator:  0.6905595064163208\n",
      "Epoch:  16     Batch:  341  /  468     Loss_generator:  0.6864923238754272     Loss_discriminator:  0.694575309753418\n",
      "Epoch:  16     Batch:  342  /  468     Loss_generator:  0.6703329086303711     Loss_discriminator:  0.6925286054611206\n",
      "Epoch:  16     Batch:  343  /  468     Loss_generator:  0.6548836827278137     Loss_discriminator:  0.6818607449531555\n",
      "Epoch:  16     Batch:  344  /  468     Loss_generator:  0.6974406838417053     Loss_discriminator:  0.6747146844863892\n",
      "Epoch:  16     Batch:  345  /  468     Loss_generator:  0.7436717748641968     Loss_discriminator:  0.6822265982627869\n",
      "Epoch:  16     Batch:  346  /  468     Loss_generator:  0.7694414854049683     Loss_discriminator:  0.6834089756011963\n",
      "Epoch:  16     Batch:  347  /  468     Loss_generator:  0.7542194128036499     Loss_discriminator:  0.6827848553657532\n",
      "Epoch:  16     Batch:  348  /  468     Loss_generator:  0.7076661586761475     Loss_discriminator:  0.6909466981887817\n",
      "Epoch:  16     Batch:  349  /  468     Loss_generator:  0.6549511551856995     Loss_discriminator:  0.6997634172439575\n",
      "Epoch:  16     Batch:  350  /  468     Loss_generator:  0.6816695928573608     Loss_discriminator:  0.6956357359886169\n",
      "Epoch:  16     Batch:  351  /  468     Loss_generator:  0.7168256640434265     Loss_discriminator:  0.6960150003433228\n",
      "Epoch:  16     Batch:  352  /  468     Loss_generator:  0.7079439759254456     Loss_discriminator:  0.6889066696166992\n",
      "Epoch:  16     Batch:  353  /  468     Loss_generator:  0.7170957922935486     Loss_discriminator:  0.6705783605575562\n",
      "Epoch:  16     Batch:  354  /  468     Loss_generator:  0.6888583898544312     Loss_discriminator:  0.6744842529296875\n",
      "Epoch:  16     Batch:  355  /  468     Loss_generator:  0.6584641933441162     Loss_discriminator:  0.689197838306427\n",
      "Epoch:  16     Batch:  356  /  468     Loss_generator:  0.7137795686721802     Loss_discriminator:  0.6760061383247375\n",
      "Epoch:  16     Batch:  357  /  468     Loss_generator:  0.7753287553787231     Loss_discriminator:  0.6808955669403076\n",
      "Epoch:  16     Batch:  358  /  468     Loss_generator:  0.78258216381073     Loss_discriminator:  0.6901084184646606\n",
      "Epoch:  16     Batch:  359  /  468     Loss_generator:  0.7439035177230835     Loss_discriminator:  0.6796483397483826\n",
      "Epoch:  16     Batch:  360  /  468     Loss_generator:  0.7402119636535645     Loss_discriminator:  0.6939409971237183\n",
      "Epoch:  16     Batch:  361  /  468     Loss_generator:  0.721911609172821     Loss_discriminator:  0.6863458156585693\n",
      "Epoch:  16     Batch:  362  /  468     Loss_generator:  0.6836235523223877     Loss_discriminator:  0.6781383752822876\n",
      "Epoch:  16     Batch:  363  /  468     Loss_generator:  0.6668959259986877     Loss_discriminator:  0.6864719390869141\n",
      "Epoch:  16     Batch:  364  /  468     Loss_generator:  0.6567496657371521     Loss_discriminator:  0.694129228591919\n",
      "Epoch:  16     Batch:  365  /  468     Loss_generator:  0.694505512714386     Loss_discriminator:  0.6968029141426086\n",
      "Epoch:  16     Batch:  366  /  468     Loss_generator:  0.7205727696418762     Loss_discriminator:  0.686827540397644\n",
      "Epoch:  16     Batch:  367  /  468     Loss_generator:  0.695438027381897     Loss_discriminator:  0.6856774091720581\n",
      "Epoch:  16     Batch:  368  /  468     Loss_generator:  0.7171947360038757     Loss_discriminator:  0.6901261806488037\n",
      "Epoch:  16     Batch:  369  /  468     Loss_generator:  0.7195266485214233     Loss_discriminator:  0.6713987588882446\n",
      "Epoch:  16     Batch:  370  /  468     Loss_generator:  0.7226146459579468     Loss_discriminator:  0.6931799650192261\n",
      "Epoch:  16     Batch:  371  /  468     Loss_generator:  0.7429782748222351     Loss_discriminator:  0.6878534555435181\n",
      "Epoch:  16     Batch:  372  /  468     Loss_generator:  0.7271837592124939     Loss_discriminator:  0.6825562715530396\n",
      "Epoch:  16     Batch:  373  /  468     Loss_generator:  0.7198302745819092     Loss_discriminator:  0.6825741529464722\n",
      "Epoch:  16     Batch:  374  /  468     Loss_generator:  0.6883336305618286     Loss_discriminator:  0.6803750395774841\n",
      "Epoch:  16     Batch:  375  /  468     Loss_generator:  0.7099759578704834     Loss_discriminator:  0.6849683523178101\n",
      "Epoch:  16     Batch:  376  /  468     Loss_generator:  0.7549679279327393     Loss_discriminator:  0.6796578168869019\n",
      "Epoch:  16     Batch:  377  /  468     Loss_generator:  0.7510762810707092     Loss_discriminator:  0.6846522092819214\n",
      "Epoch:  16     Batch:  378  /  468     Loss_generator:  0.7103934288024902     Loss_discriminator:  0.6867154836654663\n",
      "Epoch:  16     Batch:  379  /  468     Loss_generator:  0.6475141048431396     Loss_discriminator:  0.683846116065979\n",
      "Epoch:  16     Batch:  380  /  468     Loss_generator:  0.6650059223175049     Loss_discriminator:  0.688147783279419\n",
      "Epoch:  16     Batch:  381  /  468     Loss_generator:  0.7040485143661499     Loss_discriminator:  0.6771146059036255\n",
      "Epoch:  16     Batch:  382  /  468     Loss_generator:  0.7796828150749207     Loss_discriminator:  0.6915029883384705\n",
      "Epoch:  16     Batch:  383  /  468     Loss_generator:  0.8159612417221069     Loss_discriminator:  0.6913736462593079\n",
      "Epoch:  16     Batch:  384  /  468     Loss_generator:  0.7477744817733765     Loss_discriminator:  0.7030033469200134\n",
      "Epoch:  16     Batch:  385  /  468     Loss_generator:  0.659428596496582     Loss_discriminator:  0.6873483657836914\n",
      "Epoch:  16     Batch:  386  /  468     Loss_generator:  0.6173999309539795     Loss_discriminator:  0.6880046725273132\n",
      "Epoch:  16     Batch:  387  /  468     Loss_generator:  0.6383436322212219     Loss_discriminator:  0.6938262581825256\n",
      "Epoch:  16     Batch:  388  /  468     Loss_generator:  0.682780385017395     Loss_discriminator:  0.6973764300346375\n",
      "Epoch:  16     Batch:  389  /  468     Loss_generator:  0.795516848564148     Loss_discriminator:  0.6867314577102661\n",
      "Epoch:  16     Batch:  390  /  468     Loss_generator:  0.8777521848678589     Loss_discriminator:  0.6830445528030396\n",
      "Epoch:  16     Batch:  391  /  468     Loss_generator:  0.7980196475982666     Loss_discriminator:  0.6941589117050171\n",
      "Epoch:  16     Batch:  392  /  468     Loss_generator:  0.7287637591362     Loss_discriminator:  0.6925562024116516\n",
      "Epoch:  16     Batch:  393  /  468     Loss_generator:  0.6486150622367859     Loss_discriminator:  0.6905161142349243\n",
      "Epoch:  16     Batch:  394  /  468     Loss_generator:  0.6294654607772827     Loss_discriminator:  0.6965452432632446\n",
      "Epoch:  16     Batch:  395  /  468     Loss_generator:  0.6447275876998901     Loss_discriminator:  0.6764570474624634\n",
      "Epoch:  16     Batch:  396  /  468     Loss_generator:  0.6677138805389404     Loss_discriminator:  0.7023232579231262\n",
      "Epoch:  16     Batch:  397  /  468     Loss_generator:  0.7422154545783997     Loss_discriminator:  0.6843737363815308\n",
      "Epoch:  16     Batch:  398  /  468     Loss_generator:  0.7686131000518799     Loss_discriminator:  0.6871089935302734\n",
      "Epoch:  16     Batch:  399  /  468     Loss_generator:  0.737576961517334     Loss_discriminator:  0.6799203753471375\n",
      "Epoch:  16     Batch:  400  /  468     Loss_generator:  0.6957322955131531     Loss_discriminator:  0.6865639686584473\n",
      "Epoch:  16     Batch:  401  /  468     Loss_generator:  0.7062633037567139     Loss_discriminator:  0.6915141344070435\n",
      "Epoch:  16     Batch:  402  /  468     Loss_generator:  0.7049261331558228     Loss_discriminator:  0.6870419979095459\n",
      "Epoch:  16     Batch:  403  /  468     Loss_generator:  0.7295018434524536     Loss_discriminator:  0.6546192169189453\n",
      "Epoch:  16     Batch:  404  /  468     Loss_generator:  0.737565815448761     Loss_discriminator:  0.6866695284843445\n",
      "Epoch:  16     Batch:  405  /  468     Loss_generator:  0.7193235158920288     Loss_discriminator:  0.6936614513397217\n",
      "Epoch:  16     Batch:  406  /  468     Loss_generator:  0.6868923306465149     Loss_discriminator:  0.6855652332305908\n",
      "Epoch:  16     Batch:  407  /  468     Loss_generator:  0.7257978320121765     Loss_discriminator:  0.6830582618713379\n",
      "Epoch:  16     Batch:  408  /  468     Loss_generator:  0.7409842610359192     Loss_discriminator:  0.6789180636405945\n",
      "Epoch:  16     Batch:  409  /  468     Loss_generator:  0.7428489923477173     Loss_discriminator:  0.681097686290741\n",
      "Epoch:  16     Batch:  410  /  468     Loss_generator:  0.7344692349433899     Loss_discriminator:  0.689893364906311\n",
      "Epoch:  16     Batch:  411  /  468     Loss_generator:  0.682049036026001     Loss_discriminator:  0.6883186101913452\n",
      "Epoch:  16     Batch:  412  /  468     Loss_generator:  0.6637041568756104     Loss_discriminator:  0.6909470558166504\n",
      "Epoch:  16     Batch:  413  /  468     Loss_generator:  0.6970735788345337     Loss_discriminator:  0.6934292316436768\n",
      "Epoch:  16     Batch:  414  /  468     Loss_generator:  0.7356461882591248     Loss_discriminator:  0.6854075193405151\n",
      "Epoch:  16     Batch:  415  /  468     Loss_generator:  0.7283974289894104     Loss_discriminator:  0.6935663819313049\n",
      "Epoch:  16     Batch:  416  /  468     Loss_generator:  0.7342925071716309     Loss_discriminator:  0.6747718453407288\n",
      "Epoch:  16     Batch:  417  /  468     Loss_generator:  0.7185783982276917     Loss_discriminator:  0.692541241645813\n",
      "Epoch:  16     Batch:  418  /  468     Loss_generator:  0.7025488615036011     Loss_discriminator:  0.685683012008667\n",
      "Epoch:  16     Batch:  419  /  468     Loss_generator:  0.7118443250656128     Loss_discriminator:  0.6869227886199951\n",
      "Epoch:  16     Batch:  420  /  468     Loss_generator:  0.7598235607147217     Loss_discriminator:  0.6774883270263672\n",
      "Epoch:  16     Batch:  421  /  468     Loss_generator:  0.7025237679481506     Loss_discriminator:  0.6838446259498596\n",
      "Epoch:  16     Batch:  422  /  468     Loss_generator:  0.6941519975662231     Loss_discriminator:  0.675055980682373\n",
      "Epoch:  16     Batch:  423  /  468     Loss_generator:  0.6909477710723877     Loss_discriminator:  0.6750167012214661\n",
      "Epoch:  16     Batch:  424  /  468     Loss_generator:  0.7677671313285828     Loss_discriminator:  0.6858590841293335\n",
      "Epoch:  16     Batch:  425  /  468     Loss_generator:  0.7533303499221802     Loss_discriminator:  0.6826496124267578\n",
      "Epoch:  16     Batch:  426  /  468     Loss_generator:  0.736066460609436     Loss_discriminator:  0.6866466403007507\n",
      "Epoch:  16     Batch:  427  /  468     Loss_generator:  0.7221843004226685     Loss_discriminator:  0.6701533794403076\n",
      "Epoch:  16     Batch:  428  /  468     Loss_generator:  0.6742797493934631     Loss_discriminator:  0.6833410859107971\n",
      "Epoch:  16     Batch:  429  /  468     Loss_generator:  0.6676586270332336     Loss_discriminator:  0.6693071722984314\n",
      "Epoch:  16     Batch:  430  /  468     Loss_generator:  0.6905444264411926     Loss_discriminator:  0.6903901100158691\n",
      "Epoch:  16     Batch:  431  /  468     Loss_generator:  0.702926754951477     Loss_discriminator:  0.6827667355537415\n",
      "Epoch:  16     Batch:  432  /  468     Loss_generator:  0.7024165987968445     Loss_discriminator:  0.673904538154602\n",
      "Epoch:  16     Batch:  433  /  468     Loss_generator:  0.6904827952384949     Loss_discriminator:  0.6864137053489685\n",
      "Epoch:  16     Batch:  434  /  468     Loss_generator:  0.6891257762908936     Loss_discriminator:  0.676915168762207\n",
      "Epoch:  16     Batch:  435  /  468     Loss_generator:  0.6900323629379272     Loss_discriminator:  0.6924155354499817\n",
      "Epoch:  16     Batch:  436  /  468     Loss_generator:  0.7458900809288025     Loss_discriminator:  0.6790708303451538\n",
      "Epoch:  16     Batch:  437  /  468     Loss_generator:  0.764794647693634     Loss_discriminator:  0.6942789554595947\n",
      "Epoch:  16     Batch:  438  /  468     Loss_generator:  0.7391502857208252     Loss_discriminator:  0.682583749294281\n",
      "Epoch:  16     Batch:  439  /  468     Loss_generator:  0.6957283020019531     Loss_discriminator:  0.6759490966796875\n",
      "Epoch:  16     Batch:  440  /  468     Loss_generator:  0.6761800050735474     Loss_discriminator:  0.6928962469100952\n",
      "Epoch:  16     Batch:  441  /  468     Loss_generator:  0.7028006911277771     Loss_discriminator:  0.6900249719619751\n",
      "Epoch:  16     Batch:  442  /  468     Loss_generator:  0.7377710342407227     Loss_discriminator:  0.6834291219711304\n",
      "Epoch:  16     Batch:  443  /  468     Loss_generator:  0.7292710542678833     Loss_discriminator:  0.6854428052902222\n",
      "Epoch:  16     Batch:  444  /  468     Loss_generator:  0.7067786455154419     Loss_discriminator:  0.6769394874572754\n",
      "Epoch:  16     Batch:  445  /  468     Loss_generator:  0.7206746935844421     Loss_discriminator:  0.6981062293052673\n",
      "Epoch:  16     Batch:  446  /  468     Loss_generator:  0.6768520474433899     Loss_discriminator:  0.6769770383834839\n",
      "Epoch:  16     Batch:  447  /  468     Loss_generator:  0.6290074586868286     Loss_discriminator:  0.689435601234436\n",
      "Epoch:  16     Batch:  448  /  468     Loss_generator:  0.7174276113510132     Loss_discriminator:  0.6917370557785034\n",
      "Epoch:  16     Batch:  449  /  468     Loss_generator:  0.7614737749099731     Loss_discriminator:  0.6750658750534058\n",
      "Epoch:  16     Batch:  450  /  468     Loss_generator:  0.7536183595657349     Loss_discriminator:  0.6718856692314148\n",
      "Epoch:  16     Batch:  451  /  468     Loss_generator:  0.7423568964004517     Loss_discriminator:  0.6828490495681763\n",
      "Epoch:  16     Batch:  452  /  468     Loss_generator:  0.6712508201599121     Loss_discriminator:  0.6931227445602417\n",
      "Epoch:  16     Batch:  453  /  468     Loss_generator:  0.672370195388794     Loss_discriminator:  0.6824659109115601\n",
      "Epoch:  16     Batch:  454  /  468     Loss_generator:  0.6674253940582275     Loss_discriminator:  0.6897342801094055\n",
      "Epoch:  16     Batch:  455  /  468     Loss_generator:  0.6907147169113159     Loss_discriminator:  0.6863857507705688\n",
      "Epoch:  16     Batch:  456  /  468     Loss_generator:  0.7294728755950928     Loss_discriminator:  0.6842738389968872\n",
      "Epoch:  16     Batch:  457  /  468     Loss_generator:  0.748053789138794     Loss_discriminator:  0.6818252205848694\n",
      "Epoch:  16     Batch:  458  /  468     Loss_generator:  0.7631385922431946     Loss_discriminator:  0.6858825087547302\n",
      "Epoch:  16     Batch:  459  /  468     Loss_generator:  0.696483850479126     Loss_discriminator:  0.6953402757644653\n",
      "Epoch:  16     Batch:  460  /  468     Loss_generator:  0.6816185116767883     Loss_discriminator:  0.6761407852172852\n",
      "Epoch:  16     Batch:  461  /  468     Loss_generator:  0.6883723735809326     Loss_discriminator:  0.6639790534973145\n",
      "Epoch:  16     Batch:  462  /  468     Loss_generator:  0.6982367634773254     Loss_discriminator:  0.6858890652656555\n",
      "Epoch:  16     Batch:  463  /  468     Loss_generator:  0.7181922197341919     Loss_discriminator:  0.6788384914398193\n",
      "Epoch:  16     Batch:  464  /  468     Loss_generator:  0.7304311394691467     Loss_discriminator:  0.6880509853363037\n",
      "Epoch:  16     Batch:  465  /  468     Loss_generator:  0.7308515310287476     Loss_discriminator:  0.6969872713088989\n",
      "Epoch:  16     Batch:  466  /  468     Loss_generator:  0.7148630619049072     Loss_discriminator:  0.6967938542366028\n",
      "Epoch:  16     Batch:  467  /  468     Loss_generator:  0.7273821830749512     Loss_discriminator:  0.6866621971130371\n",
      "Epoch:  17     Batch:  0  /  468     Loss_generator:  0.6995932459831238     Loss_discriminator:  0.6835663318634033\n",
      "Epoch:  17     Batch:  1  /  468     Loss_generator:  0.7071300148963928     Loss_discriminator:  0.688242495059967\n",
      "Epoch:  17     Batch:  2  /  468     Loss_generator:  0.7000070810317993     Loss_discriminator:  0.6943458318710327\n",
      "Epoch:  17     Batch:  3  /  468     Loss_generator:  0.6866423487663269     Loss_discriminator:  0.6710855960845947\n",
      "Epoch:  17     Batch:  4  /  468     Loss_generator:  0.7032638192176819     Loss_discriminator:  0.6843125224113464\n",
      "Epoch:  17     Batch:  5  /  468     Loss_generator:  0.6852822303771973     Loss_discriminator:  0.676506519317627\n",
      "Epoch:  17     Batch:  6  /  468     Loss_generator:  0.7132976651191711     Loss_discriminator:  0.6961858868598938\n",
      "Epoch:  17     Batch:  7  /  468     Loss_generator:  0.733741283416748     Loss_discriminator:  0.706813633441925\n",
      "Epoch:  17     Batch:  8  /  468     Loss_generator:  0.7704700827598572     Loss_discriminator:  0.6803680658340454\n",
      "Epoch:  17     Batch:  9  /  468     Loss_generator:  0.7630050778388977     Loss_discriminator:  0.6897783875465393\n",
      "Epoch:  17     Batch:  10  /  468     Loss_generator:  0.718695342540741     Loss_discriminator:  0.6849514245986938\n",
      "Epoch:  17     Batch:  11  /  468     Loss_generator:  0.6878011226654053     Loss_discriminator:  0.7056400179862976\n",
      "Epoch:  17     Batch:  12  /  468     Loss_generator:  0.663056492805481     Loss_discriminator:  0.6755983829498291\n",
      "Epoch:  17     Batch:  13  /  468     Loss_generator:  0.6696726083755493     Loss_discriminator:  0.6741354465484619\n",
      "Epoch:  17     Batch:  14  /  468     Loss_generator:  0.6862760782241821     Loss_discriminator:  0.680263876914978\n",
      "Epoch:  17     Batch:  15  /  468     Loss_generator:  0.7175206542015076     Loss_discriminator:  0.7002304792404175\n",
      "Epoch:  17     Batch:  16  /  468     Loss_generator:  0.7229368686676025     Loss_discriminator:  0.6741077899932861\n",
      "Epoch:  17     Batch:  17  /  468     Loss_generator:  0.7089254856109619     Loss_discriminator:  0.689453125\n",
      "Epoch:  17     Batch:  18  /  468     Loss_generator:  0.6787804365158081     Loss_discriminator:  0.6899250745773315\n",
      "Epoch:  17     Batch:  19  /  468     Loss_generator:  0.708344578742981     Loss_discriminator:  0.6927456259727478\n",
      "Epoch:  17     Batch:  20  /  468     Loss_generator:  0.7054041028022766     Loss_discriminator:  0.6996279954910278\n",
      "Epoch:  17     Batch:  21  /  468     Loss_generator:  0.7233595848083496     Loss_discriminator:  0.6730051040649414\n",
      "Epoch:  17     Batch:  22  /  468     Loss_generator:  0.7152569890022278     Loss_discriminator:  0.66510409116745\n",
      "Epoch:  17     Batch:  23  /  468     Loss_generator:  0.7247718572616577     Loss_discriminator:  0.6884256601333618\n",
      "Epoch:  17     Batch:  24  /  468     Loss_generator:  0.694736897945404     Loss_discriminator:  0.6918545365333557\n",
      "Epoch:  17     Batch:  25  /  468     Loss_generator:  0.686418354511261     Loss_discriminator:  0.6828886270523071\n",
      "Epoch:  17     Batch:  26  /  468     Loss_generator:  0.7054886817932129     Loss_discriminator:  0.6912341117858887\n",
      "Epoch:  17     Batch:  27  /  468     Loss_generator:  0.7359306216239929     Loss_discriminator:  0.6774992942810059\n",
      "Epoch:  17     Batch:  28  /  468     Loss_generator:  0.7120680809020996     Loss_discriminator:  0.6820377111434937\n",
      "Epoch:  17     Batch:  29  /  468     Loss_generator:  0.720946192741394     Loss_discriminator:  0.6909211874008179\n",
      "Epoch:  17     Batch:  30  /  468     Loss_generator:  0.6967713832855225     Loss_discriminator:  0.6928297877311707\n",
      "Epoch:  17     Batch:  31  /  468     Loss_generator:  0.7080346345901489     Loss_discriminator:  0.6852667927742004\n",
      "Epoch:  17     Batch:  32  /  468     Loss_generator:  0.6853718757629395     Loss_discriminator:  0.6934374570846558\n",
      "Epoch:  17     Batch:  33  /  468     Loss_generator:  0.7146258354187012     Loss_discriminator:  0.6737727522850037\n",
      "Epoch:  17     Batch:  34  /  468     Loss_generator:  0.7554235458374023     Loss_discriminator:  0.7031278014183044\n",
      "Epoch:  17     Batch:  35  /  468     Loss_generator:  0.7582334280014038     Loss_discriminator:  0.6751124858856201\n",
      "Epoch:  17     Batch:  36  /  468     Loss_generator:  0.6899120807647705     Loss_discriminator:  0.6864794492721558\n",
      "Epoch:  17     Batch:  37  /  468     Loss_generator:  0.6905562877655029     Loss_discriminator:  0.6877353191375732\n",
      "Epoch:  17     Batch:  38  /  468     Loss_generator:  0.7071729898452759     Loss_discriminator:  0.6830881834030151\n",
      "Epoch:  17     Batch:  39  /  468     Loss_generator:  0.6987961530685425     Loss_discriminator:  0.6879019737243652\n",
      "Epoch:  17     Batch:  40  /  468     Loss_generator:  0.6937110424041748     Loss_discriminator:  0.6803945302963257\n",
      "Epoch:  17     Batch:  41  /  468     Loss_generator:  0.7088671922683716     Loss_discriminator:  0.678585410118103\n",
      "Epoch:  17     Batch:  42  /  468     Loss_generator:  0.7091360092163086     Loss_discriminator:  0.671815037727356\n",
      "Epoch:  17     Batch:  43  /  468     Loss_generator:  0.6880784034729004     Loss_discriminator:  0.6790223121643066\n",
      "Epoch:  17     Batch:  44  /  468     Loss_generator:  0.677553653717041     Loss_discriminator:  0.6819838285446167\n",
      "Epoch:  17     Batch:  45  /  468     Loss_generator:  0.7004097104072571     Loss_discriminator:  0.6741939783096313\n",
      "Epoch:  17     Batch:  46  /  468     Loss_generator:  0.7356224060058594     Loss_discriminator:  0.6849554777145386\n",
      "Epoch:  17     Batch:  47  /  468     Loss_generator:  0.7524011135101318     Loss_discriminator:  0.6902045011520386\n",
      "Epoch:  17     Batch:  48  /  468     Loss_generator:  0.7366852760314941     Loss_discriminator:  0.6777478456497192\n",
      "Epoch:  17     Batch:  49  /  468     Loss_generator:  0.7261630296707153     Loss_discriminator:  0.686102569103241\n",
      "Epoch:  17     Batch:  50  /  468     Loss_generator:  0.6836665868759155     Loss_discriminator:  0.696042537689209\n",
      "Epoch:  17     Batch:  51  /  468     Loss_generator:  0.6913677453994751     Loss_discriminator:  0.6893172264099121\n",
      "Epoch:  17     Batch:  52  /  468     Loss_generator:  0.7174068689346313     Loss_discriminator:  0.686939537525177\n",
      "Epoch:  17     Batch:  53  /  468     Loss_generator:  0.7372307181358337     Loss_discriminator:  0.6896169781684875\n",
      "Epoch:  17     Batch:  54  /  468     Loss_generator:  0.7693533897399902     Loss_discriminator:  0.7005438804626465\n",
      "Epoch:  17     Batch:  55  /  468     Loss_generator:  0.7289898991584778     Loss_discriminator:  0.6895696520805359\n",
      "Epoch:  17     Batch:  56  /  468     Loss_generator:  0.6980070471763611     Loss_discriminator:  0.6763002276420593\n",
      "Epoch:  17     Batch:  57  /  468     Loss_generator:  0.6616531610488892     Loss_discriminator:  0.6832971572875977\n",
      "Epoch:  17     Batch:  58  /  468     Loss_generator:  0.6994255185127258     Loss_discriminator:  0.6824848651885986\n",
      "Epoch:  17     Batch:  59  /  468     Loss_generator:  0.7416009902954102     Loss_discriminator:  0.6864452362060547\n",
      "Epoch:  17     Batch:  60  /  468     Loss_generator:  0.8048248887062073     Loss_discriminator:  0.684514045715332\n",
      "Epoch:  17     Batch:  61  /  468     Loss_generator:  0.7745382785797119     Loss_discriminator:  0.6754086017608643\n",
      "Epoch:  17     Batch:  62  /  468     Loss_generator:  0.7202199697494507     Loss_discriminator:  0.6954399347305298\n",
      "Epoch:  17     Batch:  63  /  468     Loss_generator:  0.6585825085639954     Loss_discriminator:  0.6703771948814392\n",
      "Epoch:  17     Batch:  64  /  468     Loss_generator:  0.6557736992835999     Loss_discriminator:  0.6982283592224121\n",
      "Epoch:  17     Batch:  65  /  468     Loss_generator:  0.6999766230583191     Loss_discriminator:  0.6782712936401367\n",
      "Epoch:  17     Batch:  66  /  468     Loss_generator:  0.7413794994354248     Loss_discriminator:  0.6761772632598877\n",
      "Epoch:  17     Batch:  67  /  468     Loss_generator:  0.7640058994293213     Loss_discriminator:  0.7117086052894592\n",
      "Epoch:  17     Batch:  68  /  468     Loss_generator:  0.7610372304916382     Loss_discriminator:  0.6943517327308655\n",
      "Epoch:  17     Batch:  69  /  468     Loss_generator:  0.7413609027862549     Loss_discriminator:  0.6891411542892456\n",
      "Epoch:  17     Batch:  70  /  468     Loss_generator:  0.7302241921424866     Loss_discriminator:  0.6698281168937683\n",
      "Epoch:  17     Batch:  71  /  468     Loss_generator:  0.6883967518806458     Loss_discriminator:  0.6960120797157288\n",
      "Epoch:  17     Batch:  72  /  468     Loss_generator:  0.6576113700866699     Loss_discriminator:  0.6897242069244385\n",
      "Epoch:  17     Batch:  73  /  468     Loss_generator:  0.643186092376709     Loss_discriminator:  0.6880747675895691\n",
      "Epoch:  17     Batch:  74  /  468     Loss_generator:  0.675885796546936     Loss_discriminator:  0.6808364391326904\n",
      "Epoch:  17     Batch:  75  /  468     Loss_generator:  0.7396615743637085     Loss_discriminator:  0.6805382370948792\n",
      "Epoch:  17     Batch:  76  /  468     Loss_generator:  0.7407691478729248     Loss_discriminator:  0.7061453461647034\n",
      "Epoch:  17     Batch:  77  /  468     Loss_generator:  0.7149839401245117     Loss_discriminator:  0.6956206560134888\n",
      "Epoch:  17     Batch:  78  /  468     Loss_generator:  0.6858556270599365     Loss_discriminator:  0.6899707317352295\n",
      "Epoch:  17     Batch:  79  /  468     Loss_generator:  0.7013292908668518     Loss_discriminator:  0.6869258880615234\n",
      "Epoch:  17     Batch:  80  /  468     Loss_generator:  0.700798511505127     Loss_discriminator:  0.698652982711792\n",
      "Epoch:  17     Batch:  81  /  468     Loss_generator:  0.7313719391822815     Loss_discriminator:  0.697443962097168\n",
      "Epoch:  17     Batch:  82  /  468     Loss_generator:  0.7188490033149719     Loss_discriminator:  0.6856880187988281\n",
      "Epoch:  17     Batch:  83  /  468     Loss_generator:  0.7282019853591919     Loss_discriminator:  0.6897627115249634\n",
      "Epoch:  17     Batch:  84  /  468     Loss_generator:  0.7266753911972046     Loss_discriminator:  0.6977943181991577\n",
      "Epoch:  17     Batch:  85  /  468     Loss_generator:  0.6956800222396851     Loss_discriminator:  0.6880717277526855\n",
      "Epoch:  17     Batch:  86  /  468     Loss_generator:  0.6530793905258179     Loss_discriminator:  0.6998984217643738\n",
      "Epoch:  17     Batch:  87  /  468     Loss_generator:  0.7135683298110962     Loss_discriminator:  0.6792913675308228\n",
      "Epoch:  17     Batch:  88  /  468     Loss_generator:  0.7676694393157959     Loss_discriminator:  0.6769238710403442\n",
      "Epoch:  17     Batch:  89  /  468     Loss_generator:  0.7790441513061523     Loss_discriminator:  0.6966732144355774\n",
      "Epoch:  17     Batch:  90  /  468     Loss_generator:  0.7111552953720093     Loss_discriminator:  0.6861428022384644\n",
      "Epoch:  17     Batch:  91  /  468     Loss_generator:  0.6976816654205322     Loss_discriminator:  0.6872047185897827\n",
      "Epoch:  17     Batch:  92  /  468     Loss_generator:  0.6648694276809692     Loss_discriminator:  0.678596556186676\n",
      "Epoch:  17     Batch:  93  /  468     Loss_generator:  0.6904072165489197     Loss_discriminator:  0.6682385206222534\n",
      "Epoch:  17     Batch:  94  /  468     Loss_generator:  0.6885482668876648     Loss_discriminator:  0.6817930936813354\n",
      "Epoch:  17     Batch:  95  /  468     Loss_generator:  0.7168291807174683     Loss_discriminator:  0.6799130439758301\n",
      "Epoch:  17     Batch:  96  /  468     Loss_generator:  0.7732086777687073     Loss_discriminator:  0.7023218870162964\n",
      "Epoch:  17     Batch:  97  /  468     Loss_generator:  0.7325868010520935     Loss_discriminator:  0.6939359903335571\n",
      "Epoch:  17     Batch:  98  /  468     Loss_generator:  0.6947833895683289     Loss_discriminator:  0.6790483593940735\n",
      "Epoch:  17     Batch:  99  /  468     Loss_generator:  0.7078919410705566     Loss_discriminator:  0.6783628463745117\n",
      "Epoch:  17     Batch:  100  /  468     Loss_generator:  0.7236747741699219     Loss_discriminator:  0.6924488544464111\n",
      "Epoch:  17     Batch:  101  /  468     Loss_generator:  0.7207906246185303     Loss_discriminator:  0.675006628036499\n",
      "Epoch:  17     Batch:  102  /  468     Loss_generator:  0.7072962522506714     Loss_discriminator:  0.6804317235946655\n",
      "Epoch:  17     Batch:  103  /  468     Loss_generator:  0.6954004764556885     Loss_discriminator:  0.6796936988830566\n",
      "Epoch:  17     Batch:  104  /  468     Loss_generator:  0.7008371949195862     Loss_discriminator:  0.701881468296051\n",
      "Epoch:  17     Batch:  105  /  468     Loss_generator:  0.7320806384086609     Loss_discriminator:  0.6827889084815979\n",
      "Epoch:  17     Batch:  106  /  468     Loss_generator:  0.7388125658035278     Loss_discriminator:  0.6936800479888916\n",
      "Epoch:  17     Batch:  107  /  468     Loss_generator:  0.731519341468811     Loss_discriminator:  0.6785216927528381\n",
      "Epoch:  17     Batch:  108  /  468     Loss_generator:  0.7089337706565857     Loss_discriminator:  0.6836763620376587\n",
      "Epoch:  17     Batch:  109  /  468     Loss_generator:  0.6718998551368713     Loss_discriminator:  0.6851025819778442\n",
      "Epoch:  17     Batch:  110  /  468     Loss_generator:  0.6742037534713745     Loss_discriminator:  0.6833441853523254\n",
      "Epoch:  17     Batch:  111  /  468     Loss_generator:  0.6918407082557678     Loss_discriminator:  0.6897317171096802\n",
      "Epoch:  17     Batch:  112  /  468     Loss_generator:  0.741925060749054     Loss_discriminator:  0.6811413764953613\n",
      "Epoch:  17     Batch:  113  /  468     Loss_generator:  0.7422337532043457     Loss_discriminator:  0.7057701349258423\n",
      "Epoch:  17     Batch:  114  /  468     Loss_generator:  0.7306528091430664     Loss_discriminator:  0.6863723993301392\n",
      "Epoch:  17     Batch:  115  /  468     Loss_generator:  0.6919616460800171     Loss_discriminator:  0.6878945231437683\n",
      "Epoch:  17     Batch:  116  /  468     Loss_generator:  0.6979670524597168     Loss_discriminator:  0.6816364526748657\n",
      "Epoch:  17     Batch:  117  /  468     Loss_generator:  0.7068049907684326     Loss_discriminator:  0.6833560466766357\n",
      "Epoch:  17     Batch:  118  /  468     Loss_generator:  0.7006465196609497     Loss_discriminator:  0.6755818128585815\n",
      "Epoch:  17     Batch:  119  /  468     Loss_generator:  0.6886730194091797     Loss_discriminator:  0.6811851859092712\n",
      "Epoch:  17     Batch:  120  /  468     Loss_generator:  0.7009301781654358     Loss_discriminator:  0.6814625859260559\n",
      "Epoch:  17     Batch:  121  /  468     Loss_generator:  0.729343831539154     Loss_discriminator:  0.6743690967559814\n",
      "Epoch:  17     Batch:  122  /  468     Loss_generator:  0.7460304498672485     Loss_discriminator:  0.6977498531341553\n",
      "Epoch:  17     Batch:  123  /  468     Loss_generator:  0.7663763761520386     Loss_discriminator:  0.6863168478012085\n",
      "Epoch:  17     Batch:  124  /  468     Loss_generator:  0.704473614692688     Loss_discriminator:  0.6960123777389526\n",
      "Epoch:  17     Batch:  125  /  468     Loss_generator:  0.7178205847740173     Loss_discriminator:  0.693468451499939\n",
      "Epoch:  17     Batch:  126  /  468     Loss_generator:  0.7354931235313416     Loss_discriminator:  0.6781419515609741\n",
      "Epoch:  17     Batch:  127  /  468     Loss_generator:  0.6972271203994751     Loss_discriminator:  0.6850401163101196\n",
      "Epoch:  17     Batch:  128  /  468     Loss_generator:  0.6951695680618286     Loss_discriminator:  0.674312174320221\n",
      "Epoch:  17     Batch:  129  /  468     Loss_generator:  0.7176069021224976     Loss_discriminator:  0.6824802756309509\n",
      "Epoch:  17     Batch:  130  /  468     Loss_generator:  0.7474572658538818     Loss_discriminator:  0.6732556819915771\n",
      "Epoch:  17     Batch:  131  /  468     Loss_generator:  0.7150211930274963     Loss_discriminator:  0.6822777986526489\n",
      "Epoch:  17     Batch:  132  /  468     Loss_generator:  0.6871978044509888     Loss_discriminator:  0.6885794997215271\n",
      "Epoch:  17     Batch:  133  /  468     Loss_generator:  0.6828651428222656     Loss_discriminator:  0.6835577487945557\n",
      "Epoch:  17     Batch:  134  /  468     Loss_generator:  0.7115427851676941     Loss_discriminator:  0.6937801837921143\n",
      "Epoch:  17     Batch:  135  /  468     Loss_generator:  0.7398629784584045     Loss_discriminator:  0.684767484664917\n",
      "Epoch:  17     Batch:  136  /  468     Loss_generator:  0.7443618774414062     Loss_discriminator:  0.6991604566574097\n",
      "Epoch:  17     Batch:  137  /  468     Loss_generator:  0.7013652920722961     Loss_discriminator:  0.6977951526641846\n",
      "Epoch:  17     Batch:  138  /  468     Loss_generator:  0.6746771335601807     Loss_discriminator:  0.6967935562133789\n",
      "Epoch:  17     Batch:  139  /  468     Loss_generator:  0.6989337205886841     Loss_discriminator:  0.6929370164871216\n",
      "Epoch:  17     Batch:  140  /  468     Loss_generator:  0.6990362405776978     Loss_discriminator:  0.6980509757995605\n",
      "Epoch:  17     Batch:  141  /  468     Loss_generator:  0.7023924589157104     Loss_discriminator:  0.699190616607666\n",
      "Epoch:  17     Batch:  142  /  468     Loss_generator:  0.7347460985183716     Loss_discriminator:  0.6785556077957153\n",
      "Epoch:  17     Batch:  143  /  468     Loss_generator:  0.7562012672424316     Loss_discriminator:  0.6878545880317688\n",
      "Epoch:  17     Batch:  144  /  468     Loss_generator:  0.7348917722702026     Loss_discriminator:  0.6689003705978394\n",
      "Epoch:  17     Batch:  145  /  468     Loss_generator:  0.6721417307853699     Loss_discriminator:  0.6777223348617554\n",
      "Epoch:  17     Batch:  146  /  468     Loss_generator:  0.6554981470108032     Loss_discriminator:  0.6806147694587708\n",
      "Epoch:  17     Batch:  147  /  468     Loss_generator:  0.6695409417152405     Loss_discriminator:  0.6851820945739746\n",
      "Epoch:  17     Batch:  148  /  468     Loss_generator:  0.713912308216095     Loss_discriminator:  0.6904082298278809\n",
      "Epoch:  17     Batch:  149  /  468     Loss_generator:  0.7640342712402344     Loss_discriminator:  0.6769372820854187\n",
      "Epoch:  17     Batch:  150  /  468     Loss_generator:  0.7260581254959106     Loss_discriminator:  0.7000879645347595\n",
      "Epoch:  17     Batch:  151  /  468     Loss_generator:  0.6958019137382507     Loss_discriminator:  0.6885933876037598\n",
      "Epoch:  17     Batch:  152  /  468     Loss_generator:  0.6758257150650024     Loss_discriminator:  0.6823350191116333\n",
      "Epoch:  17     Batch:  153  /  468     Loss_generator:  0.6698921918869019     Loss_discriminator:  0.6798498630523682\n",
      "Epoch:  17     Batch:  154  /  468     Loss_generator:  0.711318850517273     Loss_discriminator:  0.6749114394187927\n",
      "Epoch:  17     Batch:  155  /  468     Loss_generator:  0.7877218723297119     Loss_discriminator:  0.6865905523300171\n",
      "Epoch:  17     Batch:  156  /  468     Loss_generator:  0.7716183662414551     Loss_discriminator:  0.6793488264083862\n",
      "Epoch:  17     Batch:  157  /  468     Loss_generator:  0.6986795663833618     Loss_discriminator:  0.7030481696128845\n",
      "Epoch:  17     Batch:  158  /  468     Loss_generator:  0.6493791341781616     Loss_discriminator:  0.693023145198822\n",
      "Epoch:  17     Batch:  159  /  468     Loss_generator:  0.6383493542671204     Loss_discriminator:  0.6777011156082153\n",
      "Epoch:  17     Batch:  160  /  468     Loss_generator:  0.6881566047668457     Loss_discriminator:  0.6949729919433594\n",
      "Epoch:  17     Batch:  161  /  468     Loss_generator:  0.776875376701355     Loss_discriminator:  0.6798819303512573\n",
      "Epoch:  17     Batch:  162  /  468     Loss_generator:  0.7981137037277222     Loss_discriminator:  0.6926059126853943\n",
      "Epoch:  17     Batch:  163  /  468     Loss_generator:  0.7809324860572815     Loss_discriminator:  0.6815423965454102\n",
      "Epoch:  17     Batch:  164  /  468     Loss_generator:  0.7126045823097229     Loss_discriminator:  0.6901914477348328\n",
      "Epoch:  17     Batch:  165  /  468     Loss_generator:  0.6601828336715698     Loss_discriminator:  0.688644289970398\n",
      "Epoch:  17     Batch:  166  /  468     Loss_generator:  0.670466423034668     Loss_discriminator:  0.6758952140808105\n",
      "Epoch:  17     Batch:  167  /  468     Loss_generator:  0.7150230407714844     Loss_discriminator:  0.6891225576400757\n",
      "Epoch:  17     Batch:  168  /  468     Loss_generator:  0.754239559173584     Loss_discriminator:  0.6858893632888794\n",
      "Epoch:  17     Batch:  169  /  468     Loss_generator:  0.7347285151481628     Loss_discriminator:  0.677434504032135\n",
      "Epoch:  17     Batch:  170  /  468     Loss_generator:  0.7015827894210815     Loss_discriminator:  0.6894169449806213\n",
      "Epoch:  17     Batch:  171  /  468     Loss_generator:  0.7136189937591553     Loss_discriminator:  0.6849822402000427\n",
      "Epoch:  17     Batch:  172  /  468     Loss_generator:  0.733649730682373     Loss_discriminator:  0.6796396970748901\n",
      "Epoch:  17     Batch:  173  /  468     Loss_generator:  0.721310019493103     Loss_discriminator:  0.6816173195838928\n",
      "Epoch:  17     Batch:  174  /  468     Loss_generator:  0.7598535418510437     Loss_discriminator:  0.6766958236694336\n",
      "Epoch:  17     Batch:  175  /  468     Loss_generator:  0.6961565017700195     Loss_discriminator:  0.6852730512619019\n",
      "Epoch:  17     Batch:  176  /  468     Loss_generator:  0.6698790788650513     Loss_discriminator:  0.6945009231567383\n",
      "Epoch:  17     Batch:  177  /  468     Loss_generator:  0.6511760950088501     Loss_discriminator:  0.6782827377319336\n",
      "Epoch:  17     Batch:  178  /  468     Loss_generator:  0.6896677017211914     Loss_discriminator:  0.6982741355895996\n",
      "Epoch:  17     Batch:  179  /  468     Loss_generator:  0.7366682887077332     Loss_discriminator:  0.6862685680389404\n",
      "Epoch:  17     Batch:  180  /  468     Loss_generator:  0.7586015462875366     Loss_discriminator:  0.6860957145690918\n",
      "Epoch:  17     Batch:  181  /  468     Loss_generator:  0.7306379675865173     Loss_discriminator:  0.6792056560516357\n",
      "Epoch:  17     Batch:  182  /  468     Loss_generator:  0.6956434845924377     Loss_discriminator:  0.6729041934013367\n",
      "Epoch:  17     Batch:  183  /  468     Loss_generator:  0.674697756767273     Loss_discriminator:  0.6901617050170898\n",
      "Epoch:  17     Batch:  184  /  468     Loss_generator:  0.6908964514732361     Loss_discriminator:  0.6816672682762146\n",
      "Epoch:  17     Batch:  185  /  468     Loss_generator:  0.721662700176239     Loss_discriminator:  0.6902463436126709\n",
      "Epoch:  17     Batch:  186  /  468     Loss_generator:  0.7602146863937378     Loss_discriminator:  0.6897916793823242\n",
      "Epoch:  17     Batch:  187  /  468     Loss_generator:  0.7454131245613098     Loss_discriminator:  0.6768699884414673\n",
      "Epoch:  17     Batch:  188  /  468     Loss_generator:  0.7239669561386108     Loss_discriminator:  0.6847889423370361\n",
      "Epoch:  17     Batch:  189  /  468     Loss_generator:  0.6880699992179871     Loss_discriminator:  0.6737242937088013\n",
      "Epoch:  17     Batch:  190  /  468     Loss_generator:  0.6946603059768677     Loss_discriminator:  0.6848738789558411\n",
      "Epoch:  17     Batch:  191  /  468     Loss_generator:  0.6749355792999268     Loss_discriminator:  0.689563512802124\n",
      "Epoch:  17     Batch:  192  /  468     Loss_generator:  0.6993967294692993     Loss_discriminator:  0.6886255741119385\n",
      "Epoch:  17     Batch:  193  /  468     Loss_generator:  0.7203583717346191     Loss_discriminator:  0.6950662732124329\n",
      "Epoch:  17     Batch:  194  /  468     Loss_generator:  0.6934927701950073     Loss_discriminator:  0.6676499843597412\n",
      "Epoch:  17     Batch:  195  /  468     Loss_generator:  0.6922500729560852     Loss_discriminator:  0.692462682723999\n",
      "Epoch:  17     Batch:  196  /  468     Loss_generator:  0.7137407064437866     Loss_discriminator:  0.6742221117019653\n",
      "Epoch:  17     Batch:  197  /  468     Loss_generator:  0.7410844564437866     Loss_discriminator:  0.6840448379516602\n",
      "Epoch:  17     Batch:  198  /  468     Loss_generator:  0.7393887042999268     Loss_discriminator:  0.695451557636261\n",
      "Epoch:  17     Batch:  199  /  468     Loss_generator:  0.7158737778663635     Loss_discriminator:  0.6977194547653198\n",
      "Epoch:  17     Batch:  200  /  468     Loss_generator:  0.654587984085083     Loss_discriminator:  0.7008345723152161\n",
      "Epoch:  17     Batch:  201  /  468     Loss_generator:  0.693206787109375     Loss_discriminator:  0.674225389957428\n",
      "Epoch:  17     Batch:  202  /  468     Loss_generator:  0.7424179315567017     Loss_discriminator:  0.6815086007118225\n",
      "Epoch:  17     Batch:  203  /  468     Loss_generator:  0.724783182144165     Loss_discriminator:  0.6806838512420654\n",
      "Epoch:  17     Batch:  204  /  468     Loss_generator:  0.7176574468612671     Loss_discriminator:  0.6827154159545898\n",
      "Epoch:  17     Batch:  205  /  468     Loss_generator:  0.6647464632987976     Loss_discriminator:  0.7007771730422974\n",
      "Epoch:  17     Batch:  206  /  468     Loss_generator:  0.6666983366012573     Loss_discriminator:  0.6812012195587158\n",
      "Epoch:  17     Batch:  207  /  468     Loss_generator:  0.7149500250816345     Loss_discriminator:  0.6853158473968506\n",
      "Epoch:  17     Batch:  208  /  468     Loss_generator:  0.7325389385223389     Loss_discriminator:  0.688571572303772\n",
      "Epoch:  17     Batch:  209  /  468     Loss_generator:  0.7544000148773193     Loss_discriminator:  0.688814640045166\n",
      "Epoch:  17     Batch:  210  /  468     Loss_generator:  0.710138201713562     Loss_discriminator:  0.689717710018158\n",
      "Epoch:  17     Batch:  211  /  468     Loss_generator:  0.6711654663085938     Loss_discriminator:  0.6854944229125977\n",
      "Epoch:  17     Batch:  212  /  468     Loss_generator:  0.6828305125236511     Loss_discriminator:  0.6861079335212708\n",
      "Epoch:  17     Batch:  213  /  468     Loss_generator:  0.710351288318634     Loss_discriminator:  0.6775220036506653\n",
      "Epoch:  17     Batch:  214  /  468     Loss_generator:  0.7293269038200378     Loss_discriminator:  0.6952289938926697\n",
      "Epoch:  17     Batch:  215  /  468     Loss_generator:  0.7390443682670593     Loss_discriminator:  0.6848190426826477\n",
      "Epoch:  17     Batch:  216  /  468     Loss_generator:  0.7087848782539368     Loss_discriminator:  0.6871985793113708\n",
      "Epoch:  17     Batch:  217  /  468     Loss_generator:  0.6745943427085876     Loss_discriminator:  0.6871000528335571\n",
      "Epoch:  17     Batch:  218  /  468     Loss_generator:  0.7050889730453491     Loss_discriminator:  0.6833744645118713\n",
      "Epoch:  17     Batch:  219  /  468     Loss_generator:  0.6978641748428345     Loss_discriminator:  0.6877544522285461\n",
      "Epoch:  17     Batch:  220  /  468     Loss_generator:  0.7243048548698425     Loss_discriminator:  0.681005597114563\n",
      "Epoch:  17     Batch:  221  /  468     Loss_generator:  0.74638831615448     Loss_discriminator:  0.6724191904067993\n",
      "Epoch:  17     Batch:  222  /  468     Loss_generator:  0.7827068567276001     Loss_discriminator:  0.6839148998260498\n",
      "Epoch:  17     Batch:  223  /  468     Loss_generator:  0.7413345575332642     Loss_discriminator:  0.6786267757415771\n",
      "Epoch:  17     Batch:  224  /  468     Loss_generator:  0.688425600528717     Loss_discriminator:  0.6840808987617493\n",
      "Epoch:  17     Batch:  225  /  468     Loss_generator:  0.6646547317504883     Loss_discriminator:  0.6780427098274231\n",
      "Epoch:  17     Batch:  226  /  468     Loss_generator:  0.6488538384437561     Loss_discriminator:  0.6799054741859436\n",
      "Epoch:  17     Batch:  227  /  468     Loss_generator:  0.6882551908493042     Loss_discriminator:  0.6771667003631592\n",
      "Epoch:  17     Batch:  228  /  468     Loss_generator:  0.7529110908508301     Loss_discriminator:  0.691116213798523\n",
      "Epoch:  17     Batch:  229  /  468     Loss_generator:  0.7374703884124756     Loss_discriminator:  0.6972014904022217\n",
      "Epoch:  17     Batch:  230  /  468     Loss_generator:  0.7354989051818848     Loss_discriminator:  0.6746154427528381\n",
      "Epoch:  17     Batch:  231  /  468     Loss_generator:  0.6990511417388916     Loss_discriminator:  0.689334511756897\n",
      "Epoch:  17     Batch:  232  /  468     Loss_generator:  0.6872841119766235     Loss_discriminator:  0.6852482557296753\n",
      "Epoch:  17     Batch:  233  /  468     Loss_generator:  0.7093529105186462     Loss_discriminator:  0.673385500907898\n",
      "Epoch:  17     Batch:  234  /  468     Loss_generator:  0.7512290477752686     Loss_discriminator:  0.6844843029975891\n",
      "Epoch:  17     Batch:  235  /  468     Loss_generator:  0.7304248213768005     Loss_discriminator:  0.6820886135101318\n",
      "Epoch:  17     Batch:  236  /  468     Loss_generator:  0.7072526812553406     Loss_discriminator:  0.6928670406341553\n",
      "Epoch:  17     Batch:  237  /  468     Loss_generator:  0.675396740436554     Loss_discriminator:  0.6915808916091919\n",
      "Epoch:  17     Batch:  238  /  468     Loss_generator:  0.6913784146308899     Loss_discriminator:  0.6968473196029663\n",
      "Epoch:  17     Batch:  239  /  468     Loss_generator:  0.7206282615661621     Loss_discriminator:  0.6754705905914307\n",
      "Epoch:  17     Batch:  240  /  468     Loss_generator:  0.7619682550430298     Loss_discriminator:  0.6778022050857544\n",
      "Epoch:  17     Batch:  241  /  468     Loss_generator:  0.7513395547866821     Loss_discriminator:  0.680107831954956\n",
      "Epoch:  17     Batch:  242  /  468     Loss_generator:  0.7221531867980957     Loss_discriminator:  0.6819872856140137\n",
      "Epoch:  17     Batch:  243  /  468     Loss_generator:  0.6812640428543091     Loss_discriminator:  0.6832528114318848\n",
      "Epoch:  17     Batch:  244  /  468     Loss_generator:  0.679008424282074     Loss_discriminator:  0.6776185631752014\n",
      "Epoch:  17     Batch:  245  /  468     Loss_generator:  0.715008020401001     Loss_discriminator:  0.6944586038589478\n",
      "Epoch:  17     Batch:  246  /  468     Loss_generator:  0.6980834007263184     Loss_discriminator:  0.6855272650718689\n",
      "Epoch:  17     Batch:  247  /  468     Loss_generator:  0.7008539438247681     Loss_discriminator:  0.6877261996269226\n",
      "Epoch:  17     Batch:  248  /  468     Loss_generator:  0.7224355936050415     Loss_discriminator:  0.688854455947876\n",
      "Epoch:  17     Batch:  249  /  468     Loss_generator:  0.7040191292762756     Loss_discriminator:  0.6937896013259888\n",
      "Epoch:  17     Batch:  250  /  468     Loss_generator:  0.7377749085426331     Loss_discriminator:  0.6911424994468689\n",
      "Epoch:  17     Batch:  251  /  468     Loss_generator:  0.6998814940452576     Loss_discriminator:  0.6949607133865356\n",
      "Epoch:  17     Batch:  252  /  468     Loss_generator:  0.7211073040962219     Loss_discriminator:  0.6806623935699463\n",
      "Epoch:  17     Batch:  253  /  468     Loss_generator:  0.7267906069755554     Loss_discriminator:  0.6934146285057068\n",
      "Epoch:  17     Batch:  254  /  468     Loss_generator:  0.7076995372772217     Loss_discriminator:  0.6845921874046326\n",
      "Epoch:  17     Batch:  255  /  468     Loss_generator:  0.6997325420379639     Loss_discriminator:  0.6868029832839966\n",
      "Epoch:  17     Batch:  256  /  468     Loss_generator:  0.6901839375495911     Loss_discriminator:  0.7007120847702026\n",
      "Epoch:  17     Batch:  257  /  468     Loss_generator:  0.686068594455719     Loss_discriminator:  0.69370436668396\n",
      "Epoch:  17     Batch:  258  /  468     Loss_generator:  0.7324917316436768     Loss_discriminator:  0.691642701625824\n",
      "Epoch:  17     Batch:  259  /  468     Loss_generator:  0.7551027536392212     Loss_discriminator:  0.6628466844558716\n",
      "Epoch:  17     Batch:  260  /  468     Loss_generator:  0.7233253717422485     Loss_discriminator:  0.681106448173523\n",
      "Epoch:  17     Batch:  261  /  468     Loss_generator:  0.6654487252235413     Loss_discriminator:  0.6950043439865112\n",
      "Epoch:  17     Batch:  262  /  468     Loss_generator:  0.707109272480011     Loss_discriminator:  0.6915751099586487\n",
      "Epoch:  17     Batch:  263  /  468     Loss_generator:  0.7465067505836487     Loss_discriminator:  0.6833313703536987\n",
      "Epoch:  17     Batch:  264  /  468     Loss_generator:  0.750124454498291     Loss_discriminator:  0.6758538484573364\n",
      "Epoch:  17     Batch:  265  /  468     Loss_generator:  0.7065908312797546     Loss_discriminator:  0.6831765174865723\n",
      "Epoch:  17     Batch:  266  /  468     Loss_generator:  0.6886483430862427     Loss_discriminator:  0.6749483346939087\n",
      "Epoch:  17     Batch:  267  /  468     Loss_generator:  0.6928891539573669     Loss_discriminator:  0.6774942278862\n",
      "Epoch:  17     Batch:  268  /  468     Loss_generator:  0.7204543352127075     Loss_discriminator:  0.6959408521652222\n",
      "Epoch:  17     Batch:  269  /  468     Loss_generator:  0.7330045104026794     Loss_discriminator:  0.6745508909225464\n",
      "Epoch:  17     Batch:  270  /  468     Loss_generator:  0.7202122211456299     Loss_discriminator:  0.6794478297233582\n",
      "Epoch:  17     Batch:  271  /  468     Loss_generator:  0.7018265724182129     Loss_discriminator:  0.6849170923233032\n",
      "Epoch:  17     Batch:  272  /  468     Loss_generator:  0.7263002395629883     Loss_discriminator:  0.6796662211418152\n",
      "Epoch:  17     Batch:  273  /  468     Loss_generator:  0.7668194770812988     Loss_discriminator:  0.6783479452133179\n",
      "Epoch:  17     Batch:  274  /  468     Loss_generator:  0.7058303356170654     Loss_discriminator:  0.6890448927879333\n",
      "Epoch:  17     Batch:  275  /  468     Loss_generator:  0.6744552850723267     Loss_discriminator:  0.6835857629776001\n",
      "Epoch:  17     Batch:  276  /  468     Loss_generator:  0.6676133871078491     Loss_discriminator:  0.7012670040130615\n",
      "Epoch:  17     Batch:  277  /  468     Loss_generator:  0.7245449423789978     Loss_discriminator:  0.6858985424041748\n",
      "Epoch:  17     Batch:  278  /  468     Loss_generator:  0.7392337322235107     Loss_discriminator:  0.6947808265686035\n",
      "Epoch:  17     Batch:  279  /  468     Loss_generator:  0.7666142582893372     Loss_discriminator:  0.6779046058654785\n",
      "Epoch:  17     Batch:  280  /  468     Loss_generator:  0.7345078587532043     Loss_discriminator:  0.6908610463142395\n",
      "Epoch:  17     Batch:  281  /  468     Loss_generator:  0.6920251846313477     Loss_discriminator:  0.689348042011261\n",
      "Epoch:  17     Batch:  282  /  468     Loss_generator:  0.683559000492096     Loss_discriminator:  0.6816275715827942\n",
      "Epoch:  17     Batch:  283  /  468     Loss_generator:  0.6652669906616211     Loss_discriminator:  0.6843765377998352\n",
      "Epoch:  17     Batch:  284  /  468     Loss_generator:  0.6981104016304016     Loss_discriminator:  0.6818355321884155\n",
      "Epoch:  17     Batch:  285  /  468     Loss_generator:  0.7284210920333862     Loss_discriminator:  0.6921053528785706\n",
      "Epoch:  17     Batch:  286  /  468     Loss_generator:  0.7614161372184753     Loss_discriminator:  0.6964994668960571\n",
      "Epoch:  17     Batch:  287  /  468     Loss_generator:  0.7566730976104736     Loss_discriminator:  0.696760892868042\n",
      "Epoch:  17     Batch:  288  /  468     Loss_generator:  0.6968650221824646     Loss_discriminator:  0.6878961324691772\n",
      "Epoch:  17     Batch:  289  /  468     Loss_generator:  0.6583045721054077     Loss_discriminator:  0.6758757829666138\n",
      "Epoch:  17     Batch:  290  /  468     Loss_generator:  0.684386134147644     Loss_discriminator:  0.6900985240936279\n",
      "Epoch:  17     Batch:  291  /  468     Loss_generator:  0.7340399026870728     Loss_discriminator:  0.679538905620575\n",
      "Epoch:  17     Batch:  292  /  468     Loss_generator:  0.7654335498809814     Loss_discriminator:  0.6929609775543213\n",
      "Epoch:  17     Batch:  293  /  468     Loss_generator:  0.791634738445282     Loss_discriminator:  0.6867049932479858\n",
      "Epoch:  17     Batch:  294  /  468     Loss_generator:  0.7403049468994141     Loss_discriminator:  0.6860299706459045\n",
      "Epoch:  17     Batch:  295  /  468     Loss_generator:  0.7099667191505432     Loss_discriminator:  0.6965142488479614\n",
      "Epoch:  17     Batch:  296  /  468     Loss_generator:  0.6660962104797363     Loss_discriminator:  0.6875678896903992\n",
      "Epoch:  17     Batch:  297  /  468     Loss_generator:  0.6435285806655884     Loss_discriminator:  0.6875627636909485\n",
      "Epoch:  17     Batch:  298  /  468     Loss_generator:  0.641531229019165     Loss_discriminator:  0.6882290244102478\n",
      "Epoch:  17     Batch:  299  /  468     Loss_generator:  0.6969894170761108     Loss_discriminator:  0.6913925409317017\n",
      "Epoch:  17     Batch:  300  /  468     Loss_generator:  0.7710597515106201     Loss_discriminator:  0.6802970767021179\n",
      "Epoch:  17     Batch:  301  /  468     Loss_generator:  0.7501989603042603     Loss_discriminator:  0.6912650465965271\n",
      "Epoch:  17     Batch:  302  /  468     Loss_generator:  0.6999640464782715     Loss_discriminator:  0.6878067255020142\n",
      "Epoch:  17     Batch:  303  /  468     Loss_generator:  0.7058645486831665     Loss_discriminator:  0.6981031894683838\n",
      "Epoch:  17     Batch:  304  /  468     Loss_generator:  0.7112972736358643     Loss_discriminator:  0.6773602366447449\n",
      "Epoch:  17     Batch:  305  /  468     Loss_generator:  0.70601487159729     Loss_discriminator:  0.69736647605896\n",
      "Epoch:  17     Batch:  306  /  468     Loss_generator:  0.6929206848144531     Loss_discriminator:  0.6854757070541382\n",
      "Epoch:  17     Batch:  307  /  468     Loss_generator:  0.692378044128418     Loss_discriminator:  0.6926771402359009\n",
      "Epoch:  17     Batch:  308  /  468     Loss_generator:  0.6963731050491333     Loss_discriminator:  0.6781774759292603\n",
      "Epoch:  17     Batch:  309  /  468     Loss_generator:  0.7083384394645691     Loss_discriminator:  0.679096519947052\n",
      "Epoch:  17     Batch:  310  /  468     Loss_generator:  0.7117953896522522     Loss_discriminator:  0.6818088293075562\n",
      "Epoch:  17     Batch:  311  /  468     Loss_generator:  0.7310001254081726     Loss_discriminator:  0.6889156699180603\n",
      "Epoch:  17     Batch:  312  /  468     Loss_generator:  0.7457333207130432     Loss_discriminator:  0.6949921250343323\n",
      "Epoch:  17     Batch:  313  /  468     Loss_generator:  0.7049027681350708     Loss_discriminator:  0.6786060929298401\n",
      "Epoch:  17     Batch:  314  /  468     Loss_generator:  0.6632451415061951     Loss_discriminator:  0.6783783435821533\n",
      "Epoch:  17     Batch:  315  /  468     Loss_generator:  0.682411253452301     Loss_discriminator:  0.6944654583930969\n",
      "Epoch:  17     Batch:  316  /  468     Loss_generator:  0.7268351912498474     Loss_discriminator:  0.6839537620544434\n",
      "Epoch:  17     Batch:  317  /  468     Loss_generator:  0.7472752332687378     Loss_discriminator:  0.6851210594177246\n",
      "Epoch:  17     Batch:  318  /  468     Loss_generator:  0.748685359954834     Loss_discriminator:  0.6962367296218872\n",
      "Epoch:  17     Batch:  319  /  468     Loss_generator:  0.7276206016540527     Loss_discriminator:  0.6817660331726074\n",
      "Epoch:  17     Batch:  320  /  468     Loss_generator:  0.6741536855697632     Loss_discriminator:  0.6737513542175293\n",
      "Epoch:  17     Batch:  321  /  468     Loss_generator:  0.66996169090271     Loss_discriminator:  0.6776671409606934\n",
      "Epoch:  17     Batch:  322  /  468     Loss_generator:  0.6754566431045532     Loss_discriminator:  0.6779392957687378\n",
      "Epoch:  17     Batch:  323  /  468     Loss_generator:  0.7438503503799438     Loss_discriminator:  0.68306964635849\n",
      "Epoch:  17     Batch:  324  /  468     Loss_generator:  0.7374297976493835     Loss_discriminator:  0.6837838292121887\n",
      "Epoch:  17     Batch:  325  /  468     Loss_generator:  0.7049325108528137     Loss_discriminator:  0.6707266569137573\n",
      "Epoch:  17     Batch:  326  /  468     Loss_generator:  0.6968385577201843     Loss_discriminator:  0.6837100982666016\n",
      "Epoch:  17     Batch:  327  /  468     Loss_generator:  0.6741976737976074     Loss_discriminator:  0.6831196546554565\n",
      "Epoch:  17     Batch:  328  /  468     Loss_generator:  0.7103203535079956     Loss_discriminator:  0.6769704222679138\n",
      "Epoch:  17     Batch:  329  /  468     Loss_generator:  0.7533804774284363     Loss_discriminator:  0.694466233253479\n",
      "Epoch:  17     Batch:  330  /  468     Loss_generator:  0.7529881000518799     Loss_discriminator:  0.6807601451873779\n",
      "Epoch:  17     Batch:  331  /  468     Loss_generator:  0.7180199027061462     Loss_discriminator:  0.6886599659919739\n",
      "Epoch:  17     Batch:  332  /  468     Loss_generator:  0.6856362819671631     Loss_discriminator:  0.680780827999115\n",
      "Epoch:  17     Batch:  333  /  468     Loss_generator:  0.6619589328765869     Loss_discriminator:  0.686882734298706\n",
      "Epoch:  17     Batch:  334  /  468     Loss_generator:  0.651369035243988     Loss_discriminator:  0.6996917724609375\n",
      "Epoch:  17     Batch:  335  /  468     Loss_generator:  0.6755993962287903     Loss_discriminator:  0.6818077564239502\n",
      "Epoch:  17     Batch:  336  /  468     Loss_generator:  0.7368423342704773     Loss_discriminator:  0.7028752565383911\n",
      "Epoch:  17     Batch:  337  /  468     Loss_generator:  0.7216320037841797     Loss_discriminator:  0.6931347250938416\n",
      "Epoch:  17     Batch:  338  /  468     Loss_generator:  0.745070219039917     Loss_discriminator:  0.688385546207428\n",
      "Epoch:  17     Batch:  339  /  468     Loss_generator:  0.7632936239242554     Loss_discriminator:  0.6768856048583984\n",
      "Epoch:  17     Batch:  340  /  468     Loss_generator:  0.7482746243476868     Loss_discriminator:  0.6963620185852051\n",
      "Epoch:  17     Batch:  341  /  468     Loss_generator:  0.6687768697738647     Loss_discriminator:  0.6769445538520813\n",
      "Epoch:  17     Batch:  342  /  468     Loss_generator:  0.6413366198539734     Loss_discriminator:  0.6921321153640747\n",
      "Epoch:  17     Batch:  343  /  468     Loss_generator:  0.6626842021942139     Loss_discriminator:  0.6962926387786865\n",
      "Epoch:  17     Batch:  344  /  468     Loss_generator:  0.7110008001327515     Loss_discriminator:  0.6872155666351318\n",
      "Epoch:  17     Batch:  345  /  468     Loss_generator:  0.7734410762786865     Loss_discriminator:  0.674135148525238\n",
      "Epoch:  17     Batch:  346  /  468     Loss_generator:  0.7616744637489319     Loss_discriminator:  0.6891444325447083\n",
      "Epoch:  17     Batch:  347  /  468     Loss_generator:  0.7413378953933716     Loss_discriminator:  0.6747705936431885\n",
      "Epoch:  17     Batch:  348  /  468     Loss_generator:  0.7192444205284119     Loss_discriminator:  0.6906738877296448\n",
      "Epoch:  17     Batch:  349  /  468     Loss_generator:  0.7184520959854126     Loss_discriminator:  0.6920007467269897\n",
      "Epoch:  17     Batch:  350  /  468     Loss_generator:  0.687416136264801     Loss_discriminator:  0.6805081963539124\n",
      "Epoch:  17     Batch:  351  /  468     Loss_generator:  0.6632762551307678     Loss_discriminator:  0.7011352777481079\n",
      "Epoch:  17     Batch:  352  /  468     Loss_generator:  0.6709495782852173     Loss_discriminator:  0.6868675947189331\n",
      "Epoch:  17     Batch:  353  /  468     Loss_generator:  0.7383788824081421     Loss_discriminator:  0.6779117584228516\n",
      "Epoch:  17     Batch:  354  /  468     Loss_generator:  0.7528452277183533     Loss_discriminator:  0.6924240589141846\n",
      "Epoch:  17     Batch:  355  /  468     Loss_generator:  0.738215982913971     Loss_discriminator:  0.6939406394958496\n",
      "Epoch:  17     Batch:  356  /  468     Loss_generator:  0.7183016538619995     Loss_discriminator:  0.6993931531906128\n",
      "Epoch:  17     Batch:  357  /  468     Loss_generator:  0.7038604021072388     Loss_discriminator:  0.6734767556190491\n",
      "Epoch:  17     Batch:  358  /  468     Loss_generator:  0.7172260284423828     Loss_discriminator:  0.693783700466156\n",
      "Epoch:  17     Batch:  359  /  468     Loss_generator:  0.7233287692070007     Loss_discriminator:  0.6891444325447083\n",
      "Epoch:  17     Batch:  360  /  468     Loss_generator:  0.6932793259620667     Loss_discriminator:  0.6848329901695251\n",
      "Epoch:  17     Batch:  361  /  468     Loss_generator:  0.6946665048599243     Loss_discriminator:  0.687934398651123\n",
      "Epoch:  17     Batch:  362  /  468     Loss_generator:  0.7117829918861389     Loss_discriminator:  0.6943453550338745\n",
      "Epoch:  17     Batch:  363  /  468     Loss_generator:  0.7035095691680908     Loss_discriminator:  0.6966103911399841\n",
      "Epoch:  17     Batch:  364  /  468     Loss_generator:  0.6763706803321838     Loss_discriminator:  0.6837050318717957\n",
      "Epoch:  17     Batch:  365  /  468     Loss_generator:  0.698428750038147     Loss_discriminator:  0.6866808533668518\n",
      "Epoch:  17     Batch:  366  /  468     Loss_generator:  0.706748902797699     Loss_discriminator:  0.6788672208786011\n",
      "Epoch:  17     Batch:  367  /  468     Loss_generator:  0.7050793170928955     Loss_discriminator:  0.6817277669906616\n",
      "Epoch:  17     Batch:  368  /  468     Loss_generator:  0.7347559928894043     Loss_discriminator:  0.6728804111480713\n",
      "Epoch:  17     Batch:  369  /  468     Loss_generator:  0.7242979407310486     Loss_discriminator:  0.6835922002792358\n",
      "Epoch:  17     Batch:  370  /  468     Loss_generator:  0.6994122266769409     Loss_discriminator:  0.694366455078125\n",
      "Epoch:  17     Batch:  371  /  468     Loss_generator:  0.682043731212616     Loss_discriminator:  0.6928719282150269\n",
      "Epoch:  17     Batch:  372  /  468     Loss_generator:  0.7048438191413879     Loss_discriminator:  0.6937202215194702\n",
      "Epoch:  17     Batch:  373  /  468     Loss_generator:  0.6985814571380615     Loss_discriminator:  0.6888879537582397\n",
      "Epoch:  17     Batch:  374  /  468     Loss_generator:  0.6909979581832886     Loss_discriminator:  0.6953195333480835\n",
      "Epoch:  17     Batch:  375  /  468     Loss_generator:  0.6794213652610779     Loss_discriminator:  0.6810390949249268\n",
      "Epoch:  17     Batch:  376  /  468     Loss_generator:  0.7414945960044861     Loss_discriminator:  0.6955962181091309\n",
      "Epoch:  17     Batch:  377  /  468     Loss_generator:  0.765868067741394     Loss_discriminator:  0.6880315542221069\n",
      "Epoch:  17     Batch:  378  /  468     Loss_generator:  0.7280534505844116     Loss_discriminator:  0.6910193562507629\n",
      "Epoch:  17     Batch:  379  /  468     Loss_generator:  0.705146074295044     Loss_discriminator:  0.6860874891281128\n",
      "Epoch:  17     Batch:  380  /  468     Loss_generator:  0.6829245090484619     Loss_discriminator:  0.6784645318984985\n",
      "Epoch:  17     Batch:  381  /  468     Loss_generator:  0.682133674621582     Loss_discriminator:  0.67912757396698\n",
      "Epoch:  17     Batch:  382  /  468     Loss_generator:  0.6987576484680176     Loss_discriminator:  0.6944055557250977\n",
      "Epoch:  17     Batch:  383  /  468     Loss_generator:  0.7074320316314697     Loss_discriminator:  0.6948524713516235\n",
      "Epoch:  17     Batch:  384  /  468     Loss_generator:  0.7293364405632019     Loss_discriminator:  0.666183590888977\n",
      "Epoch:  17     Batch:  385  /  468     Loss_generator:  0.7273871898651123     Loss_discriminator:  0.6730282306671143\n",
      "Epoch:  17     Batch:  386  /  468     Loss_generator:  0.6912175416946411     Loss_discriminator:  0.6700703501701355\n",
      "Epoch:  17     Batch:  387  /  468     Loss_generator:  0.6850144863128662     Loss_discriminator:  0.6768953800201416\n",
      "Epoch:  17     Batch:  388  /  468     Loss_generator:  0.7097926735877991     Loss_discriminator:  0.6707348227500916\n",
      "Epoch:  17     Batch:  389  /  468     Loss_generator:  0.7183513641357422     Loss_discriminator:  0.6806353330612183\n",
      "Epoch:  17     Batch:  390  /  468     Loss_generator:  0.7575984001159668     Loss_discriminator:  0.6767604351043701\n",
      "Epoch:  17     Batch:  391  /  468     Loss_generator:  0.7045302391052246     Loss_discriminator:  0.6981912851333618\n",
      "Epoch:  17     Batch:  392  /  468     Loss_generator:  0.7080686688423157     Loss_discriminator:  0.6686882972717285\n",
      "Epoch:  17     Batch:  393  /  468     Loss_generator:  0.6632413864135742     Loss_discriminator:  0.691280722618103\n",
      "Epoch:  17     Batch:  394  /  468     Loss_generator:  0.69715416431427     Loss_discriminator:  0.6878170967102051\n",
      "Epoch:  17     Batch:  395  /  468     Loss_generator:  0.699252188205719     Loss_discriminator:  0.6855096220970154\n",
      "Epoch:  17     Batch:  396  /  468     Loss_generator:  0.697680652141571     Loss_discriminator:  0.6920005679130554\n",
      "Epoch:  17     Batch:  397  /  468     Loss_generator:  0.7476527690887451     Loss_discriminator:  0.6856560707092285\n",
      "Epoch:  17     Batch:  398  /  468     Loss_generator:  0.7963510751724243     Loss_discriminator:  0.6786897778511047\n",
      "Epoch:  17     Batch:  399  /  468     Loss_generator:  0.774499773979187     Loss_discriminator:  0.6857354640960693\n",
      "Epoch:  17     Batch:  400  /  468     Loss_generator:  0.7119636535644531     Loss_discriminator:  0.6860618591308594\n",
      "Epoch:  17     Batch:  401  /  468     Loss_generator:  0.6618452668190002     Loss_discriminator:  0.6978495121002197\n",
      "Epoch:  17     Batch:  402  /  468     Loss_generator:  0.6672281622886658     Loss_discriminator:  0.6684562563896179\n",
      "Epoch:  17     Batch:  403  /  468     Loss_generator:  0.6782119870185852     Loss_discriminator:  0.6888667345046997\n",
      "Epoch:  17     Batch:  404  /  468     Loss_generator:  0.7409472465515137     Loss_discriminator:  0.6847915053367615\n",
      "Epoch:  17     Batch:  405  /  468     Loss_generator:  0.78607577085495     Loss_discriminator:  0.6830323934555054\n",
      "Epoch:  17     Batch:  406  /  468     Loss_generator:  0.8092136383056641     Loss_discriminator:  0.6889814138412476\n",
      "Epoch:  17     Batch:  407  /  468     Loss_generator:  0.7456673383712769     Loss_discriminator:  0.6757153272628784\n",
      "Epoch:  17     Batch:  408  /  468     Loss_generator:  0.6827577352523804     Loss_discriminator:  0.695148229598999\n",
      "Epoch:  17     Batch:  409  /  468     Loss_generator:  0.6333966255187988     Loss_discriminator:  0.6944421529769897\n",
      "Epoch:  17     Batch:  410  /  468     Loss_generator:  0.6445270776748657     Loss_discriminator:  0.6814928650856018\n",
      "Epoch:  17     Batch:  411  /  468     Loss_generator:  0.7047983407974243     Loss_discriminator:  0.6851614713668823\n",
      "Epoch:  17     Batch:  412  /  468     Loss_generator:  0.7469542026519775     Loss_discriminator:  0.6815152168273926\n",
      "Epoch:  17     Batch:  413  /  468     Loss_generator:  0.7611750364303589     Loss_discriminator:  0.6824333667755127\n",
      "Epoch:  17     Batch:  414  /  468     Loss_generator:  0.7691813707351685     Loss_discriminator:  0.690627932548523\n",
      "Epoch:  17     Batch:  415  /  468     Loss_generator:  0.7212701439857483     Loss_discriminator:  0.691990077495575\n",
      "Epoch:  17     Batch:  416  /  468     Loss_generator:  0.6966051459312439     Loss_discriminator:  0.6779037714004517\n",
      "Epoch:  17     Batch:  417  /  468     Loss_generator:  0.6743497848510742     Loss_discriminator:  0.6907030344009399\n",
      "Epoch:  17     Batch:  418  /  468     Loss_generator:  0.6783754825592041     Loss_discriminator:  0.7009658217430115\n",
      "Epoch:  17     Batch:  419  /  468     Loss_generator:  0.6612531542778015     Loss_discriminator:  0.6939589381217957\n",
      "Epoch:  17     Batch:  420  /  468     Loss_generator:  0.6879239082336426     Loss_discriminator:  0.6670159101486206\n",
      "Epoch:  17     Batch:  421  /  468     Loss_generator:  0.7610695362091064     Loss_discriminator:  0.6870779991149902\n",
      "Epoch:  17     Batch:  422  /  468     Loss_generator:  0.7849347591400146     Loss_discriminator:  0.693407416343689\n",
      "Epoch:  17     Batch:  423  /  468     Loss_generator:  0.7916332483291626     Loss_discriminator:  0.6932008862495422\n",
      "Epoch:  17     Batch:  424  /  468     Loss_generator:  0.7112736105918884     Loss_discriminator:  0.6841583251953125\n",
      "Epoch:  17     Batch:  425  /  468     Loss_generator:  0.6779468059539795     Loss_discriminator:  0.6907411813735962\n",
      "Epoch:  17     Batch:  426  /  468     Loss_generator:  0.6508469581604004     Loss_discriminator:  0.6882053017616272\n",
      "Epoch:  17     Batch:  427  /  468     Loss_generator:  0.6481844186782837     Loss_discriminator:  0.6860888004302979\n",
      "Epoch:  17     Batch:  428  /  468     Loss_generator:  0.6830614805221558     Loss_discriminator:  0.6836246848106384\n",
      "Epoch:  17     Batch:  429  /  468     Loss_generator:  0.721284806728363     Loss_discriminator:  0.6993805170059204\n",
      "Epoch:  17     Batch:  430  /  468     Loss_generator:  0.7575293779373169     Loss_discriminator:  0.7052958607673645\n",
      "Epoch:  17     Batch:  431  /  468     Loss_generator:  0.7646806240081787     Loss_discriminator:  0.6739023923873901\n",
      "Epoch:  17     Batch:  432  /  468     Loss_generator:  0.722088634967804     Loss_discriminator:  0.6806655526161194\n",
      "Epoch:  17     Batch:  433  /  468     Loss_generator:  0.7096524834632874     Loss_discriminator:  0.6942692995071411\n",
      "Epoch:  17     Batch:  434  /  468     Loss_generator:  0.7372751832008362     Loss_discriminator:  0.7020126581192017\n",
      "Epoch:  17     Batch:  435  /  468     Loss_generator:  0.7503759264945984     Loss_discriminator:  0.6909334659576416\n",
      "Epoch:  17     Batch:  436  /  468     Loss_generator:  0.7394377589225769     Loss_discriminator:  0.6746335029602051\n",
      "Epoch:  17     Batch:  437  /  468     Loss_generator:  0.7124454975128174     Loss_discriminator:  0.685539960861206\n",
      "Epoch:  17     Batch:  438  /  468     Loss_generator:  0.6798057556152344     Loss_discriminator:  0.6984907984733582\n",
      "Epoch:  17     Batch:  439  /  468     Loss_generator:  0.682382345199585     Loss_discriminator:  0.687637448310852\n",
      "Epoch:  17     Batch:  440  /  468     Loss_generator:  0.6770583987236023     Loss_discriminator:  0.6855818629264832\n",
      "Epoch:  17     Batch:  441  /  468     Loss_generator:  0.6830487251281738     Loss_discriminator:  0.6862204670906067\n",
      "Epoch:  17     Batch:  442  /  468     Loss_generator:  0.7292754054069519     Loss_discriminator:  0.6926795244216919\n",
      "Epoch:  17     Batch:  443  /  468     Loss_generator:  0.7593198418617249     Loss_discriminator:  0.670828640460968\n",
      "Epoch:  17     Batch:  444  /  468     Loss_generator:  0.7518025040626526     Loss_discriminator:  0.6862285137176514\n",
      "Epoch:  17     Batch:  445  /  468     Loss_generator:  0.7252116203308105     Loss_discriminator:  0.6898837089538574\n",
      "Epoch:  17     Batch:  446  /  468     Loss_generator:  0.7040801644325256     Loss_discriminator:  0.678932785987854\n",
      "Epoch:  17     Batch:  447  /  468     Loss_generator:  0.6602562665939331     Loss_discriminator:  0.6887703537940979\n",
      "Epoch:  17     Batch:  448  /  468     Loss_generator:  0.6481354236602783     Loss_discriminator:  0.6811610460281372\n",
      "Epoch:  17     Batch:  449  /  468     Loss_generator:  0.7088142037391663     Loss_discriminator:  0.6770358085632324\n",
      "Epoch:  17     Batch:  450  /  468     Loss_generator:  0.779933750629425     Loss_discriminator:  0.689177393913269\n",
      "Epoch:  17     Batch:  451  /  468     Loss_generator:  0.7798344492912292     Loss_discriminator:  0.6823232173919678\n",
      "Epoch:  17     Batch:  452  /  468     Loss_generator:  0.7172827124595642     Loss_discriminator:  0.6756798624992371\n",
      "Epoch:  17     Batch:  453  /  468     Loss_generator:  0.6926877498626709     Loss_discriminator:  0.6847890615463257\n",
      "Epoch:  17     Batch:  454  /  468     Loss_generator:  0.6662087440490723     Loss_discriminator:  0.6819860935211182\n",
      "Epoch:  17     Batch:  455  /  468     Loss_generator:  0.6970236301422119     Loss_discriminator:  0.6857746839523315\n",
      "Epoch:  17     Batch:  456  /  468     Loss_generator:  0.7439684867858887     Loss_discriminator:  0.6813678741455078\n",
      "Epoch:  17     Batch:  457  /  468     Loss_generator:  0.7469147443771362     Loss_discriminator:  0.6873207092285156\n",
      "Epoch:  17     Batch:  458  /  468     Loss_generator:  0.726452112197876     Loss_discriminator:  0.6850206851959229\n",
      "Epoch:  17     Batch:  459  /  468     Loss_generator:  0.6810156106948853     Loss_discriminator:  0.6867427825927734\n",
      "Epoch:  17     Batch:  460  /  468     Loss_generator:  0.7168643474578857     Loss_discriminator:  0.6800408959388733\n",
      "Epoch:  17     Batch:  461  /  468     Loss_generator:  0.7412346601486206     Loss_discriminator:  0.7023991346359253\n",
      "Epoch:  17     Batch:  462  /  468     Loss_generator:  0.7457454204559326     Loss_discriminator:  0.6769208908081055\n",
      "Epoch:  17     Batch:  463  /  468     Loss_generator:  0.7271057367324829     Loss_discriminator:  0.6846601366996765\n",
      "Epoch:  17     Batch:  464  /  468     Loss_generator:  0.6967729330062866     Loss_discriminator:  0.6943153738975525\n",
      "Epoch:  17     Batch:  465  /  468     Loss_generator:  0.6920720338821411     Loss_discriminator:  0.6924000978469849\n",
      "Epoch:  17     Batch:  466  /  468     Loss_generator:  0.7006031274795532     Loss_discriminator:  0.70430588722229\n",
      "Epoch:  17     Batch:  467  /  468     Loss_generator:  0.7243399620056152     Loss_discriminator:  0.6819940805435181\n",
      "Epoch:  18     Batch:  0  /  468     Loss_generator:  0.7126306295394897     Loss_discriminator:  0.6896887421607971\n",
      "Epoch:  18     Batch:  1  /  468     Loss_generator:  0.7068970203399658     Loss_discriminator:  0.6771504878997803\n",
      "Epoch:  18     Batch:  2  /  468     Loss_generator:  0.7471367120742798     Loss_discriminator:  0.6805577278137207\n",
      "Epoch:  18     Batch:  3  /  468     Loss_generator:  0.752804160118103     Loss_discriminator:  0.6942886114120483\n",
      "Epoch:  18     Batch:  4  /  468     Loss_generator:  0.7186612486839294     Loss_discriminator:  0.6849114894866943\n",
      "Epoch:  18     Batch:  5  /  468     Loss_generator:  0.6907913684844971     Loss_discriminator:  0.6831880807876587\n",
      "Epoch:  18     Batch:  6  /  468     Loss_generator:  0.6699318885803223     Loss_discriminator:  0.6775215864181519\n",
      "Epoch:  18     Batch:  7  /  468     Loss_generator:  0.685804009437561     Loss_discriminator:  0.6836124658584595\n",
      "Epoch:  18     Batch:  8  /  468     Loss_generator:  0.7371026277542114     Loss_discriminator:  0.6919485330581665\n",
      "Epoch:  18     Batch:  9  /  468     Loss_generator:  0.7438419461250305     Loss_discriminator:  0.6976902484893799\n",
      "Epoch:  18     Batch:  10  /  468     Loss_generator:  0.7315181493759155     Loss_discriminator:  0.679653525352478\n",
      "Epoch:  18     Batch:  11  /  468     Loss_generator:  0.7291588187217712     Loss_discriminator:  0.6907060146331787\n",
      "Epoch:  18     Batch:  12  /  468     Loss_generator:  0.6762011051177979     Loss_discriminator:  0.6848090887069702\n",
      "Epoch:  18     Batch:  13  /  468     Loss_generator:  0.7024074792861938     Loss_discriminator:  0.6930708885192871\n",
      "Epoch:  18     Batch:  14  /  468     Loss_generator:  0.7178978323936462     Loss_discriminator:  0.6985368728637695\n",
      "Epoch:  18     Batch:  15  /  468     Loss_generator:  0.7167502641677856     Loss_discriminator:  0.6877783536911011\n",
      "Epoch:  18     Batch:  16  /  468     Loss_generator:  0.7157837152481079     Loss_discriminator:  0.6832530498504639\n",
      "Epoch:  18     Batch:  17  /  468     Loss_generator:  0.7405617237091064     Loss_discriminator:  0.6902072429656982\n",
      "Epoch:  18     Batch:  18  /  468     Loss_generator:  0.7197511792182922     Loss_discriminator:  0.687214732170105\n",
      "Epoch:  18     Batch:  19  /  468     Loss_generator:  0.6995232701301575     Loss_discriminator:  0.6843889951705933\n",
      "Epoch:  18     Batch:  20  /  468     Loss_generator:  0.7004311680793762     Loss_discriminator:  0.6920560598373413\n",
      "Epoch:  18     Batch:  21  /  468     Loss_generator:  0.721103310585022     Loss_discriminator:  0.6895574331283569\n",
      "Epoch:  18     Batch:  22  /  468     Loss_generator:  0.7224343419075012     Loss_discriminator:  0.6755052804946899\n",
      "Epoch:  18     Batch:  23  /  468     Loss_generator:  0.7383446097373962     Loss_discriminator:  0.6934682130813599\n",
      "Epoch:  18     Batch:  24  /  468     Loss_generator:  0.7190655469894409     Loss_discriminator:  0.7085168361663818\n",
      "Epoch:  18     Batch:  25  /  468     Loss_generator:  0.6857991814613342     Loss_discriminator:  0.6938574314117432\n",
      "Epoch:  18     Batch:  26  /  468     Loss_generator:  0.7022349834442139     Loss_discriminator:  0.69865882396698\n",
      "Epoch:  18     Batch:  27  /  468     Loss_generator:  0.7217050790786743     Loss_discriminator:  0.6792317628860474\n",
      "Epoch:  18     Batch:  28  /  468     Loss_generator:  0.735541820526123     Loss_discriminator:  0.6960440278053284\n",
      "Epoch:  18     Batch:  29  /  468     Loss_generator:  0.7142893075942993     Loss_discriminator:  0.6880703568458557\n",
      "Epoch:  18     Batch:  30  /  468     Loss_generator:  0.7046442031860352     Loss_discriminator:  0.68967604637146\n",
      "Epoch:  18     Batch:  31  /  468     Loss_generator:  0.7211697697639465     Loss_discriminator:  0.6932855844497681\n",
      "Epoch:  18     Batch:  32  /  468     Loss_generator:  0.7041800022125244     Loss_discriminator:  0.6879948973655701\n",
      "Epoch:  18     Batch:  33  /  468     Loss_generator:  0.7302453517913818     Loss_discriminator:  0.695164680480957\n",
      "Epoch:  18     Batch:  34  /  468     Loss_generator:  0.7241801619529724     Loss_discriminator:  0.6808273196220398\n",
      "Epoch:  18     Batch:  35  /  468     Loss_generator:  0.7102588415145874     Loss_discriminator:  0.6673597097396851\n",
      "Epoch:  18     Batch:  36  /  468     Loss_generator:  0.6963388323783875     Loss_discriminator:  0.6957212686538696\n",
      "Epoch:  18     Batch:  37  /  468     Loss_generator:  0.6993046402931213     Loss_discriminator:  0.6672251224517822\n",
      "Epoch:  18     Batch:  38  /  468     Loss_generator:  0.6904443502426147     Loss_discriminator:  0.6801934242248535\n",
      "Epoch:  18     Batch:  39  /  468     Loss_generator:  0.7338191866874695     Loss_discriminator:  0.6767743825912476\n",
      "Epoch:  18     Batch:  40  /  468     Loss_generator:  0.7052066326141357     Loss_discriminator:  0.6816556453704834\n",
      "Epoch:  18     Batch:  41  /  468     Loss_generator:  0.704756498336792     Loss_discriminator:  0.6840163469314575\n",
      "Epoch:  18     Batch:  42  /  468     Loss_generator:  0.7141627073287964     Loss_discriminator:  0.6991161108016968\n",
      "Epoch:  18     Batch:  43  /  468     Loss_generator:  0.7182881236076355     Loss_discriminator:  0.6903678178787231\n",
      "Epoch:  18     Batch:  44  /  468     Loss_generator:  0.7111480236053467     Loss_discriminator:  0.6940299272537231\n",
      "Epoch:  18     Batch:  45  /  468     Loss_generator:  0.7148383259773254     Loss_discriminator:  0.6823892593383789\n",
      "Epoch:  18     Batch:  46  /  468     Loss_generator:  0.7074837684631348     Loss_discriminator:  0.6814037561416626\n",
      "Epoch:  18     Batch:  47  /  468     Loss_generator:  0.725906491279602     Loss_discriminator:  0.6889868378639221\n",
      "Epoch:  18     Batch:  48  /  468     Loss_generator:  0.7076835036277771     Loss_discriminator:  0.6931726336479187\n",
      "Epoch:  18     Batch:  49  /  468     Loss_generator:  0.6958798766136169     Loss_discriminator:  0.6933560371398926\n",
      "Epoch:  18     Batch:  50  /  468     Loss_generator:  0.7198439836502075     Loss_discriminator:  0.669739842414856\n",
      "Epoch:  18     Batch:  51  /  468     Loss_generator:  0.6996927261352539     Loss_discriminator:  0.7028244137763977\n",
      "Epoch:  18     Batch:  52  /  468     Loss_generator:  0.7055270075798035     Loss_discriminator:  0.6941314935684204\n",
      "Epoch:  18     Batch:  53  /  468     Loss_generator:  0.6978560090065002     Loss_discriminator:  0.6892886161804199\n",
      "Epoch:  18     Batch:  54  /  468     Loss_generator:  0.6999911069869995     Loss_discriminator:  0.669465959072113\n",
      "Epoch:  18     Batch:  55  /  468     Loss_generator:  0.715188205242157     Loss_discriminator:  0.6882258057594299\n",
      "Epoch:  18     Batch:  56  /  468     Loss_generator:  0.7257808446884155     Loss_discriminator:  0.6934974193572998\n",
      "Epoch:  18     Batch:  57  /  468     Loss_generator:  0.675849199295044     Loss_discriminator:  0.6868331432342529\n",
      "Epoch:  18     Batch:  58  /  468     Loss_generator:  0.6849045753479004     Loss_discriminator:  0.6787758469581604\n",
      "Epoch:  18     Batch:  59  /  468     Loss_generator:  0.7114347815513611     Loss_discriminator:  0.6884834170341492\n",
      "Epoch:  18     Batch:  60  /  468     Loss_generator:  0.7500864267349243     Loss_discriminator:  0.6767910122871399\n",
      "Epoch:  18     Batch:  61  /  468     Loss_generator:  0.7397440671920776     Loss_discriminator:  0.688065230846405\n",
      "Epoch:  18     Batch:  62  /  468     Loss_generator:  0.7229520678520203     Loss_discriminator:  0.671504020690918\n",
      "Epoch:  18     Batch:  63  /  468     Loss_generator:  0.7059786319732666     Loss_discriminator:  0.6779221296310425\n",
      "Epoch:  18     Batch:  64  /  468     Loss_generator:  0.7052838206291199     Loss_discriminator:  0.6820011138916016\n",
      "Epoch:  18     Batch:  65  /  468     Loss_generator:  0.701342761516571     Loss_discriminator:  0.671912670135498\n",
      "Epoch:  18     Batch:  66  /  468     Loss_generator:  0.6923314332962036     Loss_discriminator:  0.6802771091461182\n",
      "Epoch:  18     Batch:  67  /  468     Loss_generator:  0.6956272125244141     Loss_discriminator:  0.6835969686508179\n",
      "Epoch:  18     Batch:  68  /  468     Loss_generator:  0.7168878316879272     Loss_discriminator:  0.6787891387939453\n",
      "Epoch:  18     Batch:  69  /  468     Loss_generator:  0.7083392143249512     Loss_discriminator:  0.6834588646888733\n",
      "Epoch:  18     Batch:  70  /  468     Loss_generator:  0.7112995386123657     Loss_discriminator:  0.6862505674362183\n",
      "Epoch:  18     Batch:  71  /  468     Loss_generator:  0.7035127282142639     Loss_discriminator:  0.6897134780883789\n",
      "Epoch:  18     Batch:  72  /  468     Loss_generator:  0.6901617050170898     Loss_discriminator:  0.6746010780334473\n",
      "Epoch:  18     Batch:  73  /  468     Loss_generator:  0.6856635212898254     Loss_discriminator:  0.6822476387023926\n",
      "Epoch:  18     Batch:  74  /  468     Loss_generator:  0.7208390831947327     Loss_discriminator:  0.6862537860870361\n",
      "Epoch:  18     Batch:  75  /  468     Loss_generator:  0.7475484609603882     Loss_discriminator:  0.6800496578216553\n",
      "Epoch:  18     Batch:  76  /  468     Loss_generator:  0.7422754764556885     Loss_discriminator:  0.6853932738304138\n",
      "Epoch:  18     Batch:  77  /  468     Loss_generator:  0.7257810831069946     Loss_discriminator:  0.683356761932373\n",
      "Epoch:  18     Batch:  78  /  468     Loss_generator:  0.7182040214538574     Loss_discriminator:  0.6684218049049377\n",
      "Epoch:  18     Batch:  79  /  468     Loss_generator:  0.7146987915039062     Loss_discriminator:  0.6805464029312134\n",
      "Epoch:  18     Batch:  80  /  468     Loss_generator:  0.6838672161102295     Loss_discriminator:  0.6848933100700378\n",
      "Epoch:  18     Batch:  81  /  468     Loss_generator:  0.685202956199646     Loss_discriminator:  0.6880191564559937\n",
      "Epoch:  18     Batch:  82  /  468     Loss_generator:  0.6918764114379883     Loss_discriminator:  0.6779406666755676\n",
      "Epoch:  18     Batch:  83  /  468     Loss_generator:  0.7063647508621216     Loss_discriminator:  0.6873579621315002\n",
      "Epoch:  18     Batch:  84  /  468     Loss_generator:  0.7287333011627197     Loss_discriminator:  0.6863842010498047\n",
      "Epoch:  18     Batch:  85  /  468     Loss_generator:  0.7394576072692871     Loss_discriminator:  0.6810504198074341\n",
      "Epoch:  18     Batch:  86  /  468     Loss_generator:  0.7166348099708557     Loss_discriminator:  0.6864017248153687\n",
      "Epoch:  18     Batch:  87  /  468     Loss_generator:  0.6555111408233643     Loss_discriminator:  0.68967604637146\n",
      "Epoch:  18     Batch:  88  /  468     Loss_generator:  0.6333746314048767     Loss_discriminator:  0.6760971546173096\n",
      "Epoch:  18     Batch:  89  /  468     Loss_generator:  0.72850501537323     Loss_discriminator:  0.6981263160705566\n",
      "Epoch:  18     Batch:  90  /  468     Loss_generator:  0.78485506772995     Loss_discriminator:  0.6832526326179504\n",
      "Epoch:  18     Batch:  91  /  468     Loss_generator:  0.7819534540176392     Loss_discriminator:  0.6738682985305786\n",
      "Epoch:  18     Batch:  92  /  468     Loss_generator:  0.7262284755706787     Loss_discriminator:  0.685483455657959\n",
      "Epoch:  18     Batch:  93  /  468     Loss_generator:  0.6784766912460327     Loss_discriminator:  0.6708053350448608\n",
      "Epoch:  18     Batch:  94  /  468     Loss_generator:  0.667756974697113     Loss_discriminator:  0.6745065450668335\n",
      "Epoch:  18     Batch:  95  /  468     Loss_generator:  0.6824683547019958     Loss_discriminator:  0.674554169178009\n",
      "Epoch:  18     Batch:  96  /  468     Loss_generator:  0.7166706323623657     Loss_discriminator:  0.684157133102417\n",
      "Epoch:  18     Batch:  97  /  468     Loss_generator:  0.733789324760437     Loss_discriminator:  0.6724629402160645\n",
      "Epoch:  18     Batch:  98  /  468     Loss_generator:  0.7135844230651855     Loss_discriminator:  0.6835249662399292\n",
      "Epoch:  18     Batch:  99  /  468     Loss_generator:  0.7067549228668213     Loss_discriminator:  0.6905497312545776\n",
      "Epoch:  18     Batch:  100  /  468     Loss_generator:  0.6863731741905212     Loss_discriminator:  0.6867337822914124\n",
      "Epoch:  18     Batch:  101  /  468     Loss_generator:  0.6944138407707214     Loss_discriminator:  0.6860935688018799\n",
      "Epoch:  18     Batch:  102  /  468     Loss_generator:  0.6999901533126831     Loss_discriminator:  0.6777185201644897\n",
      "Epoch:  18     Batch:  103  /  468     Loss_generator:  0.7375027537345886     Loss_discriminator:  0.6903746724128723\n",
      "Epoch:  18     Batch:  104  /  468     Loss_generator:  0.7619096040725708     Loss_discriminator:  0.67189621925354\n",
      "Epoch:  18     Batch:  105  /  468     Loss_generator:  0.7559991478919983     Loss_discriminator:  0.6770861148834229\n",
      "Epoch:  18     Batch:  106  /  468     Loss_generator:  0.7391048669815063     Loss_discriminator:  0.6917152404785156\n",
      "Epoch:  18     Batch:  107  /  468     Loss_generator:  0.6858376264572144     Loss_discriminator:  0.6894829273223877\n",
      "Epoch:  18     Batch:  108  /  468     Loss_generator:  0.6634759902954102     Loss_discriminator:  0.6900424957275391\n",
      "Epoch:  18     Batch:  109  /  468     Loss_generator:  0.6680608987808228     Loss_discriminator:  0.693027913570404\n",
      "Epoch:  18     Batch:  110  /  468     Loss_generator:  0.7417159676551819     Loss_discriminator:  0.6854764819145203\n",
      "Epoch:  18     Batch:  111  /  468     Loss_generator:  0.7575215101242065     Loss_discriminator:  0.6814536452293396\n",
      "Epoch:  18     Batch:  112  /  468     Loss_generator:  0.7227941751480103     Loss_discriminator:  0.6848790645599365\n",
      "Epoch:  18     Batch:  113  /  468     Loss_generator:  0.6799511313438416     Loss_discriminator:  0.692998468875885\n",
      "Epoch:  18     Batch:  114  /  468     Loss_generator:  0.6894954442977905     Loss_discriminator:  0.6740481853485107\n",
      "Epoch:  18     Batch:  115  /  468     Loss_generator:  0.6842371821403503     Loss_discriminator:  0.6797791719436646\n",
      "Epoch:  18     Batch:  116  /  468     Loss_generator:  0.7307009696960449     Loss_discriminator:  0.6832123398780823\n",
      "Epoch:  18     Batch:  117  /  468     Loss_generator:  0.7479133009910583     Loss_discriminator:  0.6908100843429565\n",
      "Epoch:  18     Batch:  118  /  468     Loss_generator:  0.7582327127456665     Loss_discriminator:  0.6921049356460571\n",
      "Epoch:  18     Batch:  119  /  468     Loss_generator:  0.7046047449111938     Loss_discriminator:  0.6788549423217773\n",
      "Epoch:  18     Batch:  120  /  468     Loss_generator:  0.6956524848937988     Loss_discriminator:  0.6824180483818054\n",
      "Epoch:  18     Batch:  121  /  468     Loss_generator:  0.7012232542037964     Loss_discriminator:  0.6878190040588379\n",
      "Epoch:  18     Batch:  122  /  468     Loss_generator:  0.7439982891082764     Loss_discriminator:  0.687760055065155\n",
      "Epoch:  18     Batch:  123  /  468     Loss_generator:  0.7562258243560791     Loss_discriminator:  0.6884472370147705\n",
      "Epoch:  18     Batch:  124  /  468     Loss_generator:  0.7266016602516174     Loss_discriminator:  0.6872437000274658\n",
      "Epoch:  18     Batch:  125  /  468     Loss_generator:  0.6977584362030029     Loss_discriminator:  0.6865061521530151\n",
      "Epoch:  18     Batch:  126  /  468     Loss_generator:  0.6888613700866699     Loss_discriminator:  0.6711372137069702\n",
      "Epoch:  18     Batch:  127  /  468     Loss_generator:  0.7113009095191956     Loss_discriminator:  0.678972065448761\n",
      "Epoch:  18     Batch:  128  /  468     Loss_generator:  0.7055672407150269     Loss_discriminator:  0.6904699206352234\n",
      "Epoch:  18     Batch:  129  /  468     Loss_generator:  0.710587203502655     Loss_discriminator:  0.6831946969032288\n",
      "Epoch:  18     Batch:  130  /  468     Loss_generator:  0.6983702182769775     Loss_discriminator:  0.6757409572601318\n",
      "Epoch:  18     Batch:  131  /  468     Loss_generator:  0.6887856721878052     Loss_discriminator:  0.6944268941879272\n",
      "Epoch:  18     Batch:  132  /  468     Loss_generator:  0.6809688806533813     Loss_discriminator:  0.6853324770927429\n",
      "Epoch:  18     Batch:  133  /  468     Loss_generator:  0.697632372379303     Loss_discriminator:  0.6787788271903992\n",
      "Epoch:  18     Batch:  134  /  468     Loss_generator:  0.748468279838562     Loss_discriminator:  0.7019237875938416\n",
      "Epoch:  18     Batch:  135  /  468     Loss_generator:  0.7554817199707031     Loss_discriminator:  0.683832049369812\n",
      "Epoch:  18     Batch:  136  /  468     Loss_generator:  0.7340775728225708     Loss_discriminator:  0.6778587698936462\n",
      "Epoch:  18     Batch:  137  /  468     Loss_generator:  0.7150747776031494     Loss_discriminator:  0.6858989000320435\n",
      "Epoch:  18     Batch:  138  /  468     Loss_generator:  0.6818923950195312     Loss_discriminator:  0.6908727288246155\n",
      "Epoch:  18     Batch:  139  /  468     Loss_generator:  0.6766615509986877     Loss_discriminator:  0.68183833360672\n",
      "Epoch:  18     Batch:  140  /  468     Loss_generator:  0.7178767919540405     Loss_discriminator:  0.6927165389060974\n",
      "Epoch:  18     Batch:  141  /  468     Loss_generator:  0.7385648488998413     Loss_discriminator:  0.6948984265327454\n",
      "Epoch:  18     Batch:  142  /  468     Loss_generator:  0.7291315197944641     Loss_discriminator:  0.6885001063346863\n",
      "Epoch:  18     Batch:  143  /  468     Loss_generator:  0.7349981069564819     Loss_discriminator:  0.6872413754463196\n",
      "Epoch:  18     Batch:  144  /  468     Loss_generator:  0.7273170948028564     Loss_discriminator:  0.6916943788528442\n",
      "Epoch:  18     Batch:  145  /  468     Loss_generator:  0.684005856513977     Loss_discriminator:  0.6848881244659424\n",
      "Epoch:  18     Batch:  146  /  468     Loss_generator:  0.742396891117096     Loss_discriminator:  0.6879842281341553\n",
      "Epoch:  18     Batch:  147  /  468     Loss_generator:  0.7208261489868164     Loss_discriminator:  0.6933501958847046\n",
      "Epoch:  18     Batch:  148  /  468     Loss_generator:  0.685360848903656     Loss_discriminator:  0.6878958940505981\n",
      "Epoch:  18     Batch:  149  /  468     Loss_generator:  0.6672868728637695     Loss_discriminator:  0.6681405305862427\n",
      "Epoch:  18     Batch:  150  /  468     Loss_generator:  0.6531208157539368     Loss_discriminator:  0.7041289210319519\n",
      "Epoch:  18     Batch:  151  /  468     Loss_generator:  0.6681856513023376     Loss_discriminator:  0.6887661814689636\n",
      "Epoch:  18     Batch:  152  /  468     Loss_generator:  0.7103608846664429     Loss_discriminator:  0.696914792060852\n",
      "Epoch:  18     Batch:  153  /  468     Loss_generator:  0.7762439250946045     Loss_discriminator:  0.6843116283416748\n",
      "Epoch:  18     Batch:  154  /  468     Loss_generator:  0.784156322479248     Loss_discriminator:  0.6862830519676208\n",
      "Epoch:  18     Batch:  155  /  468     Loss_generator:  0.7610585689544678     Loss_discriminator:  0.6756747961044312\n",
      "Epoch:  18     Batch:  156  /  468     Loss_generator:  0.686753511428833     Loss_discriminator:  0.6960833072662354\n",
      "Epoch:  18     Batch:  157  /  468     Loss_generator:  0.6864280104637146     Loss_discriminator:  0.6791774034500122\n",
      "Epoch:  18     Batch:  158  /  468     Loss_generator:  0.6618942618370056     Loss_discriminator:  0.6888614296913147\n",
      "Epoch:  18     Batch:  159  /  468     Loss_generator:  0.7510419487953186     Loss_discriminator:  0.6786977052688599\n",
      "Epoch:  18     Batch:  160  /  468     Loss_generator:  0.7830064296722412     Loss_discriminator:  0.6683356165885925\n",
      "Epoch:  18     Batch:  161  /  468     Loss_generator:  0.7395983338356018     Loss_discriminator:  0.698441743850708\n",
      "Epoch:  18     Batch:  162  /  468     Loss_generator:  0.6983962059020996     Loss_discriminator:  0.7014352679252625\n",
      "Epoch:  18     Batch:  163  /  468     Loss_generator:  0.6615832448005676     Loss_discriminator:  0.6943009495735168\n",
      "Epoch:  18     Batch:  164  /  468     Loss_generator:  0.6450985670089722     Loss_discriminator:  0.6869246959686279\n",
      "Epoch:  18     Batch:  165  /  468     Loss_generator:  0.6988319754600525     Loss_discriminator:  0.6885176301002502\n",
      "Epoch:  18     Batch:  166  /  468     Loss_generator:  0.7857140302658081     Loss_discriminator:  0.6851097345352173\n",
      "Epoch:  18     Batch:  167  /  468     Loss_generator:  0.8247298002243042     Loss_discriminator:  0.7009904384613037\n",
      "Epoch:  18     Batch:  168  /  468     Loss_generator:  0.730923593044281     Loss_discriminator:  0.6770599484443665\n",
      "Epoch:  18     Batch:  169  /  468     Loss_generator:  0.6576534509658813     Loss_discriminator:  0.6877492666244507\n",
      "Epoch:  18     Batch:  170  /  468     Loss_generator:  0.62892085313797     Loss_discriminator:  0.6752979755401611\n",
      "Epoch:  18     Batch:  171  /  468     Loss_generator:  0.6607471108436584     Loss_discriminator:  0.6865734457969666\n",
      "Epoch:  18     Batch:  172  /  468     Loss_generator:  0.7742955684661865     Loss_discriminator:  0.7018848061561584\n",
      "Epoch:  18     Batch:  173  /  468     Loss_generator:  0.8448401093482971     Loss_discriminator:  0.6790921688079834\n",
      "Epoch:  18     Batch:  174  /  468     Loss_generator:  0.7972169518470764     Loss_discriminator:  0.6857354640960693\n",
      "Epoch:  18     Batch:  175  /  468     Loss_generator:  0.7141252756118774     Loss_discriminator:  0.6739965677261353\n",
      "Epoch:  18     Batch:  176  /  468     Loss_generator:  0.6323856711387634     Loss_discriminator:  0.686529278755188\n",
      "Epoch:  18     Batch:  177  /  468     Loss_generator:  0.6126320958137512     Loss_discriminator:  0.6799246072769165\n",
      "Epoch:  18     Batch:  178  /  468     Loss_generator:  0.7017759084701538     Loss_discriminator:  0.6989795565605164\n",
      "Epoch:  18     Batch:  179  /  468     Loss_generator:  0.7635151147842407     Loss_discriminator:  0.6836074590682983\n",
      "Epoch:  18     Batch:  180  /  468     Loss_generator:  0.7877858281135559     Loss_discriminator:  0.7012923359870911\n",
      "Epoch:  18     Batch:  181  /  468     Loss_generator:  0.7578113675117493     Loss_discriminator:  0.6754528880119324\n",
      "Epoch:  18     Batch:  182  /  468     Loss_generator:  0.69687819480896     Loss_discriminator:  0.6736125946044922\n",
      "Epoch:  18     Batch:  183  /  468     Loss_generator:  0.6921323537826538     Loss_discriminator:  0.6784969568252563\n",
      "Epoch:  18     Batch:  184  /  468     Loss_generator:  0.6958600282669067     Loss_discriminator:  0.67827969789505\n",
      "Epoch:  18     Batch:  185  /  468     Loss_generator:  0.7005559206008911     Loss_discriminator:  0.6843295097351074\n",
      "Epoch:  18     Batch:  186  /  468     Loss_generator:  0.706250786781311     Loss_discriminator:  0.6877763271331787\n",
      "Epoch:  18     Batch:  187  /  468     Loss_generator:  0.6953163743019104     Loss_discriminator:  0.6729826927185059\n",
      "Epoch:  18     Batch:  188  /  468     Loss_generator:  0.6843468546867371     Loss_discriminator:  0.688637912273407\n",
      "Epoch:  18     Batch:  189  /  468     Loss_generator:  0.7096121311187744     Loss_discriminator:  0.6849949359893799\n",
      "Epoch:  18     Batch:  190  /  468     Loss_generator:  0.7536923885345459     Loss_discriminator:  0.6674315929412842\n",
      "Epoch:  18     Batch:  191  /  468     Loss_generator:  0.725691020488739     Loss_discriminator:  0.6901830434799194\n",
      "Epoch:  18     Batch:  192  /  468     Loss_generator:  0.6915308833122253     Loss_discriminator:  0.6825152635574341\n",
      "Epoch:  18     Batch:  193  /  468     Loss_generator:  0.6954655647277832     Loss_discriminator:  0.6648796796798706\n",
      "Epoch:  18     Batch:  194  /  468     Loss_generator:  0.7075667977333069     Loss_discriminator:  0.6889748573303223\n",
      "Epoch:  18     Batch:  195  /  468     Loss_generator:  0.7016751766204834     Loss_discriminator:  0.6960048675537109\n",
      "Epoch:  18     Batch:  196  /  468     Loss_generator:  0.6976017951965332     Loss_discriminator:  0.6746474504470825\n",
      "Epoch:  18     Batch:  197  /  468     Loss_generator:  0.7403910160064697     Loss_discriminator:  0.6756561994552612\n",
      "Epoch:  18     Batch:  198  /  468     Loss_generator:  0.7624973654747009     Loss_discriminator:  0.6875267028808594\n",
      "Epoch:  18     Batch:  199  /  468     Loss_generator:  0.777374267578125     Loss_discriminator:  0.6865932941436768\n",
      "Epoch:  18     Batch:  200  /  468     Loss_generator:  0.7272903919219971     Loss_discriminator:  0.6944109201431274\n",
      "Epoch:  18     Batch:  201  /  468     Loss_generator:  0.6808541417121887     Loss_discriminator:  0.679104208946228\n",
      "Epoch:  18     Batch:  202  /  468     Loss_generator:  0.6752214431762695     Loss_discriminator:  0.6910779476165771\n",
      "Epoch:  18     Batch:  203  /  468     Loss_generator:  0.6834417581558228     Loss_discriminator:  0.6795994639396667\n",
      "Epoch:  18     Batch:  204  /  468     Loss_generator:  0.7131549119949341     Loss_discriminator:  0.6820136308670044\n",
      "Epoch:  18     Batch:  205  /  468     Loss_generator:  0.7620187997817993     Loss_discriminator:  0.6912161111831665\n",
      "Epoch:  18     Batch:  206  /  468     Loss_generator:  0.7549277544021606     Loss_discriminator:  0.6896623969078064\n",
      "Epoch:  18     Batch:  207  /  468     Loss_generator:  0.6871733069419861     Loss_discriminator:  0.6883692741394043\n",
      "Epoch:  18     Batch:  208  /  468     Loss_generator:  0.6774122714996338     Loss_discriminator:  0.6873026490211487\n",
      "Epoch:  18     Batch:  209  /  468     Loss_generator:  0.7056149840354919     Loss_discriminator:  0.69754958152771\n",
      "Epoch:  18     Batch:  210  /  468     Loss_generator:  0.735802173614502     Loss_discriminator:  0.6756499409675598\n",
      "Epoch:  18     Batch:  211  /  468     Loss_generator:  0.7671347856521606     Loss_discriminator:  0.682904839515686\n",
      "Epoch:  18     Batch:  212  /  468     Loss_generator:  0.7459388971328735     Loss_discriminator:  0.6842243671417236\n",
      "Epoch:  18     Batch:  213  /  468     Loss_generator:  0.7109301686286926     Loss_discriminator:  0.681364893913269\n",
      "Epoch:  18     Batch:  214  /  468     Loss_generator:  0.6973063349723816     Loss_discriminator:  0.6966174840927124\n",
      "Epoch:  18     Batch:  215  /  468     Loss_generator:  0.6767840385437012     Loss_discriminator:  0.6818075180053711\n",
      "Epoch:  18     Batch:  216  /  468     Loss_generator:  0.6972478628158569     Loss_discriminator:  0.6888422966003418\n",
      "Epoch:  18     Batch:  217  /  468     Loss_generator:  0.7183172106742859     Loss_discriminator:  0.6877462863922119\n",
      "Epoch:  18     Batch:  218  /  468     Loss_generator:  0.7056472301483154     Loss_discriminator:  0.6911695003509521\n",
      "Epoch:  18     Batch:  219  /  468     Loss_generator:  0.7031677961349487     Loss_discriminator:  0.6888326406478882\n",
      "Epoch:  18     Batch:  220  /  468     Loss_generator:  0.7009769678115845     Loss_discriminator:  0.7029708027839661\n",
      "Epoch:  18     Batch:  221  /  468     Loss_generator:  0.7128400206565857     Loss_discriminator:  0.6894690990447998\n",
      "Epoch:  18     Batch:  222  /  468     Loss_generator:  0.7330458164215088     Loss_discriminator:  0.6893868446350098\n",
      "Epoch:  18     Batch:  223  /  468     Loss_generator:  0.7313926219940186     Loss_discriminator:  0.6814382076263428\n",
      "Epoch:  18     Batch:  224  /  468     Loss_generator:  0.6871579885482788     Loss_discriminator:  0.6981292963027954\n",
      "Epoch:  18     Batch:  225  /  468     Loss_generator:  0.7026669979095459     Loss_discriminator:  0.6983665227890015\n",
      "Epoch:  18     Batch:  226  /  468     Loss_generator:  0.6916312575340271     Loss_discriminator:  0.6727721691131592\n",
      "Epoch:  18     Batch:  227  /  468     Loss_generator:  0.6926186680793762     Loss_discriminator:  0.6864787340164185\n",
      "Epoch:  18     Batch:  228  /  468     Loss_generator:  0.7068222761154175     Loss_discriminator:  0.6769892573356628\n",
      "Epoch:  18     Batch:  229  /  468     Loss_generator:  0.7343348264694214     Loss_discriminator:  0.6986194252967834\n",
      "Epoch:  18     Batch:  230  /  468     Loss_generator:  0.6990035772323608     Loss_discriminator:  0.6872643232345581\n",
      "Epoch:  18     Batch:  231  /  468     Loss_generator:  0.7094523906707764     Loss_discriminator:  0.7080516815185547\n",
      "Epoch:  18     Batch:  232  /  468     Loss_generator:  0.7336632013320923     Loss_discriminator:  0.6808655261993408\n",
      "Epoch:  18     Batch:  233  /  468     Loss_generator:  0.7051559090614319     Loss_discriminator:  0.6858540773391724\n",
      "Epoch:  18     Batch:  234  /  468     Loss_generator:  0.732191801071167     Loss_discriminator:  0.6943137049674988\n",
      "Epoch:  18     Batch:  235  /  468     Loss_generator:  0.7172895073890686     Loss_discriminator:  0.7013879418373108\n",
      "Epoch:  18     Batch:  236  /  468     Loss_generator:  0.7199183702468872     Loss_discriminator:  0.6808815598487854\n",
      "Epoch:  18     Batch:  237  /  468     Loss_generator:  0.7092118859291077     Loss_discriminator:  0.6869949102401733\n",
      "Epoch:  18     Batch:  238  /  468     Loss_generator:  0.6984583139419556     Loss_discriminator:  0.6805074214935303\n",
      "Epoch:  18     Batch:  239  /  468     Loss_generator:  0.6868801712989807     Loss_discriminator:  0.6672450304031372\n",
      "Epoch:  18     Batch:  240  /  468     Loss_generator:  0.7174781560897827     Loss_discriminator:  0.6735681295394897\n",
      "Epoch:  18     Batch:  241  /  468     Loss_generator:  0.7279012203216553     Loss_discriminator:  0.6773496270179749\n",
      "Epoch:  18     Batch:  242  /  468     Loss_generator:  0.6843046545982361     Loss_discriminator:  0.6877313256263733\n",
      "Epoch:  18     Batch:  243  /  468     Loss_generator:  0.6654720306396484     Loss_discriminator:  0.7013554573059082\n",
      "Epoch:  18     Batch:  244  /  468     Loss_generator:  0.7019709348678589     Loss_discriminator:  0.6979576349258423\n",
      "Epoch:  18     Batch:  245  /  468     Loss_generator:  0.7222679257392883     Loss_discriminator:  0.6864397525787354\n",
      "Epoch:  18     Batch:  246  /  468     Loss_generator:  0.7591989040374756     Loss_discriminator:  0.6863665580749512\n",
      "Epoch:  18     Batch:  247  /  468     Loss_generator:  0.7211159467697144     Loss_discriminator:  0.6874666810035706\n",
      "Epoch:  18     Batch:  248  /  468     Loss_generator:  0.6731014251708984     Loss_discriminator:  0.682440459728241\n",
      "Epoch:  18     Batch:  249  /  468     Loss_generator:  0.6873125433921814     Loss_discriminator:  0.6874715089797974\n",
      "Epoch:  18     Batch:  250  /  468     Loss_generator:  0.7087319493293762     Loss_discriminator:  0.6836912631988525\n",
      "Epoch:  18     Batch:  251  /  468     Loss_generator:  0.7510250806808472     Loss_discriminator:  0.6919575929641724\n",
      "Epoch:  18     Batch:  252  /  468     Loss_generator:  0.753304123878479     Loss_discriminator:  0.6813889741897583\n",
      "Epoch:  18     Batch:  253  /  468     Loss_generator:  0.7674704194068909     Loss_discriminator:  0.689909815788269\n",
      "Epoch:  18     Batch:  254  /  468     Loss_generator:  0.7394853830337524     Loss_discriminator:  0.685697078704834\n",
      "Epoch:  18     Batch:  255  /  468     Loss_generator:  0.7091553807258606     Loss_discriminator:  0.6929938793182373\n",
      "Epoch:  18     Batch:  256  /  468     Loss_generator:  0.6512619256973267     Loss_discriminator:  0.6873886585235596\n",
      "Epoch:  18     Batch:  257  /  468     Loss_generator:  0.6662757396697998     Loss_discriminator:  0.6933547258377075\n",
      "Epoch:  18     Batch:  258  /  468     Loss_generator:  0.7146236300468445     Loss_discriminator:  0.6942099332809448\n",
      "Epoch:  18     Batch:  259  /  468     Loss_generator:  0.7984280586242676     Loss_discriminator:  0.6887378096580505\n",
      "Epoch:  18     Batch:  260  /  468     Loss_generator:  0.7641183137893677     Loss_discriminator:  0.6924914717674255\n",
      "Epoch:  18     Batch:  261  /  468     Loss_generator:  0.710437536239624     Loss_discriminator:  0.6828105449676514\n",
      "Epoch:  18     Batch:  262  /  468     Loss_generator:  0.6836376190185547     Loss_discriminator:  0.6692544221878052\n",
      "Epoch:  18     Batch:  263  /  468     Loss_generator:  0.6728078126907349     Loss_discriminator:  0.6912370920181274\n",
      "Epoch:  18     Batch:  264  /  468     Loss_generator:  0.7067314386367798     Loss_discriminator:  0.6760486364364624\n",
      "Epoch:  18     Batch:  265  /  468     Loss_generator:  0.7315794825553894     Loss_discriminator:  0.6820045709609985\n",
      "Epoch:  18     Batch:  266  /  468     Loss_generator:  0.717342734336853     Loss_discriminator:  0.6709076166152954\n",
      "Epoch:  18     Batch:  267  /  468     Loss_generator:  0.6956933736801147     Loss_discriminator:  0.7036564350128174\n",
      "Epoch:  18     Batch:  268  /  468     Loss_generator:  0.7160812020301819     Loss_discriminator:  0.6702542901039124\n",
      "Epoch:  18     Batch:  269  /  468     Loss_generator:  0.7300278544425964     Loss_discriminator:  0.6770695447921753\n",
      "Epoch:  18     Batch:  270  /  468     Loss_generator:  0.7716500163078308     Loss_discriminator:  0.6687577962875366\n",
      "Epoch:  18     Batch:  271  /  468     Loss_generator:  0.7371190786361694     Loss_discriminator:  0.701209306716919\n",
      "Epoch:  18     Batch:  272  /  468     Loss_generator:  0.6933143734931946     Loss_discriminator:  0.6836612820625305\n",
      "Epoch:  18     Batch:  273  /  468     Loss_generator:  0.6563690304756165     Loss_discriminator:  0.6718863248825073\n",
      "Epoch:  18     Batch:  274  /  468     Loss_generator:  0.6654905080795288     Loss_discriminator:  0.6792427897453308\n",
      "Epoch:  18     Batch:  275  /  468     Loss_generator:  0.6775983572006226     Loss_discriminator:  0.682353138923645\n",
      "Epoch:  18     Batch:  276  /  468     Loss_generator:  0.697563648223877     Loss_discriminator:  0.670365571975708\n",
      "Epoch:  18     Batch:  277  /  468     Loss_generator:  0.7364023923873901     Loss_discriminator:  0.6730275750160217\n",
      "Epoch:  18     Batch:  278  /  468     Loss_generator:  0.7399275302886963     Loss_discriminator:  0.6925152540206909\n",
      "Epoch:  18     Batch:  279  /  468     Loss_generator:  0.7285417318344116     Loss_discriminator:  0.681099534034729\n",
      "Epoch:  18     Batch:  280  /  468     Loss_generator:  0.7098463773727417     Loss_discriminator:  0.6860232949256897\n",
      "Epoch:  18     Batch:  281  /  468     Loss_generator:  0.6934727430343628     Loss_discriminator:  0.6871377229690552\n",
      "Epoch:  18     Batch:  282  /  468     Loss_generator:  0.6871777176856995     Loss_discriminator:  0.6966919898986816\n",
      "Epoch:  18     Batch:  283  /  468     Loss_generator:  0.7169463634490967     Loss_discriminator:  0.6864190697669983\n",
      "Epoch:  18     Batch:  284  /  468     Loss_generator:  0.7246171236038208     Loss_discriminator:  0.6819337606430054\n",
      "Epoch:  18     Batch:  285  /  468     Loss_generator:  0.7099310159683228     Loss_discriminator:  0.6913968324661255\n",
      "Epoch:  18     Batch:  286  /  468     Loss_generator:  0.7226943373680115     Loss_discriminator:  0.6820665597915649\n",
      "Epoch:  18     Batch:  287  /  468     Loss_generator:  0.7044283151626587     Loss_discriminator:  0.6810974478721619\n",
      "Epoch:  18     Batch:  288  /  468     Loss_generator:  0.6790326237678528     Loss_discriminator:  0.688241183757782\n",
      "Epoch:  18     Batch:  289  /  468     Loss_generator:  0.6925116777420044     Loss_discriminator:  0.6981350183486938\n",
      "Epoch:  18     Batch:  290  /  468     Loss_generator:  0.7187589406967163     Loss_discriminator:  0.6790728569030762\n",
      "Epoch:  18     Batch:  291  /  468     Loss_generator:  0.7456165552139282     Loss_discriminator:  0.6714162826538086\n",
      "Epoch:  18     Batch:  292  /  468     Loss_generator:  0.726845920085907     Loss_discriminator:  0.662146806716919\n",
      "Epoch:  18     Batch:  293  /  468     Loss_generator:  0.7281492352485657     Loss_discriminator:  0.6904395818710327\n",
      "Epoch:  18     Batch:  294  /  468     Loss_generator:  0.7335361242294312     Loss_discriminator:  0.6896569728851318\n",
      "Epoch:  18     Batch:  295  /  468     Loss_generator:  0.7473063468933105     Loss_discriminator:  0.6776363849639893\n",
      "Epoch:  18     Batch:  296  /  468     Loss_generator:  0.7301541566848755     Loss_discriminator:  0.6919213533401489\n",
      "Epoch:  18     Batch:  297  /  468     Loss_generator:  0.7076475620269775     Loss_discriminator:  0.6996014714241028\n",
      "Epoch:  18     Batch:  298  /  468     Loss_generator:  0.731028139591217     Loss_discriminator:  0.7014502286911011\n",
      "Epoch:  18     Batch:  299  /  468     Loss_generator:  0.7338125705718994     Loss_discriminator:  0.6697872877120972\n",
      "Epoch:  18     Batch:  300  /  468     Loss_generator:  0.7146538496017456     Loss_discriminator:  0.6824495792388916\n",
      "Epoch:  18     Batch:  301  /  468     Loss_generator:  0.7063108682632446     Loss_discriminator:  0.6862850189208984\n",
      "Epoch:  18     Batch:  302  /  468     Loss_generator:  0.6849321126937866     Loss_discriminator:  0.6817210912704468\n",
      "Epoch:  18     Batch:  303  /  468     Loss_generator:  0.694007396697998     Loss_discriminator:  0.6833398938179016\n",
      "Epoch:  18     Batch:  304  /  468     Loss_generator:  0.6985440254211426     Loss_discriminator:  0.6959991455078125\n",
      "Epoch:  18     Batch:  305  /  468     Loss_generator:  0.7057728171348572     Loss_discriminator:  0.6671048402786255\n",
      "Epoch:  18     Batch:  306  /  468     Loss_generator:  0.7117151021957397     Loss_discriminator:  0.6836069226264954\n",
      "Epoch:  18     Batch:  307  /  468     Loss_generator:  0.7325140237808228     Loss_discriminator:  0.7025223970413208\n",
      "Epoch:  18     Batch:  308  /  468     Loss_generator:  0.7145616412162781     Loss_discriminator:  0.6725345253944397\n",
      "Epoch:  18     Batch:  309  /  468     Loss_generator:  0.750531792640686     Loss_discriminator:  0.6808390617370605\n",
      "Epoch:  18     Batch:  310  /  468     Loss_generator:  0.7320687770843506     Loss_discriminator:  0.6832274794578552\n",
      "Epoch:  18     Batch:  311  /  468     Loss_generator:  0.7431632876396179     Loss_discriminator:  0.677879273891449\n",
      "Epoch:  18     Batch:  312  /  468     Loss_generator:  0.7196688652038574     Loss_discriminator:  0.6985313892364502\n",
      "Epoch:  18     Batch:  313  /  468     Loss_generator:  0.6758183240890503     Loss_discriminator:  0.6841835379600525\n",
      "Epoch:  18     Batch:  314  /  468     Loss_generator:  0.6768802404403687     Loss_discriminator:  0.700253427028656\n",
      "Epoch:  18     Batch:  315  /  468     Loss_generator:  0.7015043497085571     Loss_discriminator:  0.6917982697486877\n",
      "Epoch:  18     Batch:  316  /  468     Loss_generator:  0.7060487270355225     Loss_discriminator:  0.682059645652771\n",
      "Epoch:  18     Batch:  317  /  468     Loss_generator:  0.7105846405029297     Loss_discriminator:  0.6772540807723999\n",
      "Epoch:  18     Batch:  318  /  468     Loss_generator:  0.7441480159759521     Loss_discriminator:  0.6874035000801086\n",
      "Epoch:  18     Batch:  319  /  468     Loss_generator:  0.754259467124939     Loss_discriminator:  0.6935494542121887\n",
      "Epoch:  18     Batch:  320  /  468     Loss_generator:  0.7009009718894958     Loss_discriminator:  0.699266254901886\n",
      "Epoch:  18     Batch:  321  /  468     Loss_generator:  0.6718316078186035     Loss_discriminator:  0.6898097395896912\n",
      "Epoch:  18     Batch:  322  /  468     Loss_generator:  0.6692549586296082     Loss_discriminator:  0.6964418292045593\n",
      "Epoch:  18     Batch:  323  /  468     Loss_generator:  0.6986063122749329     Loss_discriminator:  0.6799050569534302\n",
      "Epoch:  18     Batch:  324  /  468     Loss_generator:  0.696061909198761     Loss_discriminator:  0.6941783428192139\n",
      "Epoch:  18     Batch:  325  /  468     Loss_generator:  0.7218437194824219     Loss_discriminator:  0.672947347164154\n",
      "Epoch:  18     Batch:  326  /  468     Loss_generator:  0.725730836391449     Loss_discriminator:  0.7016042470932007\n",
      "Epoch:  18     Batch:  327  /  468     Loss_generator:  0.7183275818824768     Loss_discriminator:  0.6863141655921936\n",
      "Epoch:  18     Batch:  328  /  468     Loss_generator:  0.7317541837692261     Loss_discriminator:  0.7154878377914429\n",
      "Epoch:  18     Batch:  329  /  468     Loss_generator:  0.6997315883636475     Loss_discriminator:  0.6865390539169312\n",
      "Epoch:  18     Batch:  330  /  468     Loss_generator:  0.6919090747833252     Loss_discriminator:  0.7004468441009521\n",
      "Epoch:  18     Batch:  331  /  468     Loss_generator:  0.6936339139938354     Loss_discriminator:  0.6889753341674805\n",
      "Epoch:  18     Batch:  332  /  468     Loss_generator:  0.7174673080444336     Loss_discriminator:  0.6868523359298706\n",
      "Epoch:  18     Batch:  333  /  468     Loss_generator:  0.7517512440681458     Loss_discriminator:  0.6883502006530762\n",
      "Epoch:  18     Batch:  334  /  468     Loss_generator:  0.725986659526825     Loss_discriminator:  0.6937224268913269\n",
      "Epoch:  18     Batch:  335  /  468     Loss_generator:  0.6784687042236328     Loss_discriminator:  0.6795093417167664\n",
      "Epoch:  18     Batch:  336  /  468     Loss_generator:  0.6570025682449341     Loss_discriminator:  0.6889610290527344\n",
      "Epoch:  18     Batch:  337  /  468     Loss_generator:  0.6449309587478638     Loss_discriminator:  0.6811763048171997\n",
      "Epoch:  18     Batch:  338  /  468     Loss_generator:  0.7143675088882446     Loss_discriminator:  0.6759282350540161\n",
      "Epoch:  18     Batch:  339  /  468     Loss_generator:  0.7555086016654968     Loss_discriminator:  0.7018434405326843\n",
      "Epoch:  18     Batch:  340  /  468     Loss_generator:  0.7781238555908203     Loss_discriminator:  0.684326171875\n",
      "Epoch:  18     Batch:  341  /  468     Loss_generator:  0.7355347871780396     Loss_discriminator:  0.670745313167572\n",
      "Epoch:  18     Batch:  342  /  468     Loss_generator:  0.6710981130599976     Loss_discriminator:  0.6759645342826843\n",
      "Epoch:  18     Batch:  343  /  468     Loss_generator:  0.6951082944869995     Loss_discriminator:  0.6872525215148926\n",
      "Epoch:  18     Batch:  344  /  468     Loss_generator:  0.7154712677001953     Loss_discriminator:  0.6895995736122131\n",
      "Epoch:  18     Batch:  345  /  468     Loss_generator:  0.7378597855567932     Loss_discriminator:  0.6780710816383362\n",
      "Epoch:  18     Batch:  346  /  468     Loss_generator:  0.7237257361412048     Loss_discriminator:  0.6802582740783691\n",
      "Epoch:  18     Batch:  347  /  468     Loss_generator:  0.7350373864173889     Loss_discriminator:  0.6791670322418213\n",
      "Epoch:  18     Batch:  348  /  468     Loss_generator:  0.7135647535324097     Loss_discriminator:  0.6854877471923828\n",
      "Epoch:  18     Batch:  349  /  468     Loss_generator:  0.691794216632843     Loss_discriminator:  0.6845800876617432\n",
      "Epoch:  18     Batch:  350  /  468     Loss_generator:  0.6988534927368164     Loss_discriminator:  0.6804543733596802\n",
      "Epoch:  18     Batch:  351  /  468     Loss_generator:  0.722748339176178     Loss_discriminator:  0.6911064982414246\n",
      "Epoch:  18     Batch:  352  /  468     Loss_generator:  0.752601146697998     Loss_discriminator:  0.6810232400894165\n",
      "Epoch:  18     Batch:  353  /  468     Loss_generator:  0.7338684797286987     Loss_discriminator:  0.6830456256866455\n",
      "Epoch:  18     Batch:  354  /  468     Loss_generator:  0.7100101113319397     Loss_discriminator:  0.6957294940948486\n",
      "Epoch:  18     Batch:  355  /  468     Loss_generator:  0.6833183765411377     Loss_discriminator:  0.6927075386047363\n",
      "Epoch:  18     Batch:  356  /  468     Loss_generator:  0.6531684398651123     Loss_discriminator:  0.6723175048828125\n",
      "Epoch:  18     Batch:  357  /  468     Loss_generator:  0.688859224319458     Loss_discriminator:  0.6936171054840088\n",
      "Epoch:  18     Batch:  358  /  468     Loss_generator:  0.7492868304252625     Loss_discriminator:  0.6788997650146484\n",
      "Epoch:  18     Batch:  359  /  468     Loss_generator:  0.7511966824531555     Loss_discriminator:  0.679373562335968\n",
      "Epoch:  18     Batch:  360  /  468     Loss_generator:  0.7453573942184448     Loss_discriminator:  0.677436351776123\n",
      "Epoch:  18     Batch:  361  /  468     Loss_generator:  0.7130076885223389     Loss_discriminator:  0.6929399371147156\n",
      "Epoch:  18     Batch:  362  /  468     Loss_generator:  0.69798743724823     Loss_discriminator:  0.6744788289070129\n",
      "Epoch:  18     Batch:  363  /  468     Loss_generator:  0.6766970753669739     Loss_discriminator:  0.6899986863136292\n",
      "Epoch:  18     Batch:  364  /  468     Loss_generator:  0.7147458791732788     Loss_discriminator:  0.6833245158195496\n",
      "Epoch:  18     Batch:  365  /  468     Loss_generator:  0.7162296175956726     Loss_discriminator:  0.6852885484695435\n",
      "Epoch:  18     Batch:  366  /  468     Loss_generator:  0.7062747478485107     Loss_discriminator:  0.6881811618804932\n",
      "Epoch:  18     Batch:  367  /  468     Loss_generator:  0.6867905259132385     Loss_discriminator:  0.6927257776260376\n",
      "Epoch:  18     Batch:  368  /  468     Loss_generator:  0.6547383666038513     Loss_discriminator:  0.6755770444869995\n",
      "Epoch:  18     Batch:  369  /  468     Loss_generator:  0.7174687385559082     Loss_discriminator:  0.6850734949111938\n",
      "Epoch:  18     Batch:  370  /  468     Loss_generator:  0.7769994139671326     Loss_discriminator:  0.6915273666381836\n",
      "Epoch:  18     Batch:  371  /  468     Loss_generator:  0.765231728553772     Loss_discriminator:  0.6897375583648682\n",
      "Epoch:  18     Batch:  372  /  468     Loss_generator:  0.7431883215904236     Loss_discriminator:  0.6826461553573608\n",
      "Epoch:  18     Batch:  373  /  468     Loss_generator:  0.7037039399147034     Loss_discriminator:  0.68692946434021\n",
      "Epoch:  18     Batch:  374  /  468     Loss_generator:  0.6694389581680298     Loss_discriminator:  0.6989609003067017\n",
      "Epoch:  18     Batch:  375  /  468     Loss_generator:  0.6654840707778931     Loss_discriminator:  0.6894988417625427\n",
      "Epoch:  18     Batch:  376  /  468     Loss_generator:  0.703278660774231     Loss_discriminator:  0.681609570980072\n",
      "Epoch:  18     Batch:  377  /  468     Loss_generator:  0.7145196795463562     Loss_discriminator:  0.6860583424568176\n",
      "Epoch:  18     Batch:  378  /  468     Loss_generator:  0.7200213670730591     Loss_discriminator:  0.6837030053138733\n",
      "Epoch:  18     Batch:  379  /  468     Loss_generator:  0.7074089050292969     Loss_discriminator:  0.6862972974777222\n",
      "Epoch:  18     Batch:  380  /  468     Loss_generator:  0.7199797630310059     Loss_discriminator:  0.6831516623497009\n",
      "Epoch:  18     Batch:  381  /  468     Loss_generator:  0.7344598770141602     Loss_discriminator:  0.6808533072471619\n",
      "Epoch:  18     Batch:  382  /  468     Loss_generator:  0.7421165108680725     Loss_discriminator:  0.6850317716598511\n",
      "Epoch:  18     Batch:  383  /  468     Loss_generator:  0.7334789037704468     Loss_discriminator:  0.6834779977798462\n",
      "Epoch:  18     Batch:  384  /  468     Loss_generator:  0.6962231397628784     Loss_discriminator:  0.6765762567520142\n",
      "Epoch:  18     Batch:  385  /  468     Loss_generator:  0.6846110820770264     Loss_discriminator:  0.6839684247970581\n",
      "Epoch:  18     Batch:  386  /  468     Loss_generator:  0.6867953538894653     Loss_discriminator:  0.6829297542572021\n",
      "Epoch:  18     Batch:  387  /  468     Loss_generator:  0.7260007262229919     Loss_discriminator:  0.6976511478424072\n",
      "Epoch:  18     Batch:  388  /  468     Loss_generator:  0.7401530146598816     Loss_discriminator:  0.6781343221664429\n",
      "Epoch:  18     Batch:  389  /  468     Loss_generator:  0.7400643825531006     Loss_discriminator:  0.6830132007598877\n",
      "Epoch:  18     Batch:  390  /  468     Loss_generator:  0.695134162902832     Loss_discriminator:  0.6894324421882629\n",
      "Epoch:  18     Batch:  391  /  468     Loss_generator:  0.6690577268600464     Loss_discriminator:  0.6879290342330933\n",
      "Epoch:  18     Batch:  392  /  468     Loss_generator:  0.658126711845398     Loss_discriminator:  0.6818143129348755\n",
      "Epoch:  18     Batch:  393  /  468     Loss_generator:  0.6575440168380737     Loss_discriminator:  0.6914162635803223\n",
      "Epoch:  18     Batch:  394  /  468     Loss_generator:  0.6993722915649414     Loss_discriminator:  0.6803712248802185\n",
      "Epoch:  18     Batch:  395  /  468     Loss_generator:  0.7159242630004883     Loss_discriminator:  0.6759334802627563\n",
      "Epoch:  18     Batch:  396  /  468     Loss_generator:  0.77870774269104     Loss_discriminator:  0.7062222957611084\n",
      "Epoch:  18     Batch:  397  /  468     Loss_generator:  0.7416266202926636     Loss_discriminator:  0.6834108233451843\n",
      "Epoch:  18     Batch:  398  /  468     Loss_generator:  0.7199037075042725     Loss_discriminator:  0.6753814220428467\n",
      "Epoch:  18     Batch:  399  /  468     Loss_generator:  0.7283097505569458     Loss_discriminator:  0.6875227689743042\n",
      "Epoch:  18     Batch:  400  /  468     Loss_generator:  0.703066349029541     Loss_discriminator:  0.6815011501312256\n",
      "Epoch:  18     Batch:  401  /  468     Loss_generator:  0.6900951266288757     Loss_discriminator:  0.6947030425071716\n",
      "Epoch:  18     Batch:  402  /  468     Loss_generator:  0.7019981145858765     Loss_discriminator:  0.6797892451286316\n",
      "Epoch:  18     Batch:  403  /  468     Loss_generator:  0.6835681200027466     Loss_discriminator:  0.693270742893219\n",
      "Epoch:  18     Batch:  404  /  468     Loss_generator:  0.7154245376586914     Loss_discriminator:  0.6906914710998535\n",
      "Epoch:  18     Batch:  405  /  468     Loss_generator:  0.7216777205467224     Loss_discriminator:  0.6835187673568726\n",
      "Epoch:  18     Batch:  406  /  468     Loss_generator:  0.7272587418556213     Loss_discriminator:  0.6830205917358398\n",
      "Epoch:  18     Batch:  407  /  468     Loss_generator:  0.7284753322601318     Loss_discriminator:  0.6957352161407471\n",
      "Epoch:  18     Batch:  408  /  468     Loss_generator:  0.7072793245315552     Loss_discriminator:  0.701695442199707\n",
      "Epoch:  18     Batch:  409  /  468     Loss_generator:  0.6949418783187866     Loss_discriminator:  0.6880122423171997\n",
      "Epoch:  18     Batch:  410  /  468     Loss_generator:  0.6902638077735901     Loss_discriminator:  0.6974144577980042\n",
      "Epoch:  18     Batch:  411  /  468     Loss_generator:  0.7071278691291809     Loss_discriminator:  0.689958393573761\n",
      "Epoch:  18     Batch:  412  /  468     Loss_generator:  0.7166098356246948     Loss_discriminator:  0.6636011600494385\n",
      "Epoch:  18     Batch:  413  /  468     Loss_generator:  0.7100609540939331     Loss_discriminator:  0.6833347082138062\n",
      "Epoch:  18     Batch:  414  /  468     Loss_generator:  0.700089693069458     Loss_discriminator:  0.6741954684257507\n",
      "Epoch:  18     Batch:  415  /  468     Loss_generator:  0.7222800850868225     Loss_discriminator:  0.6841151714324951\n",
      "Epoch:  18     Batch:  416  /  468     Loss_generator:  0.7421512603759766     Loss_discriminator:  0.679102897644043\n",
      "Epoch:  18     Batch:  417  /  468     Loss_generator:  0.7543088793754578     Loss_discriminator:  0.6906760931015015\n",
      "Epoch:  18     Batch:  418  /  468     Loss_generator:  0.732637882232666     Loss_discriminator:  0.6884135007858276\n",
      "Epoch:  18     Batch:  419  /  468     Loss_generator:  0.7130478620529175     Loss_discriminator:  0.6845282316207886\n",
      "Epoch:  18     Batch:  420  /  468     Loss_generator:  0.6938104629516602     Loss_discriminator:  0.6764280796051025\n",
      "Epoch:  18     Batch:  421  /  468     Loss_generator:  0.7412549257278442     Loss_discriminator:  0.6903640031814575\n",
      "Epoch:  18     Batch:  422  /  468     Loss_generator:  0.7081011533737183     Loss_discriminator:  0.6864231824874878\n",
      "Epoch:  18     Batch:  423  /  468     Loss_generator:  0.6833595633506775     Loss_discriminator:  0.6799370646476746\n",
      "Epoch:  18     Batch:  424  /  468     Loss_generator:  0.6739135384559631     Loss_discriminator:  0.686057448387146\n",
      "Epoch:  18     Batch:  425  /  468     Loss_generator:  0.700126588344574     Loss_discriminator:  0.686566948890686\n",
      "Epoch:  18     Batch:  426  /  468     Loss_generator:  0.7544746398925781     Loss_discriminator:  0.6832736134529114\n",
      "Epoch:  18     Batch:  427  /  468     Loss_generator:  0.7676726579666138     Loss_discriminator:  0.6890641450881958\n",
      "Epoch:  18     Batch:  428  /  468     Loss_generator:  0.7160568833351135     Loss_discriminator:  0.6910183429718018\n",
      "Epoch:  18     Batch:  429  /  468     Loss_generator:  0.7084203958511353     Loss_discriminator:  0.6907682418823242\n",
      "Epoch:  18     Batch:  430  /  468     Loss_generator:  0.6641826629638672     Loss_discriminator:  0.6899411678314209\n",
      "Epoch:  18     Batch:  431  /  468     Loss_generator:  0.6807266473770142     Loss_discriminator:  0.6899532675743103\n",
      "Epoch:  18     Batch:  432  /  468     Loss_generator:  0.7199523448944092     Loss_discriminator:  0.6866232752799988\n",
      "Epoch:  18     Batch:  433  /  468     Loss_generator:  0.7503676414489746     Loss_discriminator:  0.6797143220901489\n",
      "Epoch:  18     Batch:  434  /  468     Loss_generator:  0.7133098840713501     Loss_discriminator:  0.6925997138023376\n",
      "Epoch:  18     Batch:  435  /  468     Loss_generator:  0.6976301074028015     Loss_discriminator:  0.6767541766166687\n",
      "Epoch:  18     Batch:  436  /  468     Loss_generator:  0.6717984676361084     Loss_discriminator:  0.6822758316993713\n",
      "Epoch:  18     Batch:  437  /  468     Loss_generator:  0.6850142478942871     Loss_discriminator:  0.6932968497276306\n",
      "Epoch:  18     Batch:  438  /  468     Loss_generator:  0.7152225375175476     Loss_discriminator:  0.6838539242744446\n",
      "Epoch:  18     Batch:  439  /  468     Loss_generator:  0.7537325620651245     Loss_discriminator:  0.7048891186714172\n",
      "Epoch:  18     Batch:  440  /  468     Loss_generator:  0.7673817873001099     Loss_discriminator:  0.6833055019378662\n",
      "Epoch:  18     Batch:  441  /  468     Loss_generator:  0.736985445022583     Loss_discriminator:  0.6756407022476196\n",
      "Epoch:  18     Batch:  442  /  468     Loss_generator:  0.6768976449966431     Loss_discriminator:  0.6694962382316589\n",
      "Epoch:  18     Batch:  443  /  468     Loss_generator:  0.6556830406188965     Loss_discriminator:  0.69678795337677\n",
      "Epoch:  18     Batch:  444  /  468     Loss_generator:  0.6638537645339966     Loss_discriminator:  0.6845168471336365\n",
      "Epoch:  18     Batch:  445  /  468     Loss_generator:  0.6949095129966736     Loss_discriminator:  0.6879062056541443\n",
      "Epoch:  18     Batch:  446  /  468     Loss_generator:  0.7230145335197449     Loss_discriminator:  0.6804826259613037\n",
      "Epoch:  18     Batch:  447  /  468     Loss_generator:  0.7335854768753052     Loss_discriminator:  0.6836416125297546\n",
      "Epoch:  18     Batch:  448  /  468     Loss_generator:  0.7347477674484253     Loss_discriminator:  0.6884924173355103\n",
      "Epoch:  18     Batch:  449  /  468     Loss_generator:  0.6972888708114624     Loss_discriminator:  0.6938514113426208\n",
      "Epoch:  18     Batch:  450  /  468     Loss_generator:  0.6632524728775024     Loss_discriminator:  0.6883395314216614\n",
      "Epoch:  18     Batch:  451  /  468     Loss_generator:  0.7169806361198425     Loss_discriminator:  0.6791160106658936\n",
      "Epoch:  18     Batch:  452  /  468     Loss_generator:  0.7353757619857788     Loss_discriminator:  0.6817220449447632\n",
      "Epoch:  18     Batch:  453  /  468     Loss_generator:  0.771798849105835     Loss_discriminator:  0.6867709159851074\n",
      "Epoch:  18     Batch:  454  /  468     Loss_generator:  0.7540745735168457     Loss_discriminator:  0.6777592897415161\n",
      "Epoch:  18     Batch:  455  /  468     Loss_generator:  0.7087571620941162     Loss_discriminator:  0.701142430305481\n",
      "Epoch:  18     Batch:  456  /  468     Loss_generator:  0.6676154732704163     Loss_discriminator:  0.6981543302536011\n",
      "Epoch:  18     Batch:  457  /  468     Loss_generator:  0.6796581745147705     Loss_discriminator:  0.687606692314148\n",
      "Epoch:  18     Batch:  458  /  468     Loss_generator:  0.6979103684425354     Loss_discriminator:  0.6728391647338867\n",
      "Epoch:  18     Batch:  459  /  468     Loss_generator:  0.7219749093055725     Loss_discriminator:  0.687818169593811\n",
      "Epoch:  18     Batch:  460  /  468     Loss_generator:  0.7225183248519897     Loss_discriminator:  0.6841795444488525\n",
      "Epoch:  18     Batch:  461  /  468     Loss_generator:  0.6919640898704529     Loss_discriminator:  0.6935123205184937\n",
      "Epoch:  18     Batch:  462  /  468     Loss_generator:  0.6875886917114258     Loss_discriminator:  0.6851763725280762\n",
      "Epoch:  18     Batch:  463  /  468     Loss_generator:  0.719318151473999     Loss_discriminator:  0.6944983005523682\n",
      "Epoch:  18     Batch:  464  /  468     Loss_generator:  0.7450978755950928     Loss_discriminator:  0.6685022115707397\n",
      "Epoch:  18     Batch:  465  /  468     Loss_generator:  0.7129515409469604     Loss_discriminator:  0.6929097175598145\n",
      "Epoch:  18     Batch:  466  /  468     Loss_generator:  0.7196311950683594     Loss_discriminator:  0.6747649908065796\n",
      "Epoch:  18     Batch:  467  /  468     Loss_generator:  0.7143135666847229     Loss_discriminator:  0.6829424500465393\n",
      "Epoch:  19     Batch:  0  /  468     Loss_generator:  0.7146799564361572     Loss_discriminator:  0.678146243095398\n",
      "Epoch:  19     Batch:  1  /  468     Loss_generator:  0.68132084608078     Loss_discriminator:  0.6838130354881287\n",
      "Epoch:  19     Batch:  2  /  468     Loss_generator:  0.6625403165817261     Loss_discriminator:  0.6810405254364014\n",
      "Epoch:  19     Batch:  3  /  468     Loss_generator:  0.654120683670044     Loss_discriminator:  0.6886619329452515\n",
      "Epoch:  19     Batch:  4  /  468     Loss_generator:  0.7178815603256226     Loss_discriminator:  0.7009112238883972\n",
      "Epoch:  19     Batch:  5  /  468     Loss_generator:  0.7593207359313965     Loss_discriminator:  0.6837654113769531\n",
      "Epoch:  19     Batch:  6  /  468     Loss_generator:  0.7616345882415771     Loss_discriminator:  0.6857987642288208\n",
      "Epoch:  19     Batch:  7  /  468     Loss_generator:  0.7269458770751953     Loss_discriminator:  0.6882607340812683\n",
      "Epoch:  19     Batch:  8  /  468     Loss_generator:  0.6951315999031067     Loss_discriminator:  0.6864548921585083\n",
      "Epoch:  19     Batch:  9  /  468     Loss_generator:  0.6776396036148071     Loss_discriminator:  0.6773048043251038\n",
      "Epoch:  19     Batch:  10  /  468     Loss_generator:  0.7348026037216187     Loss_discriminator:  0.6783615350723267\n",
      "Epoch:  19     Batch:  11  /  468     Loss_generator:  0.7423065900802612     Loss_discriminator:  0.6868366599082947\n",
      "Epoch:  19     Batch:  12  /  468     Loss_generator:  0.753042459487915     Loss_discriminator:  0.682219386100769\n",
      "Epoch:  19     Batch:  13  /  468     Loss_generator:  0.714759349822998     Loss_discriminator:  0.6756652593612671\n",
      "Epoch:  19     Batch:  14  /  468     Loss_generator:  0.6934025287628174     Loss_discriminator:  0.6816059350967407\n",
      "Epoch:  19     Batch:  15  /  468     Loss_generator:  0.7118979692459106     Loss_discriminator:  0.6816118955612183\n",
      "Epoch:  19     Batch:  16  /  468     Loss_generator:  0.7019556164741516     Loss_discriminator:  0.6799588203430176\n",
      "Epoch:  19     Batch:  17  /  468     Loss_generator:  0.7001066207885742     Loss_discriminator:  0.6832106113433838\n",
      "Epoch:  19     Batch:  18  /  468     Loss_generator:  0.7073554396629333     Loss_discriminator:  0.6756778955459595\n",
      "Epoch:  19     Batch:  19  /  468     Loss_generator:  0.6980661153793335     Loss_discriminator:  0.6860811710357666\n",
      "Epoch:  19     Batch:  20  /  468     Loss_generator:  0.6907011270523071     Loss_discriminator:  0.6818578243255615\n",
      "Epoch:  19     Batch:  21  /  468     Loss_generator:  0.7012461423873901     Loss_discriminator:  0.6868430376052856\n",
      "Epoch:  19     Batch:  22  /  468     Loss_generator:  0.7510148286819458     Loss_discriminator:  0.678082287311554\n",
      "Epoch:  19     Batch:  23  /  468     Loss_generator:  0.7732143998146057     Loss_discriminator:  0.690468430519104\n",
      "Epoch:  19     Batch:  24  /  468     Loss_generator:  0.6937317848205566     Loss_discriminator:  0.6943756341934204\n",
      "Epoch:  19     Batch:  25  /  468     Loss_generator:  0.6666222810745239     Loss_discriminator:  0.6873477101325989\n",
      "Epoch:  19     Batch:  26  /  468     Loss_generator:  0.6699576377868652     Loss_discriminator:  0.6954067945480347\n",
      "Epoch:  19     Batch:  27  /  468     Loss_generator:  0.7211143970489502     Loss_discriminator:  0.6850079894065857\n",
      "Epoch:  19     Batch:  28  /  468     Loss_generator:  0.7512516379356384     Loss_discriminator:  0.6774618625640869\n",
      "Epoch:  19     Batch:  29  /  468     Loss_generator:  0.7284886837005615     Loss_discriminator:  0.7011121511459351\n",
      "Epoch:  19     Batch:  30  /  468     Loss_generator:  0.6720726490020752     Loss_discriminator:  0.6874384880065918\n",
      "Epoch:  19     Batch:  31  /  468     Loss_generator:  0.6685346364974976     Loss_discriminator:  0.6870414614677429\n",
      "Epoch:  19     Batch:  32  /  468     Loss_generator:  0.7090227603912354     Loss_discriminator:  0.6876980066299438\n",
      "Epoch:  19     Batch:  33  /  468     Loss_generator:  0.776505708694458     Loss_discriminator:  0.6765933036804199\n",
      "Epoch:  19     Batch:  34  /  468     Loss_generator:  0.7523279190063477     Loss_discriminator:  0.6984380483627319\n",
      "Epoch:  19     Batch:  35  /  468     Loss_generator:  0.7072073221206665     Loss_discriminator:  0.6840761303901672\n",
      "Epoch:  19     Batch:  36  /  468     Loss_generator:  0.6947689652442932     Loss_discriminator:  0.6687078475952148\n",
      "Epoch:  19     Batch:  37  /  468     Loss_generator:  0.7114669680595398     Loss_discriminator:  0.6823985576629639\n",
      "Epoch:  19     Batch:  38  /  468     Loss_generator:  0.7122195959091187     Loss_discriminator:  0.6844354271888733\n",
      "Epoch:  19     Batch:  39  /  468     Loss_generator:  0.7271934747695923     Loss_discriminator:  0.6832789182662964\n",
      "Epoch:  19     Batch:  40  /  468     Loss_generator:  0.6988493204116821     Loss_discriminator:  0.6795752048492432\n",
      "Epoch:  19     Batch:  41  /  468     Loss_generator:  0.7174660563468933     Loss_discriminator:  0.6909679174423218\n",
      "Epoch:  19     Batch:  42  /  468     Loss_generator:  0.7316319942474365     Loss_discriminator:  0.6689900755882263\n",
      "Epoch:  19     Batch:  43  /  468     Loss_generator:  0.7165740132331848     Loss_discriminator:  0.6804101467132568\n",
      "Epoch:  19     Batch:  44  /  468     Loss_generator:  0.7164424657821655     Loss_discriminator:  0.6962282657623291\n",
      "Epoch:  19     Batch:  45  /  468     Loss_generator:  0.6900755763053894     Loss_discriminator:  0.6844429969787598\n",
      "Epoch:  19     Batch:  46  /  468     Loss_generator:  0.6896159648895264     Loss_discriminator:  0.6988323926925659\n",
      "Epoch:  19     Batch:  47  /  468     Loss_generator:  0.7017309069633484     Loss_discriminator:  0.6807094812393188\n",
      "Epoch:  19     Batch:  48  /  468     Loss_generator:  0.7292228937149048     Loss_discriminator:  0.6917081475257874\n",
      "Epoch:  19     Batch:  49  /  468     Loss_generator:  0.7170835733413696     Loss_discriminator:  0.6995496153831482\n",
      "Epoch:  19     Batch:  50  /  468     Loss_generator:  0.705234944820404     Loss_discriminator:  0.6796715259552002\n",
      "Epoch:  19     Batch:  51  /  468     Loss_generator:  0.7074015736579895     Loss_discriminator:  0.6906125545501709\n",
      "Epoch:  19     Batch:  52  /  468     Loss_generator:  0.7047637701034546     Loss_discriminator:  0.6702603101730347\n",
      "Epoch:  19     Batch:  53  /  468     Loss_generator:  0.6851654648780823     Loss_discriminator:  0.6842490434646606\n",
      "Epoch:  19     Batch:  54  /  468     Loss_generator:  0.7289308309555054     Loss_discriminator:  0.6862604022026062\n",
      "Epoch:  19     Batch:  55  /  468     Loss_generator:  0.7474676370620728     Loss_discriminator:  0.6809871196746826\n",
      "Epoch:  19     Batch:  56  /  468     Loss_generator:  0.7662031650543213     Loss_discriminator:  0.6696171760559082\n",
      "Epoch:  19     Batch:  57  /  468     Loss_generator:  0.7411798238754272     Loss_discriminator:  0.6836988925933838\n",
      "Epoch:  19     Batch:  58  /  468     Loss_generator:  0.6773112416267395     Loss_discriminator:  0.6906248927116394\n",
      "Epoch:  19     Batch:  59  /  468     Loss_generator:  0.6744002103805542     Loss_discriminator:  0.6685727834701538\n",
      "Epoch:  19     Batch:  60  /  468     Loss_generator:  0.6958785653114319     Loss_discriminator:  0.6942404508590698\n",
      "Epoch:  19     Batch:  61  /  468     Loss_generator:  0.7312189936637878     Loss_discriminator:  0.69684237241745\n",
      "Epoch:  19     Batch:  62  /  468     Loss_generator:  0.7383875846862793     Loss_discriminator:  0.6756144165992737\n",
      "Epoch:  19     Batch:  63  /  468     Loss_generator:  0.7237405776977539     Loss_discriminator:  0.6824486255645752\n",
      "Epoch:  19     Batch:  64  /  468     Loss_generator:  0.69673091173172     Loss_discriminator:  0.6801377534866333\n",
      "Epoch:  19     Batch:  65  /  468     Loss_generator:  0.696462869644165     Loss_discriminator:  0.6873976588249207\n",
      "Epoch:  19     Batch:  66  /  468     Loss_generator:  0.7503722906112671     Loss_discriminator:  0.7007157802581787\n",
      "Epoch:  19     Batch:  67  /  468     Loss_generator:  0.7260357141494751     Loss_discriminator:  0.6768689155578613\n",
      "Epoch:  19     Batch:  68  /  468     Loss_generator:  0.7128387689590454     Loss_discriminator:  0.6917871236801147\n",
      "Epoch:  19     Batch:  69  /  468     Loss_generator:  0.6965889930725098     Loss_discriminator:  0.663551926612854\n",
      "Epoch:  19     Batch:  70  /  468     Loss_generator:  0.7027886509895325     Loss_discriminator:  0.6902003884315491\n",
      "Epoch:  19     Batch:  71  /  468     Loss_generator:  0.7087773084640503     Loss_discriminator:  0.684180736541748\n",
      "Epoch:  19     Batch:  72  /  468     Loss_generator:  0.7085232734680176     Loss_discriminator:  0.682709813117981\n",
      "Epoch:  19     Batch:  73  /  468     Loss_generator:  0.7053737640380859     Loss_discriminator:  0.6879968643188477\n",
      "Epoch:  19     Batch:  74  /  468     Loss_generator:  0.7170567512512207     Loss_discriminator:  0.7005889415740967\n",
      "Epoch:  19     Batch:  75  /  468     Loss_generator:  0.7271196842193604     Loss_discriminator:  0.6994818449020386\n",
      "Epoch:  19     Batch:  76  /  468     Loss_generator:  0.7391306161880493     Loss_discriminator:  0.6832225918769836\n",
      "Epoch:  19     Batch:  77  /  468     Loss_generator:  0.6902933120727539     Loss_discriminator:  0.6893840432167053\n",
      "Epoch:  19     Batch:  78  /  468     Loss_generator:  0.6956861019134521     Loss_discriminator:  0.6840046644210815\n",
      "Epoch:  19     Batch:  79  /  468     Loss_generator:  0.6897692680358887     Loss_discriminator:  0.6754522323608398\n",
      "Epoch:  19     Batch:  80  /  468     Loss_generator:  0.7273595333099365     Loss_discriminator:  0.7065229415893555\n",
      "Epoch:  19     Batch:  81  /  468     Loss_generator:  0.7263993620872498     Loss_discriminator:  0.7032420635223389\n",
      "Epoch:  19     Batch:  82  /  468     Loss_generator:  0.7322774529457092     Loss_discriminator:  0.6733921766281128\n",
      "Epoch:  19     Batch:  83  /  468     Loss_generator:  0.6808031797409058     Loss_discriminator:  0.7001383304595947\n",
      "Epoch:  19     Batch:  84  /  468     Loss_generator:  0.7310947775840759     Loss_discriminator:  0.6956969499588013\n",
      "Epoch:  19     Batch:  85  /  468     Loss_generator:  0.7511513233184814     Loss_discriminator:  0.676903247833252\n",
      "Epoch:  19     Batch:  86  /  468     Loss_generator:  0.72551429271698     Loss_discriminator:  0.6937128901481628\n",
      "Epoch:  19     Batch:  87  /  468     Loss_generator:  0.6897019147872925     Loss_discriminator:  0.6834327578544617\n",
      "Epoch:  19     Batch:  88  /  468     Loss_generator:  0.670344352722168     Loss_discriminator:  0.6943536400794983\n",
      "Epoch:  19     Batch:  89  /  468     Loss_generator:  0.6929870247840881     Loss_discriminator:  0.6796836853027344\n",
      "Epoch:  19     Batch:  90  /  468     Loss_generator:  0.703619122505188     Loss_discriminator:  0.6886088848114014\n",
      "Epoch:  19     Batch:  91  /  468     Loss_generator:  0.7484773397445679     Loss_discriminator:  0.6927126049995422\n",
      "Epoch:  19     Batch:  92  /  468     Loss_generator:  0.730398952960968     Loss_discriminator:  0.6874693632125854\n",
      "Epoch:  19     Batch:  93  /  468     Loss_generator:  0.6812747716903687     Loss_discriminator:  0.7011604309082031\n",
      "Epoch:  19     Batch:  94  /  468     Loss_generator:  0.707598090171814     Loss_discriminator:  0.6836580038070679\n",
      "Epoch:  19     Batch:  95  /  468     Loss_generator:  0.7223100066184998     Loss_discriminator:  0.6950393319129944\n",
      "Epoch:  19     Batch:  96  /  468     Loss_generator:  0.7390514016151428     Loss_discriminator:  0.6859967708587646\n",
      "Epoch:  19     Batch:  97  /  468     Loss_generator:  0.7224576473236084     Loss_discriminator:  0.6662583947181702\n",
      "Epoch:  19     Batch:  98  /  468     Loss_generator:  0.7050315141677856     Loss_discriminator:  0.6851781010627747\n",
      "Epoch:  19     Batch:  99  /  468     Loss_generator:  0.7309134006500244     Loss_discriminator:  0.6881824135780334\n",
      "Epoch:  19     Batch:  100  /  468     Loss_generator:  0.75140380859375     Loss_discriminator:  0.6871578097343445\n",
      "Epoch:  19     Batch:  101  /  468     Loss_generator:  0.7079471349716187     Loss_discriminator:  0.6797537803649902\n",
      "Epoch:  19     Batch:  102  /  468     Loss_generator:  0.6501233577728271     Loss_discriminator:  0.6813715100288391\n",
      "Epoch:  19     Batch:  103  /  468     Loss_generator:  0.6617083549499512     Loss_discriminator:  0.6984236836433411\n",
      "Epoch:  19     Batch:  104  /  468     Loss_generator:  0.7252044081687927     Loss_discriminator:  0.6883869171142578\n",
      "Epoch:  19     Batch:  105  /  468     Loss_generator:  0.800635814666748     Loss_discriminator:  0.6909686923027039\n",
      "Epoch:  19     Batch:  106  /  468     Loss_generator:  0.7769472599029541     Loss_discriminator:  0.700748085975647\n",
      "Epoch:  19     Batch:  107  /  468     Loss_generator:  0.7146296501159668     Loss_discriminator:  0.6724479794502258\n",
      "Epoch:  19     Batch:  108  /  468     Loss_generator:  0.6990698575973511     Loss_discriminator:  0.706423819065094\n",
      "Epoch:  19     Batch:  109  /  468     Loss_generator:  0.685814619064331     Loss_discriminator:  0.6786617040634155\n",
      "Epoch:  19     Batch:  110  /  468     Loss_generator:  0.6766225099563599     Loss_discriminator:  0.6693872213363647\n",
      "Epoch:  19     Batch:  111  /  468     Loss_generator:  0.6871770620346069     Loss_discriminator:  0.6775188446044922\n",
      "Epoch:  19     Batch:  112  /  468     Loss_generator:  0.6859065294265747     Loss_discriminator:  0.6858645677566528\n",
      "Epoch:  19     Batch:  113  /  468     Loss_generator:  0.7022483944892883     Loss_discriminator:  0.6768523454666138\n",
      "Epoch:  19     Batch:  114  /  468     Loss_generator:  0.7304153442382812     Loss_discriminator:  0.6867758631706238\n",
      "Epoch:  19     Batch:  115  /  468     Loss_generator:  0.7309132814407349     Loss_discriminator:  0.6908848881721497\n",
      "Epoch:  19     Batch:  116  /  468     Loss_generator:  0.7090871930122375     Loss_discriminator:  0.7020401358604431\n",
      "Epoch:  19     Batch:  117  /  468     Loss_generator:  0.7008139491081238     Loss_discriminator:  0.6878991723060608\n",
      "Epoch:  19     Batch:  118  /  468     Loss_generator:  0.744412899017334     Loss_discriminator:  0.6801767945289612\n",
      "Epoch:  19     Batch:  119  /  468     Loss_generator:  0.7430570721626282     Loss_discriminator:  0.6968482732772827\n",
      "Epoch:  19     Batch:  120  /  468     Loss_generator:  0.716818630695343     Loss_discriminator:  0.6787897944450378\n",
      "Epoch:  19     Batch:  121  /  468     Loss_generator:  0.6988073587417603     Loss_discriminator:  0.6947616934776306\n",
      "Epoch:  19     Batch:  122  /  468     Loss_generator:  0.6700598001480103     Loss_discriminator:  0.6846142411231995\n",
      "Epoch:  19     Batch:  123  /  468     Loss_generator:  0.6964166164398193     Loss_discriminator:  0.6799707412719727\n",
      "Epoch:  19     Batch:  124  /  468     Loss_generator:  0.7226567268371582     Loss_discriminator:  0.6973704099655151\n",
      "Epoch:  19     Batch:  125  /  468     Loss_generator:  0.7089835405349731     Loss_discriminator:  0.6768944263458252\n",
      "Epoch:  19     Batch:  126  /  468     Loss_generator:  0.6658310890197754     Loss_discriminator:  0.6790679693222046\n",
      "Epoch:  19     Batch:  127  /  468     Loss_generator:  0.687068521976471     Loss_discriminator:  0.6736605763435364\n",
      "Epoch:  19     Batch:  128  /  468     Loss_generator:  0.7281068563461304     Loss_discriminator:  0.6874545216560364\n",
      "Epoch:  19     Batch:  129  /  468     Loss_generator:  0.7395557165145874     Loss_discriminator:  0.6769429445266724\n",
      "Epoch:  19     Batch:  130  /  468     Loss_generator:  0.7144123911857605     Loss_discriminator:  0.6695080399513245\n",
      "Epoch:  19     Batch:  131  /  468     Loss_generator:  0.7305250763893127     Loss_discriminator:  0.677872359752655\n",
      "Epoch:  19     Batch:  132  /  468     Loss_generator:  0.7177844047546387     Loss_discriminator:  0.688901424407959\n",
      "Epoch:  19     Batch:  133  /  468     Loss_generator:  0.6933193206787109     Loss_discriminator:  0.6776003837585449\n",
      "Epoch:  19     Batch:  134  /  468     Loss_generator:  0.7060815691947937     Loss_discriminator:  0.6955791711807251\n",
      "Epoch:  19     Batch:  135  /  468     Loss_generator:  0.7265094518661499     Loss_discriminator:  0.681315541267395\n",
      "Epoch:  19     Batch:  136  /  468     Loss_generator:  0.7250564694404602     Loss_discriminator:  0.6876641511917114\n",
      "Epoch:  19     Batch:  137  /  468     Loss_generator:  0.7071789503097534     Loss_discriminator:  0.6984483003616333\n",
      "Epoch:  19     Batch:  138  /  468     Loss_generator:  0.7051607370376587     Loss_discriminator:  0.6909698247909546\n",
      "Epoch:  19     Batch:  139  /  468     Loss_generator:  0.6983391642570496     Loss_discriminator:  0.6874071955680847\n",
      "Epoch:  19     Batch:  140  /  468     Loss_generator:  0.7347191572189331     Loss_discriminator:  0.6939226388931274\n",
      "Epoch:  19     Batch:  141  /  468     Loss_generator:  0.7416883707046509     Loss_discriminator:  0.6876170635223389\n",
      "Epoch:  19     Batch:  142  /  468     Loss_generator:  0.7327809929847717     Loss_discriminator:  0.7060880661010742\n",
      "Epoch:  19     Batch:  143  /  468     Loss_generator:  0.6918364763259888     Loss_discriminator:  0.6839942932128906\n",
      "Epoch:  19     Batch:  144  /  468     Loss_generator:  0.6652822494506836     Loss_discriminator:  0.6996473073959351\n",
      "Epoch:  19     Batch:  145  /  468     Loss_generator:  0.6753642559051514     Loss_discriminator:  0.6691075563430786\n",
      "Epoch:  19     Batch:  146  /  468     Loss_generator:  0.7225750684738159     Loss_discriminator:  0.7027601003646851\n",
      "Epoch:  19     Batch:  147  /  468     Loss_generator:  0.7848200798034668     Loss_discriminator:  0.6873273849487305\n",
      "Epoch:  19     Batch:  148  /  468     Loss_generator:  0.7771161794662476     Loss_discriminator:  0.6846193075180054\n",
      "Epoch:  19     Batch:  149  /  468     Loss_generator:  0.7049223780632019     Loss_discriminator:  0.6891957521438599\n",
      "Epoch:  19     Batch:  150  /  468     Loss_generator:  0.6629935503005981     Loss_discriminator:  0.6809875965118408\n",
      "Epoch:  19     Batch:  151  /  468     Loss_generator:  0.674391508102417     Loss_discriminator:  0.6719790101051331\n",
      "Epoch:  19     Batch:  152  /  468     Loss_generator:  0.6894292831420898     Loss_discriminator:  0.6761561632156372\n",
      "Epoch:  19     Batch:  153  /  468     Loss_generator:  0.7590872049331665     Loss_discriminator:  0.6787420511245728\n",
      "Epoch:  19     Batch:  154  /  468     Loss_generator:  0.8039223551750183     Loss_discriminator:  0.6845301389694214\n",
      "Epoch:  19     Batch:  155  /  468     Loss_generator:  0.7689028978347778     Loss_discriminator:  0.6871752142906189\n",
      "Epoch:  19     Batch:  156  /  468     Loss_generator:  0.6935005187988281     Loss_discriminator:  0.6871672868728638\n",
      "Epoch:  19     Batch:  157  /  468     Loss_generator:  0.6492729187011719     Loss_discriminator:  0.6673256158828735\n",
      "Epoch:  19     Batch:  158  /  468     Loss_generator:  0.6953731775283813     Loss_discriminator:  0.7184324264526367\n",
      "Epoch:  19     Batch:  159  /  468     Loss_generator:  0.7451446056365967     Loss_discriminator:  0.6946005821228027\n",
      "Epoch:  19     Batch:  160  /  468     Loss_generator:  0.759646475315094     Loss_discriminator:  0.687872588634491\n",
      "Epoch:  19     Batch:  161  /  468     Loss_generator:  0.7554711103439331     Loss_discriminator:  0.6834176778793335\n",
      "Epoch:  19     Batch:  162  /  468     Loss_generator:  0.7080891132354736     Loss_discriminator:  0.6956954598426819\n",
      "Epoch:  19     Batch:  163  /  468     Loss_generator:  0.6617709398269653     Loss_discriminator:  0.6953305006027222\n",
      "Epoch:  19     Batch:  164  /  468     Loss_generator:  0.6279041767120361     Loss_discriminator:  0.7006573677062988\n",
      "Epoch:  19     Batch:  165  /  468     Loss_generator:  0.6741613745689392     Loss_discriminator:  0.6859009265899658\n",
      "Epoch:  19     Batch:  166  /  468     Loss_generator:  0.7346378564834595     Loss_discriminator:  0.6905258893966675\n",
      "Epoch:  19     Batch:  167  /  468     Loss_generator:  0.7831507921218872     Loss_discriminator:  0.6999204754829407\n",
      "Epoch:  19     Batch:  168  /  468     Loss_generator:  0.7786729335784912     Loss_discriminator:  0.679042398929596\n",
      "Epoch:  19     Batch:  169  /  468     Loss_generator:  0.7211258411407471     Loss_discriminator:  0.6939345598220825\n",
      "Epoch:  19     Batch:  170  /  468     Loss_generator:  0.6924985647201538     Loss_discriminator:  0.6847724914550781\n",
      "Epoch:  19     Batch:  171  /  468     Loss_generator:  0.6849518418312073     Loss_discriminator:  0.6800293326377869\n",
      "Epoch:  19     Batch:  172  /  468     Loss_generator:  0.6942704916000366     Loss_discriminator:  0.678642988204956\n",
      "Epoch:  19     Batch:  173  /  468     Loss_generator:  0.7282900810241699     Loss_discriminator:  0.6781759262084961\n",
      "Epoch:  19     Batch:  174  /  468     Loss_generator:  0.723146378993988     Loss_discriminator:  0.6872401237487793\n",
      "Epoch:  19     Batch:  175  /  468     Loss_generator:  0.7119609117507935     Loss_discriminator:  0.6903465390205383\n",
      "Epoch:  19     Batch:  176  /  468     Loss_generator:  0.7104679942131042     Loss_discriminator:  0.6981738805770874\n",
      "Epoch:  19     Batch:  177  /  468     Loss_generator:  0.7001965045928955     Loss_discriminator:  0.6845836639404297\n",
      "Epoch:  19     Batch:  178  /  468     Loss_generator:  0.7506719827651978     Loss_discriminator:  0.6883424520492554\n",
      "Epoch:  19     Batch:  179  /  468     Loss_generator:  0.7359271049499512     Loss_discriminator:  0.6876369714736938\n",
      "Epoch:  19     Batch:  180  /  468     Loss_generator:  0.7738716006278992     Loss_discriminator:  0.6899688839912415\n",
      "Epoch:  19     Batch:  181  /  468     Loss_generator:  0.7370615601539612     Loss_discriminator:  0.6756924390792847\n",
      "Epoch:  19     Batch:  182  /  468     Loss_generator:  0.7169843316078186     Loss_discriminator:  0.6800084114074707\n",
      "Epoch:  19     Batch:  183  /  468     Loss_generator:  0.6689425110816956     Loss_discriminator:  0.6932124495506287\n",
      "Epoch:  19     Batch:  184  /  468     Loss_generator:  0.6706090569496155     Loss_discriminator:  0.679419755935669\n",
      "Epoch:  19     Batch:  185  /  468     Loss_generator:  0.6925528645515442     Loss_discriminator:  0.6912516355514526\n",
      "Epoch:  19     Batch:  186  /  468     Loss_generator:  0.6939636468887329     Loss_discriminator:  0.6980288028717041\n",
      "Epoch:  19     Batch:  187  /  468     Loss_generator:  0.7105886936187744     Loss_discriminator:  0.6718775033950806\n",
      "Epoch:  19     Batch:  188  /  468     Loss_generator:  0.712498128414154     Loss_discriminator:  0.6877802610397339\n",
      "Epoch:  19     Batch:  189  /  468     Loss_generator:  0.7402979135513306     Loss_discriminator:  0.6922023892402649\n",
      "Epoch:  19     Batch:  190  /  468     Loss_generator:  0.7069031000137329     Loss_discriminator:  0.6858636140823364\n",
      "Epoch:  19     Batch:  191  /  468     Loss_generator:  0.6977013945579529     Loss_discriminator:  0.6865577697753906\n",
      "Epoch:  19     Batch:  192  /  468     Loss_generator:  0.6833116412162781     Loss_discriminator:  0.6912734508514404\n",
      "Epoch:  19     Batch:  193  /  468     Loss_generator:  0.687813401222229     Loss_discriminator:  0.6948419809341431\n",
      "Epoch:  19     Batch:  194  /  468     Loss_generator:  0.7291022539138794     Loss_discriminator:  0.6791016459465027\n",
      "Epoch:  19     Batch:  195  /  468     Loss_generator:  0.7625827789306641     Loss_discriminator:  0.6983147859573364\n",
      "Epoch:  19     Batch:  196  /  468     Loss_generator:  0.7501482963562012     Loss_discriminator:  0.6936745643615723\n",
      "Epoch:  19     Batch:  197  /  468     Loss_generator:  0.7123937606811523     Loss_discriminator:  0.6760283708572388\n",
      "Epoch:  19     Batch:  198  /  468     Loss_generator:  0.6675301194190979     Loss_discriminator:  0.6953331232070923\n",
      "Epoch:  19     Batch:  199  /  468     Loss_generator:  0.6630168557167053     Loss_discriminator:  0.6678918600082397\n",
      "Epoch:  19     Batch:  200  /  468     Loss_generator:  0.6963244080543518     Loss_discriminator:  0.6861030459403992\n",
      "Epoch:  19     Batch:  201  /  468     Loss_generator:  0.7435636520385742     Loss_discriminator:  0.6774661540985107\n",
      "Epoch:  19     Batch:  202  /  468     Loss_generator:  0.7195196151733398     Loss_discriminator:  0.6764296889305115\n",
      "Epoch:  19     Batch:  203  /  468     Loss_generator:  0.7441280484199524     Loss_discriminator:  0.6981095671653748\n",
      "Epoch:  19     Batch:  204  /  468     Loss_generator:  0.7390514016151428     Loss_discriminator:  0.7000391483306885\n",
      "Epoch:  19     Batch:  205  /  468     Loss_generator:  0.7243756651878357     Loss_discriminator:  0.6744261980056763\n",
      "Epoch:  19     Batch:  206  /  468     Loss_generator:  0.6984720230102539     Loss_discriminator:  0.6735237836837769\n",
      "Epoch:  19     Batch:  207  /  468     Loss_generator:  0.6889709234237671     Loss_discriminator:  0.6844366192817688\n",
      "Epoch:  19     Batch:  208  /  468     Loss_generator:  0.6885766386985779     Loss_discriminator:  0.6815023422241211\n",
      "Epoch:  19     Batch:  209  /  468     Loss_generator:  0.7048469185829163     Loss_discriminator:  0.677058219909668\n",
      "Epoch:  19     Batch:  210  /  468     Loss_generator:  0.7075524926185608     Loss_discriminator:  0.6833500862121582\n",
      "Epoch:  19     Batch:  211  /  468     Loss_generator:  0.7439486980438232     Loss_discriminator:  0.6809813976287842\n",
      "Epoch:  19     Batch:  212  /  468     Loss_generator:  0.7511656284332275     Loss_discriminator:  0.6797205805778503\n",
      "Epoch:  19     Batch:  213  /  468     Loss_generator:  0.7394866943359375     Loss_discriminator:  0.6856310367584229\n",
      "Epoch:  19     Batch:  214  /  468     Loss_generator:  0.6965845227241516     Loss_discriminator:  0.6843967437744141\n",
      "Epoch:  19     Batch:  215  /  468     Loss_generator:  0.7000943422317505     Loss_discriminator:  0.6884250640869141\n",
      "Epoch:  19     Batch:  216  /  468     Loss_generator:  0.6648686528205872     Loss_discriminator:  0.6786531209945679\n",
      "Epoch:  19     Batch:  217  /  468     Loss_generator:  0.6652287244796753     Loss_discriminator:  0.6910414695739746\n",
      "Epoch:  19     Batch:  218  /  468     Loss_generator:  0.681158721446991     Loss_discriminator:  0.6824196577072144\n",
      "Epoch:  19     Batch:  219  /  468     Loss_generator:  0.7659670114517212     Loss_discriminator:  0.6861515045166016\n",
      "Epoch:  19     Batch:  220  /  468     Loss_generator:  0.7632542848587036     Loss_discriminator:  0.672745943069458\n",
      "Epoch:  19     Batch:  221  /  468     Loss_generator:  0.7247143983840942     Loss_discriminator:  0.69837486743927\n",
      "Epoch:  19     Batch:  222  /  468     Loss_generator:  0.7242220640182495     Loss_discriminator:  0.6854934692382812\n",
      "Epoch:  19     Batch:  223  /  468     Loss_generator:  0.7062534093856812     Loss_discriminator:  0.6855676174163818\n",
      "Epoch:  19     Batch:  224  /  468     Loss_generator:  0.6962536573410034     Loss_discriminator:  0.6843122243881226\n",
      "Epoch:  19     Batch:  225  /  468     Loss_generator:  0.6910951137542725     Loss_discriminator:  0.6724889278411865\n",
      "Epoch:  19     Batch:  226  /  468     Loss_generator:  0.6851597428321838     Loss_discriminator:  0.680695116519928\n",
      "Epoch:  19     Batch:  227  /  468     Loss_generator:  0.7080022096633911     Loss_discriminator:  0.6945837736129761\n",
      "Epoch:  19     Batch:  228  /  468     Loss_generator:  0.7604609727859497     Loss_discriminator:  0.6931878924369812\n",
      "Epoch:  19     Batch:  229  /  468     Loss_generator:  0.761795163154602     Loss_discriminator:  0.6852961182594299\n",
      "Epoch:  19     Batch:  230  /  468     Loss_generator:  0.7051808834075928     Loss_discriminator:  0.6882568597793579\n",
      "Epoch:  19     Batch:  231  /  468     Loss_generator:  0.6528831720352173     Loss_discriminator:  0.6989672780036926\n",
      "Epoch:  19     Batch:  232  /  468     Loss_generator:  0.648809552192688     Loss_discriminator:  0.6915855407714844\n",
      "Epoch:  19     Batch:  233  /  468     Loss_generator:  0.6644212007522583     Loss_discriminator:  0.6953766345977783\n",
      "Epoch:  19     Batch:  234  /  468     Loss_generator:  0.7301321029663086     Loss_discriminator:  0.6950427889823914\n",
      "Epoch:  19     Batch:  235  /  468     Loss_generator:  0.7109049558639526     Loss_discriminator:  0.672146201133728\n",
      "Epoch:  19     Batch:  236  /  468     Loss_generator:  0.7059260010719299     Loss_discriminator:  0.6833192110061646\n",
      "Epoch:  19     Batch:  237  /  468     Loss_generator:  0.7340251803398132     Loss_discriminator:  0.6860777139663696\n",
      "Epoch:  19     Batch:  238  /  468     Loss_generator:  0.7215914130210876     Loss_discriminator:  0.6990497708320618\n",
      "Epoch:  19     Batch:  239  /  468     Loss_generator:  0.7572232484817505     Loss_discriminator:  0.686216413974762\n",
      "Epoch:  19     Batch:  240  /  468     Loss_generator:  0.7286287546157837     Loss_discriminator:  0.6923064589500427\n",
      "Epoch:  19     Batch:  241  /  468     Loss_generator:  0.7105401158332825     Loss_discriminator:  0.6856085062026978\n",
      "Epoch:  19     Batch:  242  /  468     Loss_generator:  0.7043576240539551     Loss_discriminator:  0.6830112934112549\n",
      "Epoch:  19     Batch:  243  /  468     Loss_generator:  0.6858651638031006     Loss_discriminator:  0.6971780061721802\n",
      "Epoch:  19     Batch:  244  /  468     Loss_generator:  0.7068920731544495     Loss_discriminator:  0.6771667003631592\n",
      "Epoch:  19     Batch:  245  /  468     Loss_generator:  0.7295643091201782     Loss_discriminator:  0.689767599105835\n",
      "Epoch:  19     Batch:  246  /  468     Loss_generator:  0.7177038192749023     Loss_discriminator:  0.679824948310852\n",
      "Epoch:  19     Batch:  247  /  468     Loss_generator:  0.6888421177864075     Loss_discriminator:  0.6768748760223389\n",
      "Epoch:  19     Batch:  248  /  468     Loss_generator:  0.687867283821106     Loss_discriminator:  0.6872514486312866\n",
      "Epoch:  19     Batch:  249  /  468     Loss_generator:  0.7099424600601196     Loss_discriminator:  0.6871685981750488\n",
      "Epoch:  19     Batch:  250  /  468     Loss_generator:  0.7481931447982788     Loss_discriminator:  0.6966073513031006\n",
      "Epoch:  19     Batch:  251  /  468     Loss_generator:  0.7433911561965942     Loss_discriminator:  0.6892595291137695\n",
      "Epoch:  19     Batch:  252  /  468     Loss_generator:  0.7359466552734375     Loss_discriminator:  0.6822218298912048\n",
      "Epoch:  19     Batch:  253  /  468     Loss_generator:  0.6987143754959106     Loss_discriminator:  0.6874548196792603\n",
      "Epoch:  19     Batch:  254  /  468     Loss_generator:  0.6735854148864746     Loss_discriminator:  0.6803016662597656\n",
      "Epoch:  19     Batch:  255  /  468     Loss_generator:  0.6804747581481934     Loss_discriminator:  0.6952903270721436\n",
      "Epoch:  19     Batch:  256  /  468     Loss_generator:  0.7172291278839111     Loss_discriminator:  0.6929316520690918\n",
      "Epoch:  19     Batch:  257  /  468     Loss_generator:  0.7007057070732117     Loss_discriminator:  0.6854719519615173\n",
      "Epoch:  19     Batch:  258  /  468     Loss_generator:  0.7071547508239746     Loss_discriminator:  0.6895347833633423\n",
      "Epoch:  19     Batch:  259  /  468     Loss_generator:  0.6867378354072571     Loss_discriminator:  0.6853023767471313\n",
      "Epoch:  19     Batch:  260  /  468     Loss_generator:  0.6971626281738281     Loss_discriminator:  0.6798160076141357\n",
      "Epoch:  19     Batch:  261  /  468     Loss_generator:  0.7073315382003784     Loss_discriminator:  0.6941543817520142\n",
      "Epoch:  19     Batch:  262  /  468     Loss_generator:  0.7392547726631165     Loss_discriminator:  0.6796048283576965\n",
      "Epoch:  19     Batch:  263  /  468     Loss_generator:  0.7767990827560425     Loss_discriminator:  0.6884752511978149\n",
      "Epoch:  19     Batch:  264  /  468     Loss_generator:  0.7511509656906128     Loss_discriminator:  0.6870933771133423\n",
      "Epoch:  19     Batch:  265  /  468     Loss_generator:  0.6902540922164917     Loss_discriminator:  0.7027567028999329\n",
      "Epoch:  19     Batch:  266  /  468     Loss_generator:  0.6797155737876892     Loss_discriminator:  0.6830229163169861\n",
      "Epoch:  19     Batch:  267  /  468     Loss_generator:  0.6960614323616028     Loss_discriminator:  0.6871343851089478\n",
      "Epoch:  19     Batch:  268  /  468     Loss_generator:  0.7532168030738831     Loss_discriminator:  0.6866146326065063\n",
      "Epoch:  19     Batch:  269  /  468     Loss_generator:  0.7771007418632507     Loss_discriminator:  0.6845555305480957\n",
      "Epoch:  19     Batch:  270  /  468     Loss_generator:  0.751103937625885     Loss_discriminator:  0.692512035369873\n",
      "Epoch:  19     Batch:  271  /  468     Loss_generator:  0.7010359764099121     Loss_discriminator:  0.6921204924583435\n",
      "Epoch:  19     Batch:  272  /  468     Loss_generator:  0.6612100601196289     Loss_discriminator:  0.6819249987602234\n",
      "Epoch:  19     Batch:  273  /  468     Loss_generator:  0.6803115606307983     Loss_discriminator:  0.6884795427322388\n",
      "Epoch:  19     Batch:  274  /  468     Loss_generator:  0.7482215166091919     Loss_discriminator:  0.6761813163757324\n",
      "Epoch:  19     Batch:  275  /  468     Loss_generator:  0.7566322088241577     Loss_discriminator:  0.691521942615509\n",
      "Epoch:  19     Batch:  276  /  468     Loss_generator:  0.7306802272796631     Loss_discriminator:  0.675463855266571\n",
      "Epoch:  19     Batch:  277  /  468     Loss_generator:  0.6944842338562012     Loss_discriminator:  0.676232099533081\n",
      "Epoch:  19     Batch:  278  /  468     Loss_generator:  0.6918282508850098     Loss_discriminator:  0.6846451759338379\n",
      "Epoch:  19     Batch:  279  /  468     Loss_generator:  0.7103593349456787     Loss_discriminator:  0.6851464509963989\n",
      "Epoch:  19     Batch:  280  /  468     Loss_generator:  0.6879358291625977     Loss_discriminator:  0.6788502931594849\n",
      "Epoch:  19     Batch:  281  /  468     Loss_generator:  0.6981883645057678     Loss_discriminator:  0.6995653510093689\n",
      "Epoch:  19     Batch:  282  /  468     Loss_generator:  0.7018765807151794     Loss_discriminator:  0.6786367893218994\n",
      "Epoch:  19     Batch:  283  /  468     Loss_generator:  0.7379995584487915     Loss_discriminator:  0.6730072498321533\n",
      "Epoch:  19     Batch:  284  /  468     Loss_generator:  0.7547653913497925     Loss_discriminator:  0.6832630038261414\n",
      "Epoch:  19     Batch:  285  /  468     Loss_generator:  0.6978950500488281     Loss_discriminator:  0.6801319122314453\n",
      "Epoch:  19     Batch:  286  /  468     Loss_generator:  0.662108302116394     Loss_discriminator:  0.6751415729522705\n",
      "Epoch:  19     Batch:  287  /  468     Loss_generator:  0.6735473871231079     Loss_discriminator:  0.6716058254241943\n",
      "Epoch:  19     Batch:  288  /  468     Loss_generator:  0.7312459945678711     Loss_discriminator:  0.6924852132797241\n",
      "Epoch:  19     Batch:  289  /  468     Loss_generator:  0.7688236236572266     Loss_discriminator:  0.683489203453064\n",
      "Epoch:  19     Batch:  290  /  468     Loss_generator:  0.7263176441192627     Loss_discriminator:  0.6947445869445801\n",
      "Epoch:  19     Batch:  291  /  468     Loss_generator:  0.7078243494033813     Loss_discriminator:  0.6910978555679321\n",
      "Epoch:  19     Batch:  292  /  468     Loss_generator:  0.6714591979980469     Loss_discriminator:  0.6794132590293884\n",
      "Epoch:  19     Batch:  293  /  468     Loss_generator:  0.6778457164764404     Loss_discriminator:  0.6769874095916748\n",
      "Epoch:  19     Batch:  294  /  468     Loss_generator:  0.6804115772247314     Loss_discriminator:  0.6830304861068726\n",
      "Epoch:  19     Batch:  295  /  468     Loss_generator:  0.7840747237205505     Loss_discriminator:  0.6850252151489258\n",
      "Epoch:  19     Batch:  296  /  468     Loss_generator:  0.7564411759376526     Loss_discriminator:  0.6753590703010559\n",
      "Epoch:  19     Batch:  297  /  468     Loss_generator:  0.7165975570678711     Loss_discriminator:  0.6946103572845459\n",
      "Epoch:  19     Batch:  298  /  468     Loss_generator:  0.6819678544998169     Loss_discriminator:  0.6833739876747131\n",
      "Epoch:  19     Batch:  299  /  468     Loss_generator:  0.7085264921188354     Loss_discriminator:  0.6910152435302734\n",
      "Epoch:  19     Batch:  300  /  468     Loss_generator:  0.7117249965667725     Loss_discriminator:  0.678924560546875\n",
      "Epoch:  19     Batch:  301  /  468     Loss_generator:  0.7471140027046204     Loss_discriminator:  0.6806193590164185\n",
      "Epoch:  19     Batch:  302  /  468     Loss_generator:  0.7469554543495178     Loss_discriminator:  0.6871890425682068\n",
      "Epoch:  19     Batch:  303  /  468     Loss_generator:  0.7219770550727844     Loss_discriminator:  0.6845316886901855\n",
      "Epoch:  19     Batch:  304  /  468     Loss_generator:  0.7066798210144043     Loss_discriminator:  0.6845860481262207\n",
      "Epoch:  19     Batch:  305  /  468     Loss_generator:  0.690840482711792     Loss_discriminator:  0.686677098274231\n",
      "Epoch:  19     Batch:  306  /  468     Loss_generator:  0.7036677598953247     Loss_discriminator:  0.6745930910110474\n",
      "Epoch:  19     Batch:  307  /  468     Loss_generator:  0.717140793800354     Loss_discriminator:  0.6918160319328308\n",
      "Epoch:  19     Batch:  308  /  468     Loss_generator:  0.740078330039978     Loss_discriminator:  0.6666271686553955\n",
      "Epoch:  19     Batch:  309  /  468     Loss_generator:  0.7385145425796509     Loss_discriminator:  0.6914651393890381\n",
      "Epoch:  19     Batch:  310  /  468     Loss_generator:  0.7495468854904175     Loss_discriminator:  0.6740586757659912\n",
      "Epoch:  19     Batch:  311  /  468     Loss_generator:  0.7113169431686401     Loss_discriminator:  0.696345865726471\n",
      "Epoch:  19     Batch:  312  /  468     Loss_generator:  0.6908122897148132     Loss_discriminator:  0.6758561134338379\n",
      "Epoch:  19     Batch:  313  /  468     Loss_generator:  0.6703217625617981     Loss_discriminator:  0.6881122589111328\n",
      "Epoch:  19     Batch:  314  /  468     Loss_generator:  0.7090975046157837     Loss_discriminator:  0.6912230849266052\n",
      "Epoch:  19     Batch:  315  /  468     Loss_generator:  0.6991612315177917     Loss_discriminator:  0.6778607964515686\n",
      "Epoch:  19     Batch:  316  /  468     Loss_generator:  0.7359097003936768     Loss_discriminator:  0.6867266893386841\n",
      "Epoch:  19     Batch:  317  /  468     Loss_generator:  0.7120442390441895     Loss_discriminator:  0.6809858083724976\n",
      "Epoch:  19     Batch:  318  /  468     Loss_generator:  0.7129107117652893     Loss_discriminator:  0.6896044015884399\n",
      "Epoch:  19     Batch:  319  /  468     Loss_generator:  0.6829648613929749     Loss_discriminator:  0.6724662780761719\n",
      "Epoch:  19     Batch:  320  /  468     Loss_generator:  0.6772415637969971     Loss_discriminator:  0.6811010837554932\n",
      "Epoch:  19     Batch:  321  /  468     Loss_generator:  0.7066252827644348     Loss_discriminator:  0.6894807815551758\n",
      "Epoch:  19     Batch:  322  /  468     Loss_generator:  0.7907972931861877     Loss_discriminator:  0.7058342695236206\n",
      "Epoch:  19     Batch:  323  /  468     Loss_generator:  0.8260376453399658     Loss_discriminator:  0.6971054077148438\n",
      "Epoch:  19     Batch:  324  /  468     Loss_generator:  0.7564197778701782     Loss_discriminator:  0.6748411655426025\n",
      "Epoch:  19     Batch:  325  /  468     Loss_generator:  0.6668798327445984     Loss_discriminator:  0.6940526366233826\n",
      "Epoch:  19     Batch:  326  /  468     Loss_generator:  0.6302159428596497     Loss_discriminator:  0.691124439239502\n",
      "Epoch:  19     Batch:  327  /  468     Loss_generator:  0.6104610562324524     Loss_discriminator:  0.6820026636123657\n",
      "Epoch:  19     Batch:  328  /  468     Loss_generator:  0.7033064961433411     Loss_discriminator:  0.6843598484992981\n",
      "Epoch:  19     Batch:  329  /  468     Loss_generator:  0.7988362312316895     Loss_discriminator:  0.6938471794128418\n",
      "Epoch:  19     Batch:  330  /  468     Loss_generator:  0.7807588577270508     Loss_discriminator:  0.7005882263183594\n",
      "Epoch:  19     Batch:  331  /  468     Loss_generator:  0.743684709072113     Loss_discriminator:  0.6756841540336609\n",
      "Epoch:  19     Batch:  332  /  468     Loss_generator:  0.7154097557067871     Loss_discriminator:  0.679358720779419\n",
      "Epoch:  19     Batch:  333  /  468     Loss_generator:  0.679598867893219     Loss_discriminator:  0.6839176416397095\n",
      "Epoch:  19     Batch:  334  /  468     Loss_generator:  0.6944523453712463     Loss_discriminator:  0.6956307888031006\n",
      "Epoch:  19     Batch:  335  /  468     Loss_generator:  0.6906106472015381     Loss_discriminator:  0.6984837651252747\n",
      "Epoch:  19     Batch:  336  /  468     Loss_generator:  0.7133533954620361     Loss_discriminator:  0.684643030166626\n",
      "Epoch:  19     Batch:  337  /  468     Loss_generator:  0.7145369648933411     Loss_discriminator:  0.6981911659240723\n",
      "Epoch:  19     Batch:  338  /  468     Loss_generator:  0.690227746963501     Loss_discriminator:  0.6881759762763977\n",
      "Epoch:  19     Batch:  339  /  468     Loss_generator:  0.6890906095504761     Loss_discriminator:  0.6832462549209595\n",
      "Epoch:  19     Batch:  340  /  468     Loss_generator:  0.6847939491271973     Loss_discriminator:  0.6827453374862671\n",
      "Epoch:  19     Batch:  341  /  468     Loss_generator:  0.7098977565765381     Loss_discriminator:  0.683690071105957\n",
      "Epoch:  19     Batch:  342  /  468     Loss_generator:  0.75881427526474     Loss_discriminator:  0.6780383586883545\n",
      "Epoch:  19     Batch:  343  /  468     Loss_generator:  0.7521697282791138     Loss_discriminator:  0.6702543497085571\n",
      "Epoch:  19     Batch:  344  /  468     Loss_generator:  0.705474317073822     Loss_discriminator:  0.6810696125030518\n",
      "Epoch:  19     Batch:  345  /  468     Loss_generator:  0.6879226565361023     Loss_discriminator:  0.6660884618759155\n",
      "Epoch:  19     Batch:  346  /  468     Loss_generator:  0.6966959238052368     Loss_discriminator:  0.704738199710846\n",
      "Epoch:  19     Batch:  347  /  468     Loss_generator:  0.7161303162574768     Loss_discriminator:  0.6742830276489258\n",
      "Epoch:  19     Batch:  348  /  468     Loss_generator:  0.7667606472969055     Loss_discriminator:  0.6650022268295288\n",
      "Epoch:  19     Batch:  349  /  468     Loss_generator:  0.7350294589996338     Loss_discriminator:  0.6930652260780334\n",
      "Epoch:  19     Batch:  350  /  468     Loss_generator:  0.71912682056427     Loss_discriminator:  0.6900690793991089\n",
      "Epoch:  19     Batch:  351  /  468     Loss_generator:  0.6973313093185425     Loss_discriminator:  0.6848049163818359\n",
      "Epoch:  19     Batch:  352  /  468     Loss_generator:  0.6809629201889038     Loss_discriminator:  0.7004431486129761\n",
      "Epoch:  19     Batch:  353  /  468     Loss_generator:  0.6906470060348511     Loss_discriminator:  0.6719972491264343\n",
      "Epoch:  19     Batch:  354  /  468     Loss_generator:  0.7522481083869934     Loss_discriminator:  0.6907970905303955\n",
      "Epoch:  19     Batch:  355  /  468     Loss_generator:  0.753531277179718     Loss_discriminator:  0.7008844614028931\n",
      "Epoch:  19     Batch:  356  /  468     Loss_generator:  0.7561600208282471     Loss_discriminator:  0.6883466839790344\n",
      "Epoch:  19     Batch:  357  /  468     Loss_generator:  0.7357009649276733     Loss_discriminator:  0.7002893090248108\n",
      "Epoch:  19     Batch:  358  /  468     Loss_generator:  0.685758113861084     Loss_discriminator:  0.6781947612762451\n",
      "Epoch:  19     Batch:  359  /  468     Loss_generator:  0.663153886795044     Loss_discriminator:  0.6844171285629272\n",
      "Epoch:  19     Batch:  360  /  468     Loss_generator:  0.7076472640037537     Loss_discriminator:  0.6810404062271118\n",
      "Epoch:  19     Batch:  361  /  468     Loss_generator:  0.7659834027290344     Loss_discriminator:  0.7175013422966003\n",
      "Epoch:  19     Batch:  362  /  468     Loss_generator:  0.7395016551017761     Loss_discriminator:  0.6776984930038452\n",
      "Epoch:  19     Batch:  363  /  468     Loss_generator:  0.6737714409828186     Loss_discriminator:  0.6946592330932617\n",
      "Epoch:  19     Batch:  364  /  468     Loss_generator:  0.664155125617981     Loss_discriminator:  0.6737972497940063\n",
      "Epoch:  19     Batch:  365  /  468     Loss_generator:  0.6983047723770142     Loss_discriminator:  0.6769793033599854\n",
      "Epoch:  19     Batch:  366  /  468     Loss_generator:  0.7085285186767578     Loss_discriminator:  0.6942880749702454\n",
      "Epoch:  19     Batch:  367  /  468     Loss_generator:  0.7601400017738342     Loss_discriminator:  0.6842248439788818\n",
      "Epoch:  19     Batch:  368  /  468     Loss_generator:  0.7365912199020386     Loss_discriminator:  0.6978682279586792\n",
      "Epoch:  19     Batch:  369  /  468     Loss_generator:  0.7381935715675354     Loss_discriminator:  0.6860532760620117\n",
      "Epoch:  19     Batch:  370  /  468     Loss_generator:  0.7082614898681641     Loss_discriminator:  0.6828712224960327\n",
      "Epoch:  19     Batch:  371  /  468     Loss_generator:  0.7090463042259216     Loss_discriminator:  0.6701368093490601\n",
      "Epoch:  19     Batch:  372  /  468     Loss_generator:  0.6804322600364685     Loss_discriminator:  0.6917786598205566\n",
      "Epoch:  19     Batch:  373  /  468     Loss_generator:  0.6595304012298584     Loss_discriminator:  0.6785172820091248\n",
      "Epoch:  19     Batch:  374  /  468     Loss_generator:  0.7120965719223022     Loss_discriminator:  0.6887614130973816\n",
      "Epoch:  19     Batch:  375  /  468     Loss_generator:  0.7501713037490845     Loss_discriminator:  0.6914589405059814\n",
      "Epoch:  19     Batch:  376  /  468     Loss_generator:  0.7381571531295776     Loss_discriminator:  0.6882960200309753\n",
      "Epoch:  19     Batch:  377  /  468     Loss_generator:  0.68406742811203     Loss_discriminator:  0.6815110445022583\n",
      "Epoch:  19     Batch:  378  /  468     Loss_generator:  0.6826009750366211     Loss_discriminator:  0.6685115694999695\n",
      "Epoch:  19     Batch:  379  /  468     Loss_generator:  0.694345235824585     Loss_discriminator:  0.6777031421661377\n",
      "Epoch:  19     Batch:  380  /  468     Loss_generator:  0.724180281162262     Loss_discriminator:  0.6853852272033691\n",
      "Epoch:  19     Batch:  381  /  468     Loss_generator:  0.7248749136924744     Loss_discriminator:  0.6830193400382996\n",
      "Epoch:  19     Batch:  382  /  468     Loss_generator:  0.724270224571228     Loss_discriminator:  0.6792905330657959\n",
      "Epoch:  19     Batch:  383  /  468     Loss_generator:  0.7250568866729736     Loss_discriminator:  0.6745419502258301\n",
      "Epoch:  19     Batch:  384  /  468     Loss_generator:  0.7092185020446777     Loss_discriminator:  0.6835454702377319\n",
      "Epoch:  19     Batch:  385  /  468     Loss_generator:  0.709208607673645     Loss_discriminator:  0.6844944953918457\n",
      "Epoch:  19     Batch:  386  /  468     Loss_generator:  0.6909451484680176     Loss_discriminator:  0.6967172622680664\n",
      "Epoch:  19     Batch:  387  /  468     Loss_generator:  0.701659619808197     Loss_discriminator:  0.6860230565071106\n",
      "Epoch:  19     Batch:  388  /  468     Loss_generator:  0.7507545948028564     Loss_discriminator:  0.6997710466384888\n",
      "Epoch:  19     Batch:  389  /  468     Loss_generator:  0.7422950267791748     Loss_discriminator:  0.7025484442710876\n",
      "Epoch:  19     Batch:  390  /  468     Loss_generator:  0.7122072577476501     Loss_discriminator:  0.694909930229187\n",
      "Epoch:  19     Batch:  391  /  468     Loss_generator:  0.6859605312347412     Loss_discriminator:  0.7048384547233582\n",
      "Epoch:  19     Batch:  392  /  468     Loss_generator:  0.6950790882110596     Loss_discriminator:  0.6797306537628174\n",
      "Epoch:  19     Batch:  393  /  468     Loss_generator:  0.7197172045707703     Loss_discriminator:  0.6609718799591064\n",
      "Epoch:  19     Batch:  394  /  468     Loss_generator:  0.7675696611404419     Loss_discriminator:  0.6714255809783936\n",
      "Epoch:  19     Batch:  395  /  468     Loss_generator:  0.7539219856262207     Loss_discriminator:  0.7023128271102905\n",
      "Epoch:  19     Batch:  396  /  468     Loss_generator:  0.7045038938522339     Loss_discriminator:  0.6936582922935486\n",
      "Epoch:  19     Batch:  397  /  468     Loss_generator:  0.6591649055480957     Loss_discriminator:  0.6800623536109924\n",
      "Epoch:  19     Batch:  398  /  468     Loss_generator:  0.6386816501617432     Loss_discriminator:  0.6880954504013062\n",
      "Epoch:  19     Batch:  399  /  468     Loss_generator:  0.7092587351799011     Loss_discriminator:  0.7110326290130615\n",
      "Epoch:  19     Batch:  400  /  468     Loss_generator:  0.7938962578773499     Loss_discriminator:  0.6754562258720398\n",
      "Epoch:  19     Batch:  401  /  468     Loss_generator:  0.7651281952857971     Loss_discriminator:  0.6918817758560181\n",
      "Epoch:  19     Batch:  402  /  468     Loss_generator:  0.7208634614944458     Loss_discriminator:  0.7127509117126465\n",
      "Epoch:  19     Batch:  403  /  468     Loss_generator:  0.6471139192581177     Loss_discriminator:  0.6887327432632446\n",
      "Epoch:  19     Batch:  404  /  468     Loss_generator:  0.6181778907775879     Loss_discriminator:  0.6864129900932312\n",
      "Epoch:  19     Batch:  405  /  468     Loss_generator:  0.6678484678268433     Loss_discriminator:  0.7037376165390015\n",
      "Epoch:  19     Batch:  406  /  468     Loss_generator:  0.7828376889228821     Loss_discriminator:  0.6813766360282898\n",
      "Epoch:  19     Batch:  407  /  468     Loss_generator:  0.8354489207267761     Loss_discriminator:  0.6797868609428406\n",
      "Epoch:  19     Batch:  408  /  468     Loss_generator:  0.7931415438652039     Loss_discriminator:  0.6923877000808716\n",
      "Epoch:  19     Batch:  409  /  468     Loss_generator:  0.7043750286102295     Loss_discriminator:  0.6945852041244507\n",
      "Epoch:  19     Batch:  410  /  468     Loss_generator:  0.6540296077728271     Loss_discriminator:  0.680048942565918\n",
      "Epoch:  19     Batch:  411  /  468     Loss_generator:  0.6447381973266602     Loss_discriminator:  0.678839385509491\n",
      "Epoch:  19     Batch:  412  /  468     Loss_generator:  0.6728083491325378     Loss_discriminator:  0.6969459056854248\n",
      "Epoch:  19     Batch:  413  /  468     Loss_generator:  0.7494862079620361     Loss_discriminator:  0.6875519752502441\n",
      "Epoch:  19     Batch:  414  /  468     Loss_generator:  0.7835084199905396     Loss_discriminator:  0.6664996147155762\n",
      "Epoch:  19     Batch:  415  /  468     Loss_generator:  0.7433674335479736     Loss_discriminator:  0.6795093417167664\n",
      "Epoch:  19     Batch:  416  /  468     Loss_generator:  0.6992242932319641     Loss_discriminator:  0.6853556632995605\n",
      "Epoch:  19     Batch:  417  /  468     Loss_generator:  0.6612966060638428     Loss_discriminator:  0.6729233264923096\n",
      "Epoch:  19     Batch:  418  /  468     Loss_generator:  0.670330822467804     Loss_discriminator:  0.6926684379577637\n",
      "Epoch:  19     Batch:  419  /  468     Loss_generator:  0.7347171306610107     Loss_discriminator:  0.6760075092315674\n",
      "Epoch:  19     Batch:  420  /  468     Loss_generator:  0.7537378072738647     Loss_discriminator:  0.6854044198989868\n",
      "Epoch:  19     Batch:  421  /  468     Loss_generator:  0.7355034351348877     Loss_discriminator:  0.6854394674301147\n",
      "Epoch:  19     Batch:  422  /  468     Loss_generator:  0.7248693704605103     Loss_discriminator:  0.6938767433166504\n",
      "Epoch:  19     Batch:  423  /  468     Loss_generator:  0.6527734994888306     Loss_discriminator:  0.684856653213501\n",
      "Epoch:  19     Batch:  424  /  468     Loss_generator:  0.6682761311531067     Loss_discriminator:  0.6815424561500549\n",
      "Epoch:  19     Batch:  425  /  468     Loss_generator:  0.7110681533813477     Loss_discriminator:  0.6873161196708679\n",
      "Epoch:  19     Batch:  426  /  468     Loss_generator:  0.7547742128372192     Loss_discriminator:  0.6822015643119812\n",
      "Epoch:  19     Batch:  427  /  468     Loss_generator:  0.7582797408103943     Loss_discriminator:  0.6871304512023926\n",
      "Epoch:  19     Batch:  428  /  468     Loss_generator:  0.7289880514144897     Loss_discriminator:  0.6669460535049438\n",
      "Epoch:  19     Batch:  429  /  468     Loss_generator:  0.6990386247634888     Loss_discriminator:  0.674972653388977\n",
      "Epoch:  19     Batch:  430  /  468     Loss_generator:  0.6904343962669373     Loss_discriminator:  0.7003034353256226\n",
      "Epoch:  19     Batch:  431  /  468     Loss_generator:  0.7000496983528137     Loss_discriminator:  0.6836796998977661\n",
      "Epoch:  19     Batch:  432  /  468     Loss_generator:  0.6874443292617798     Loss_discriminator:  0.6988565921783447\n",
      "Epoch:  19     Batch:  433  /  468     Loss_generator:  0.7341532111167908     Loss_discriminator:  0.6849347352981567\n",
      "Epoch:  19     Batch:  434  /  468     Loss_generator:  0.7152809500694275     Loss_discriminator:  0.6844797730445862\n",
      "Epoch:  19     Batch:  435  /  468     Loss_generator:  0.7111815214157104     Loss_discriminator:  0.6730356216430664\n",
      "Epoch:  19     Batch:  436  /  468     Loss_generator:  0.7160525321960449     Loss_discriminator:  0.6942605972290039\n",
      "Epoch:  19     Batch:  437  /  468     Loss_generator:  0.7145311832427979     Loss_discriminator:  0.7056065201759338\n",
      "Epoch:  19     Batch:  438  /  468     Loss_generator:  0.7120311260223389     Loss_discriminator:  0.6910713911056519\n",
      "Epoch:  19     Batch:  439  /  468     Loss_generator:  0.7361790537834167     Loss_discriminator:  0.6878563761711121\n",
      "Epoch:  19     Batch:  440  /  468     Loss_generator:  0.7278162240982056     Loss_discriminator:  0.6863443851470947\n",
      "Epoch:  19     Batch:  441  /  468     Loss_generator:  0.7279314994812012     Loss_discriminator:  0.6915627717971802\n",
      "Epoch:  19     Batch:  442  /  468     Loss_generator:  0.7141348123550415     Loss_discriminator:  0.6807304620742798\n",
      "Epoch:  19     Batch:  443  /  468     Loss_generator:  0.6828019022941589     Loss_discriminator:  0.6921135187149048\n",
      "Epoch:  19     Batch:  444  /  468     Loss_generator:  0.7086345553398132     Loss_discriminator:  0.6900094151496887\n",
      "Epoch:  19     Batch:  445  /  468     Loss_generator:  0.7071605920791626     Loss_discriminator:  0.6837918162345886\n",
      "Epoch:  19     Batch:  446  /  468     Loss_generator:  0.7129455804824829     Loss_discriminator:  0.6806516647338867\n",
      "Epoch:  19     Batch:  447  /  468     Loss_generator:  0.6805204749107361     Loss_discriminator:  0.6846420168876648\n",
      "Epoch:  19     Batch:  448  /  468     Loss_generator:  0.6909227967262268     Loss_discriminator:  0.7002086639404297\n",
      "Epoch:  19     Batch:  449  /  468     Loss_generator:  0.6895359754562378     Loss_discriminator:  0.6716919541358948\n",
      "Epoch:  19     Batch:  450  /  468     Loss_generator:  0.7179890871047974     Loss_discriminator:  0.6868427395820618\n",
      "Epoch:  19     Batch:  451  /  468     Loss_generator:  0.7729889154434204     Loss_discriminator:  0.6942355036735535\n",
      "Epoch:  19     Batch:  452  /  468     Loss_generator:  0.8031712770462036     Loss_discriminator:  0.6656043529510498\n",
      "Epoch:  19     Batch:  453  /  468     Loss_generator:  0.7185684442520142     Loss_discriminator:  0.6975100040435791\n",
      "Epoch:  19     Batch:  454  /  468     Loss_generator:  0.6578449010848999     Loss_discriminator:  0.6972948908805847\n",
      "Epoch:  19     Batch:  455  /  468     Loss_generator:  0.6219379901885986     Loss_discriminator:  0.6725210547447205\n",
      "Epoch:  19     Batch:  456  /  468     Loss_generator:  0.6586344242095947     Loss_discriminator:  0.6852138042449951\n",
      "Epoch:  19     Batch:  457  /  468     Loss_generator:  0.7121292948722839     Loss_discriminator:  0.7059672474861145\n",
      "Epoch:  19     Batch:  458  /  468     Loss_generator:  0.7967648506164551     Loss_discriminator:  0.6809205412864685\n",
      "Epoch:  19     Batch:  459  /  468     Loss_generator:  0.7702041268348694     Loss_discriminator:  0.6874552965164185\n",
      "Epoch:  19     Batch:  460  /  468     Loss_generator:  0.726947009563446     Loss_discriminator:  0.6957972049713135\n",
      "Epoch:  19     Batch:  461  /  468     Loss_generator:  0.6725281476974487     Loss_discriminator:  0.6925405859947205\n",
      "Epoch:  19     Batch:  462  /  468     Loss_generator:  0.6369920372962952     Loss_discriminator:  0.6868761777877808\n",
      "Epoch:  19     Batch:  463  /  468     Loss_generator:  0.658613383769989     Loss_discriminator:  0.682197093963623\n",
      "Epoch:  19     Batch:  464  /  468     Loss_generator:  0.6957578659057617     Loss_discriminator:  0.6839532852172852\n",
      "Epoch:  19     Batch:  465  /  468     Loss_generator:  0.7243490815162659     Loss_discriminator:  0.6853488087654114\n",
      "Epoch:  19     Batch:  466  /  468     Loss_generator:  0.7795015573501587     Loss_discriminator:  0.6833449006080627\n",
      "Epoch:  19     Batch:  467  /  468     Loss_generator:  0.7624748349189758     Loss_discriminator:  0.6875169277191162\n"
     ]
    }
   ],
   "source": [
    "loss_discriminator_list = []\n",
    "loss_generator_list = []\n",
    "\n",
    "\n",
    "def train(generator, discriminator, gan, noise_size=100, epochs=20, batch_size=128):\n",
    "    batches_per_epoch = int(60000 / batch_size)\n",
    "    half_batch_size = int(batch_size / 2)\n",
    "\n",
    "    for epoch in range(0, epochs):\n",
    "        for batch in range(0, batches_per_epoch):\n",
    "            # Generate batches\n",
    "            mnist_images, mnist_labels = get_mnist_batch(half_batch_size)\n",
    "            noise_samples, noise_labels = get_noise_batch(half_batch_size, noise_size)\n",
    "\n",
    "            # Step 1: Train the discriminator\n",
    "            generated_images = generator.predict(noise_samples)\n",
    "            all_images, all_labels = np.vstack((mnist_images, generated_images)), np.vstack((mnist_labels, noise_labels))\n",
    "            loss_discriminator, _ = discriminator.train_on_batch(all_images, all_labels)\n",
    "            loss_discriminator_list.append(loss_discriminator)\n",
    "\n",
    "            # Step 2: Train the generator\n",
    "            noise_samples, noise_labels = get_noise_batch(batch_size, noise_size)\n",
    "            noise_labels = np.ones((batch_size, 1))\n",
    "            loss_generator = gan.train_on_batch(noise_samples, noise_labels)\n",
    "            loss_generator_list.append(loss_generator)\n",
    "\n",
    "            print('Epoch: ', epoch, '    Batch: ', batch, ' / ', batches_per_epoch, '    Loss_generator: ', loss_generator, '    Loss_discriminator: ', loss_discriminator)\n",
    "        \n",
    "        # Save the model every epoch\n",
    "        fig = plt.figure()\n",
    "        for a in range(25):\n",
    "            ax = fig.add_subplot(5, 5, a + 1)\n",
    "            plt.imshow(generated_images[a, :, :, 0], cmap='gray_r')\n",
    "        plt.savefig('plot  epoch ' + '%02d' % epoch + '  batch ' + '%05d' % batch + '.png', dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "        # Save the generator and discriminator\n",
    "        generator.save('generator.h5')\n",
    "        discriminator.save('discriminator.h5')\n",
    "        gan.save('gan.h5')\n",
    "\n",
    "\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "gan = build_gan(generator, discriminator)\n",
    "\n",
    "train(generator, discriminator, gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "I6Jfha_dwMXb",
    "outputId": "a93089b7-9e70-4275-9dce-f4c0a53b27a8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_discriminator_list)\n",
    "plt.plot(loss_generator_list)\n",
    "plt.title(\"Model Loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"batches\")\n",
    "plt.legend([\"train\", \"validation\"], loc=\"upper right\")\n",
    "plt.show()\n",
    "plt.savefig(\"plot.png\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Generative Adversarial Networks.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
